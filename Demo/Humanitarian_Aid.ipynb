{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c03ee18-f22f-4709-91a4-d0786553bdfb",
   "metadata": {},
   "source": [
    "## Humanitarian Relief Project\n",
    "Prepared by, A. Lamsal and D.O. Oral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fff6a9-6a13-4600-b47a-3a0dd607c2aa",
   "metadata": {},
   "source": [
    "## 0. Necessities\n",
    "Run the below lying code (Without \"#\") to download all of the necessities at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf449b-e883-403d-8637-1c56c59e5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb221d53-0209-4995-9aca-6cc005cb9359",
   "metadata": {},
   "source": [
    "Run the code snippet below once, before starting your work every time. This will allow the code to access configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe2bc0-2ad7-4ebb-aac2-ec39de83617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration File Load\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\", encoding=\"utf-8\") as _f:\n",
    "    CFG = yaml.safe_load(_f) or {}\n",
    "\n",
    "class ConfigError(Exception):\n",
    "    pass\n",
    "\n",
    "def require(key, cast=None):\n",
    "    if key not in CFG:\n",
    "        raise ConfigError(f\"Missing required config key: {key}\")\n",
    "    val = CFG[key]\n",
    "    try:\n",
    "        return cast(val) if cast else val\n",
    "    except Exception as e:\n",
    "        raise ConfigError(f\"Bad type for key '{key}': {val!r} ({e})\")\n",
    "\n",
    "def optional(key, cast=None):\n",
    "    if key not in CFG:\n",
    "        return None\n",
    "    val = CFG[key]\n",
    "    return cast(val) if cast else val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd58b08-c3c1-4c1a-bd4f-982487a30578",
   "metadata": {},
   "source": [
    "## A. Data Download and Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88618ae-6fc0-41b8-93bb-fb293919700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== A0) Imports ===============================\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, box\n",
    "\n",
    "import osmnx as ox\n",
    "from owslib.wfs import WebFeatureService\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "from IPython.display import display\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55560c0d-ca13-4690-98ea-0d10ac1a5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== A1) Data, Outputs, and User Parameters ===================\n",
    "\n",
    "# ---- Directories ----\n",
    "DATA_DIR   = r\"./Data\"\n",
    "OUT_DIR_BASE = r\"./Outputs\"\n",
    "\n",
    "# Section-scoped outputs (this is Section A)\n",
    "OUT_DIR      = os.path.join(OUT_DIR_BASE, \"A\")\n",
    "IMAGES_DIR   = os.path.join(OUT_DIR_BASE, \"Images\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# ---- AOI selection mode: choose ONE of \"place\", \"coords\", or \"shapefile\"\n",
    "MODE = require(\"MODE\", str)       # \"place\" | \"coords\" | \"shapefile\"\n",
    "\n",
    "# If MODE == \"place\": the region name to query from OSM\n",
    "PLACE_NAME = require(\"PLACE_NAME\", str)\n",
    "\n",
    "# Historical OSM snapshot date (optional in Configuration)\n",
    "target_dt = require(\"target_dt\", str)\n",
    "ox.settings.overpass_settings   = f'[out:json][timeout:180][date:\"{target_dt}\"]'\n",
    "ox.settings.overpass_rate_limit = True\n",
    "\n",
    "# WFS server/layer\n",
    "WFS_URL   = require(\"WFS_URL\", str)\n",
    "WFS_LAYER = require(\"WFS_LAYER\", str)\n",
    "\n",
    "# Output filenames (written under OUT_DIR)\n",
    "OUT_BLDG      = \"buildings_selected_region.shp\"\n",
    "OUT_NODES     = \"osm_nodes.shp\"\n",
    "OUT_EDGES     = \"osm_edges.shp\"\n",
    "OUT_CITY_POLY = \"region_boundary.geojson\"   # saved when MODE == \"place\"\n",
    "\n",
    "# Grid splitting for WFS\n",
    "GRID_PARTS = require(\"GRID_PARTS\", int)   # e.g., 4x4\n",
    "\n",
    "# Optional: pad the AOI bounding box used for WFS (degrees)\n",
    "BBOX_PAD_DEG = require(\"BBOX_PAD_DEG\", float)\n",
    "\n",
    "# If MODE == \"coords\": manual AOI polygon coordinates (lon, lat)\n",
    "if MODE == \"coords\":\n",
    "    raw_coords = require(\"AOI_COORDS\")  # expect list of [lon, lat]\n",
    "    if raw_coords is None:\n",
    "        raise ValueError(\"AOI_COORDS must be set when MODE == 'coords'.\")\n",
    "    AOI_COORDS = [tuple(p) for p in raw_coords]\n",
    "else:\n",
    "    AOI_COORDS = None  # not used\n",
    "\n",
    "# If MODE == \"shapefile\": path to a polygon shapefile (inside DATA_DIR)\n",
    "if MODE == \"shapefile\":\n",
    "    SHP_PATH = os.path.join(DATA_DIR, require(\"SHP_NAME\", str))\n",
    "else:\n",
    "    SHP_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaab3fe-3b61-4d4c-81a2-eb87d95ebaca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============================ A2) Helper Functions =========================\n",
    "def split_polygon(gdf_in: gpd.GeoDataFrame, n_parts: int = 16) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Make an equal grid over the AOI and intersect to get sub-polygons.\n",
    "    For n_parts=16, creates a 4x4 grid over the AOI extent.\n",
    "    \"\"\"\n",
    "    if gdf_in.empty:\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=gdf_in.crs)\n",
    "\n",
    "    minx, miny, maxx, maxy = gdf_in.total_bounds\n",
    "    cols = int(n_parts ** 0.5)\n",
    "    rows = int(n_parts / cols)\n",
    "    dx = (maxx - minx) / cols\n",
    "    dy = (maxy - miny) / rows\n",
    "\n",
    "    cells = []\n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            x1, y1 = minx + i * dx, miny + j * dy\n",
    "            x2, y2 = x1 + dx, y1 + dy\n",
    "            cells.append(box(x1, y1, x2, y2))\n",
    "\n",
    "    grid = gpd.GeoDataFrame(geometry=cells, crs=gdf_in.crs)\n",
    "    # Intersect grid with AOI to keep only overlapping parts\n",
    "    try:\n",
    "        out = gpd.overlay(grid, gdf_in, how=\"intersection\", keep_geom_type=True)\n",
    "    except Exception:\n",
    "        out = grid\n",
    "    return out\n",
    "\n",
    "\n",
    "def download_buildings_chunk(\n",
    "    wfs: WebFeatureService,\n",
    "    bbox_3857: tuple,\n",
    "    typename: str,\n",
    "    srsname: str = \"urn:x-ogc:def:crs:EPSG:3857\",\n",
    "    max_retries: int = 3,\n",
    "    wait_sec: int = 5\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Download buildings using a rectangular bbox (EPSG:3857).\n",
    "    \"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = wfs.getfeature(\n",
    "                typename=typename,\n",
    "                bbox=bbox_3857,\n",
    "                srsname=srsname,\n",
    "                outputFormat=\"application/json\",\n",
    "            )\n",
    "            gdf = gpd.read_file(io.BytesIO(response.read()))\n",
    "            if gdf.crs is None:\n",
    "                gdf.set_crs(\"EPSG:3857\", inplace=True)\n",
    "            return gdf\n",
    "        except Exception as e:\n",
    "            print(f\"  Error on attempt {attempt}/{max_retries} for bbox={bbox_3857}: {e}\")\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(wait_sec)\n",
    "\n",
    "    return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:3857\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453d86b-2503-4004-8597-116050abe6b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===== A3) OSM download ===========\n",
    "# ===== Warning Suppression =====\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=DeprecationWarning,\n",
    "    message=\"The 'unary_union' attribute is deprecated, use the 'union_all\\\\(\\\\)' method instead.\"\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=UserWarning,\n",
    "    message=\"Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\"\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=RuntimeWarning,\n",
    "    message=\"Normalized/laundered field name:.*\"\n",
    ")\n",
    "\n",
    "# Downloading\n",
    "print(f\"[OSM Download Mode] {MODE!r}\")\n",
    "\n",
    "if MODE == \"place\":\n",
    "    print(f\"Fetching OSM admin polygon for: {PLACE_NAME}\")\n",
    "    region_boundary_gdf = ox.geocode_to_gdf(PLACE_NAME).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Save region boundary polygon\n",
    "    region_poly_path = os.path.join(OUT_DIR, OUT_CITY_POLY)\n",
    "    region_boundary_gdf.to_file(region_poly_path, driver=\"GeoJSON\")\n",
    "    print(f\"Saved region boundary → {region_poly_path}\")\n",
    "\n",
    "    # Download OSM network within the exact region polygon\n",
    "    print(\"Downloading OSM network within region polygon ...\")\n",
    "    region_geom = region_boundary_gdf.unary_union\n",
    "    G_city = ox.graph_from_polygon(region_geom, network_type=\"all\")\n",
    "    nodes, edges = ox.graph_to_gdfs(G_city)\n",
    "\n",
    "    # AOI polygon for later use in WFS\n",
    "    aoi_polygon_ll = region_boundary_gdf.unary_union\n",
    "    aoi_gdf_ll = gpd.GeoDataFrame(geometry=[aoi_polygon_ll], crs=\"EPSG:4326\")\n",
    "\n",
    "elif MODE == \"shapefile\":\n",
    "    print(f\"Loading AOI from shapefile: {SHP_PATH}\")\n",
    "    aoi_gdf_ll = gpd.read_file(SHP_PATH).to_crs(\"EPSG:4326\")\n",
    "    aoi_geom = aoi_gdf_ll.unary_union\n",
    "\n",
    "    print(\"Downloading OSM network within AOI polygon ...\")\n",
    "    G_city = ox.graph_from_polygon(aoi_geom, network_type=\"all\")\n",
    "    nodes, edges = ox.graph_to_gdfs(G_city)\n",
    "\n",
    "    # Also save the region boundary in this mode:\n",
    "    region_boundary_gdf = aoi_gdf_ll.copy()\n",
    "    region_poly_path = os.path.join(OUT_DIR, OUT_CITY_POLY)\n",
    "    region_boundary_gdf.to_file(region_poly_path, driver=\"GeoJSON\")\n",
    "    print(f\"Saved region boundary (from shapefile) → {region_poly_path}\")\n",
    "\n",
    "elif MODE == \"coords\":\n",
    "    print(\"Building AOI polygon from manual coordinates ...\")\n",
    "    polygon_ll = Polygon(AOI_COORDS)\n",
    "    aoi_gdf_ll = gpd.GeoDataFrame(geometry=[polygon_ll], crs=\"EPSG:4326\")\n",
    "\n",
    "    print(\"Downloading OSM network within AOI polygon ...\")\n",
    "    G_city = ox.graph_from_polygon(aoi_gdf_ll.unary_union, network_type=\"all\")\n",
    "    nodes, edges = ox.graph_to_gdfs(G_city)\n",
    "\n",
    "    # Also save the region boundary in this mode:\n",
    "    region_boundary_gdf = aoi_gdf_ll.copy()\n",
    "    region_poly_path = os.path.join(OUT_DIR, OUT_CITY_POLY)\n",
    "    region_boundary_gdf.to_file(region_poly_path, driver=\"GeoJSON\")\n",
    "    print(f\"Saved region boundary (from coords) → {region_poly_path}\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"MODE must be one of: 'place', 'coords', 'shapefile'\")\n",
    "\n",
    "# Save OSM nodes and edges into Outputs\\A\n",
    "nodes_path = os.path.join(OUT_DIR, OUT_NODES)\n",
    "edges_path = os.path.join(OUT_DIR, OUT_EDGES)\n",
    "nodes.to_file(nodes_path)\n",
    "edges.to_file(edges_path)\n",
    "print(f\"Saved OSM nodes → {nodes_path}\")\n",
    "print(f\"Saved OSM edges → {edges_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092b3f1-b035-4a94-938e-5d134a8ef35e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === A4) WFS download using AOI bbox → clip to AOI polygon → save ==========\n",
    "# Compute lon/lat min/max from AOI polygon\n",
    "minx, miny, maxx, maxy = aoi_gdf_ll.total_bounds\n",
    "if BBOX_PAD_DEG and BBOX_PAD_DEG > 0:\n",
    "    minx -= BBOX_PAD_DEG; miny -= BBOX_PAD_DEG\n",
    "    maxx += BBOX_PAD_DEG; maxy += BBOX_PAD_DEG\n",
    "\n",
    "print(\"AOI bbox (lon/lat):\")\n",
    "print(f\"  lon: {minx:.6f} .. {maxx:.6f}\")\n",
    "print(f\"  lat: {miny:.6f} .. {maxy:.6f}\")\n",
    "\n",
    "# Convert AOI to EPSG:3857 and split into smaller polygons for WFS\n",
    "aoi_gdf_3857 = aoi_gdf_ll.to_crs(\"EPSG:3857\")\n",
    "sub_polys_3857 = split_polygon(aoi_gdf_3857, n_parts=GRID_PARTS)\n",
    "print(f\"AOI split into {len(sub_polys_3857)} parts for WFS.\\n\")\n",
    "\n",
    "# Connect to WFS\n",
    "print(\"Connecting to WFS ...\")\n",
    "wfs = WebFeatureService(url=WFS_URL, version=\"1.1.0\", timeout=120)\n",
    "print(\"Connected.\\n\")\n",
    "\n",
    "# Download per grid cell via BBOX\n",
    "all_chunks = []\n",
    "for i, row in sub_polys_3857.iterrows():\n",
    "    part_id = i + 1\n",
    "    cell_bounds = tuple(row.geometry.bounds)\n",
    "    print(f\"Downloading buildings via WFS: part {part_id}/{len(sub_polys_3857)}\")\n",
    "    gdf_part = download_buildings_chunk(\n",
    "        wfs=wfs,\n",
    "        bbox_3857=cell_bounds,\n",
    "        typename=WFS_LAYER,\n",
    "        srsname=\"urn:x-ogc:def:crs:EPSG:3857\",\n",
    "        max_retries=3,\n",
    "        wait_sec=5\n",
    "    )\n",
    "    if gdf_part.empty:\n",
    "        print(f\"  No buildings for part {part_id}.\")\n",
    "        continue\n",
    "\n",
    "    # Clip to the exact cell polygon\n",
    "    cell_gdf = gpd.GeoDataFrame(geometry=[row.geometry], crs=sub_polys_3857.crs)\n",
    "    gdf_clip_cell = gpd.overlay(gdf_part, cell_gdf, how=\"intersection\")\n",
    "    if not gdf_clip_cell.empty:\n",
    "        all_chunks.append(gdf_clip_cell)\n",
    "\n",
    "if not all_chunks:\n",
    "    raise SystemExit(\"No buildings were downloaded from WFS for the AOI.\")\n",
    "\n",
    "# Merge and clip to the full AOI polygon\n",
    "print(\"\\nMerging WFS parts ...\")\n",
    "total_chunks = len(all_chunks)\n",
    "print(f\"  Total non-empty chunks to merge: {total_chunks}\")\n",
    "\n",
    "merged_list = []\n",
    "for idx, gdf_chunk in enumerate(all_chunks, start=1):\n",
    "    merged_list.append(gdf_chunk)\n",
    "    # lightweight \"progress bar\" in the same line\n",
    "    print(f\"  Merging chunks: {idx}/{total_chunks}\", end=\"\\r\")\n",
    "\n",
    "# finalize the progress line\n",
    "print()\n",
    "\n",
    "bld_3857_raw = gpd.GeoDataFrame(pd.concat(merged_list, ignore_index=True), crs=\"EPSG:3857\")\n",
    "\n",
    "# Drop duplicate geometries\n",
    "before_n = len(bld_3857_raw)\n",
    "print(\"  Dropping duplicate geometries ...\")\n",
    "bld_3857_raw = bld_3857_raw.drop_duplicates(subset=\"geometry\")\n",
    "after_n = len(bld_3857_raw)\n",
    "removed_n = before_n - after_n\n",
    "print(f\"  Kept {after_n} unique buildings (removed {removed_n} duplicates).\")\n",
    "\n",
    "print(\"  Clipping merged buildings to full AOI polygon ...\")\n",
    "aoi_full_3857 = aoi_gdf_ll.to_crs(\"EPSG:3857\")\n",
    "bld_3857 = gpd.overlay(bld_3857_raw, aoi_full_3857, how=\"intersection\")\n",
    "\n",
    "# Add centroid lon/lat (correct: centroid in projected CRS, then to EPSG:4326)\n",
    "print(\"  Computing centroids ...\")\n",
    "centroids_3857 = bld_3857.geometry.centroid          # in EPSG:3857\n",
    "centroids_ll = centroids_3857.to_crs(\"EPSG:4326\")    # convert to lon/lat\n",
    "\n",
    "bld_3857[\"longitude\"] = centroids_ll.x\n",
    "bld_3857[\"latitude\"]  = centroids_ll.y\n",
    "\n",
    "# Save buildings shapefile into Outputs\\A\n",
    "bldg_path = os.path.join(OUT_DIR, OUT_BLDG)\n",
    "bld_3857.to_file(bldg_path)\n",
    "print(f\"\\nExported AOI-clipped building shapefile → {bldg_path}\")\n",
    "print(f\"Total buildings saved (inside AOI): {len(bld_3857)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a6565-ef07-4b77-a195-0c9a18a8994e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======================= A5) Quick inspection (CRS + samples) ===============\n",
    "datasets = {\n",
    "    \"OSM_Nodes\": globals().get(\"nodes\", None),\n",
    "    \"OSM_Edges\": globals().get(\"edges\", None),\n",
    "    \"Region_Boundary\": globals().get(\"region_boundary_gdf\", None),  # if available\n",
    "}\n",
    "\n",
    "# Prefer previously created buildings if present; otherwise use fresh result\n",
    "if \"buildings_r\" in globals() and (globals()[\"buildings_r\"] is not None) and (not globals()[\"buildings_r\"].empty):\n",
    "    buildings_gdf = globals()[\"buildings_r\"]\n",
    "elif \"bldg\" in globals() and (globals()[\"bldg\"] is not None) and (not globals()[\"bldg\"].empty):\n",
    "    buildings_gdf = globals()[\"bldg\"]\n",
    "elif \"bld_3857\" in globals() and (globals()[\"bld_3857\"] is not None) and (not globals()[\"bld_3857\"].empty):\n",
    "    buildings_gdf = globals()[\"bld_3857\"]\n",
    "else:\n",
    "    buildings_gdf = globals().get(\"bld_3857\", None)\n",
    "\n",
    "datasets[\"Buildings\"] = buildings_gdf\n",
    "\n",
    "# --- CRS report ---\n",
    "print(\" Coordinate Reference Systems (CRS) of current GeoDataFrames:\\n\")\n",
    "for name, gdf in datasets.items():\n",
    "    if gdf is not None and hasattr(gdf, \"crs\"):\n",
    "        print(f\"{name:20s}: {gdf.crs}\")\n",
    "    else:\n",
    "        print(f\"{name:20s}: (not found or no CRS assigned)\")\n",
    "\n",
    "# --- Example rows ---\n",
    "print(\"\\n Example rows from loaded GeoDataFrames:\\n\")\n",
    "for name, gdf in datasets.items():\n",
    "    if gdf is not None and hasattr(gdf, \"empty\") and (not gdf.empty):\n",
    "        print(f\"── {name} ───────────────────────────────────────────────\")\n",
    "        try:\n",
    "            display(gdf.drop(columns=\"geometry\").head(5))\n",
    "        except Exception:\n",
    "            display(pd.DataFrame(gdf.head(5)))\n",
    "    else:\n",
    "        print(f\"── {name}: (not found or empty)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efd174-de41-44ef-8df6-aef4dd5a8ef9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============== A6) Plotting  ===============\n",
    "P = {\n",
    "    # ===== General Drawing Toggles =====\n",
    "    \"DRAW_EDGES\": True,                 # draw OSM road edges\n",
    "    \"DRAW_NODES\": False,                # draw OSM network nodes\n",
    "    \"DRAW_BUILDINGS\": True,             # draw building footprints\n",
    "    \"DRAW_REGION\": True,                # draw AOI boundary polygon\n",
    "\n",
    "    # ===== Manual Zoom (EPSG:4326) =====\n",
    "    \"lon_min\": None,                    # min longitude for custom zoom (None = auto)\n",
    "    \"lon_max\": None,                    # max longitude for custom zoom (None = auto)\n",
    "    \"lat_min\": None,                    # min latitude for custom zoom (None = auto)\n",
    "    \"lat_max\": None,                    # max latitude for custom zoom (None = auto)\n",
    "\n",
    "    # ===== Figure & Labels =====\n",
    "    \"FIGSIZE\": (11, 10),                # figure size (width, height) in inches\n",
    "    \"DPI\": 300,                         # export resolution (dots per inch)\n",
    "    \"TITLE\": \"AOI, Edges and Buildings\",  # plot title\n",
    "    \"TITLE_FONTSIZE\": 13,               # title font size (pt)\n",
    "    \"XLABEL\": \"Easting (m)\",            # x-axis label (projected meters)\n",
    "    \"YLABEL\": \"Northing (m)\",           # y-axis label (projected meters)\n",
    "\n",
    "    # ===== Region Boundary Style =====\n",
    "    \"REGION_COLOR\": \"black\",            # region boundary color\n",
    "    \"REGION_LW\": 1.2,                   # region boundary line width\n",
    "    \"REGION_ALPHA\": 1.0,                # region boundary transparency (0..1)\n",
    "    \"REGION_LABEL\": \"Region Boundary\",  # legend label for region\n",
    "\n",
    "    # ===== Road / Edge Style =====\n",
    "    \"EDGE_COLOR\": \"#9e9e9e\",            # edge color\n",
    "    \"EDGE_LW\": 0.6,                     # edge line width\n",
    "    \"EDGE_ALPHA\": 1.0,                  # edge transparency (0..1)\n",
    "    \"EDGE_LABEL\": \"Edges\",              # legend label for edges\n",
    "\n",
    "    # ===== Building Style =====\n",
    "    \"BLDG_FACE\": \"black\",               # building fill color\n",
    "    \"BLDG_EDGE\": \"none\",                # building outline color ('none' = no outline)\n",
    "    \"BLDG_LW\": 0.2,                     # building outline width (if not 'none')\n",
    "    \"BLDG_ALPHA\": 1.0,                  # building fill transparency (0..1)\n",
    "    \"BLDG_LABEL\": \"Buildings\",          # legend label for buildings\n",
    "\n",
    "    # ===== Node Style =====\n",
    "    \"NODE_COLOR\": \"#1f78b4\",            # node color\n",
    "    \"NODE_SIZE\": 1,                     # node marker size\n",
    "    \"NODE_ALPHA\": 1.0,                  # node transparency (0..1)\n",
    "    \"NODE_MAX_PLOT\": 150000,            # sample cap to avoid over-plotting\n",
    "    \"NODE_LABEL\": \"Nodes\",              # legend label for nodes\n",
    "\n",
    "    # ===== North Arrow =====\n",
    "    \"ADD_NORTH_ARROW\": True,            # show north arrow\n",
    "    \"NA_X\": 0.08,                       # arrow x-position (axes fraction 0–1)\n",
    "    \"NA_Y\": 0.12,                       # arrow y-position (axes fraction 0–1)\n",
    "    \"NA_LEN\": 0.08,                     # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",                    # arrow text\n",
    "    \"NA_COLOR\": \"black\",                # arrow color\n",
    "    \"NA_LW\": 2,                         # arrow line width\n",
    "    \"NA_FONTSIZE\": 14,                  # 'N' font size\n",
    "\n",
    "    # ===== Scalebar =====\n",
    "    \"ADD_SCALEBAR\": True,               # show scalebar\n",
    "    \"SB_DX\": 1,                         # units-per-pixel (1 when plotting in meters/UTM)\n",
    "    \"SB_UNITS\": \"m\",                    # units label for scalebar\n",
    "    \"SB_LOC\": \"lower right\",            # scalebar location\n",
    "    \"SB_BOX_ALPHA\": 0.8,                # scalebar box transparency (0..1)\n",
    "    \"SB_COLOR\": \"black\",                # scalebar text/line color\n",
    "\n",
    "    # ===== Legend =====\n",
    "    \"SHOW_LEGEND\": True,                # show legend\n",
    "    \"LEGEND_LOC\": \"upper right\",        # legend location\n",
    "    \"LEGEND_FRAME\": True,               # draw legend frame box\n",
    "    \"LEGEND_FACE\": \"white\",             # legend box facecolor\n",
    "    \"LEGEND_EDGE\": \"black\",             # legend box edgecolor\n",
    "\n",
    "    # ===== Output =====\n",
    "    \"OUT_NAME\": \"Region_UTM_Map_Datasets.png\"  # output PNG filename\n",
    "}\n",
    "\n",
    "# --- minimal helpers ---\n",
    "def add_north(ax, x, y, length, color, lw, fs, label):\n",
    "    ax.annotate(label, xy=(x, y), xytext=(x, y - length),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=fs, fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=lw, color=color),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "def add_scalebar(ax, dx, units, loc, alpha, color):\n",
    "    ax.add_artist(ScaleBar(dx, units, location=loc, box_alpha=alpha, color=color))\n",
    "\n",
    "# --- choose a CRS source ---\n",
    "cand = None\n",
    "if P[\"DRAW_BUILDINGS\"] and buildings_gdf is not None and not buildings_gdf.empty:\n",
    "    cand = buildings_gdf\n",
    "elif P[\"DRAW_EDGES\"] and datasets[\"OSM_Edges\"] is not None and not datasets[\"OSM_Edges\"].empty:\n",
    "    cand = datasets[\"OSM_Edges\"]\n",
    "elif P[\"DRAW_NODES\"] and datasets[\"OSM_Nodes\"] is not None and not datasets[\"OSM_Nodes\"].empty:\n",
    "    cand = datasets[\"OSM_Nodes\"]\n",
    "elif P[\"DRAW_REGION\"] and datasets[\"Region_Boundary\"] is not None and not datasets[\"Region_Boundary\"].empty:\n",
    "    cand = datasets[\"Region_Boundary\"]\n",
    "\n",
    "utm_crs = cand.to_crs(4326).estimate_utm_crs()\n",
    "\n",
    "# --- reproject only what we draw ---\n",
    "edges_utm  = datasets[\"OSM_Edges\"].to_crs(utm_crs)       if P[\"DRAW_EDGES\"]   and datasets[\"OSM_Edges\"]   is not None else None\n",
    "nodes_utm  = datasets[\"OSM_Nodes\"].to_crs(utm_crs)       if P[\"DRAW_NODES\"]   and datasets[\"OSM_Nodes\"]   is not None else None\n",
    "bldg_utm   = buildings_gdf.to_crs(utm_crs)               if P[\"DRAW_BUILDINGS\"] and buildings_gdf is not None       else None\n",
    "region_utm = datasets[\"Region_Boundary\"].to_crs(utm_crs) if P[\"DRAW_REGION\"]  and datasets[\"Region_Boundary\"] is not None else None\n",
    "\n",
    "# --- optional zoom (EPSG:4326 → UTM bounds) ---\n",
    "use_zoom = all(v is not None for v in [P[\"lon_min\"], P[\"lon_max\"], P[\"lat_min\"], P[\"lat_max\"]])\n",
    "if use_zoom:\n",
    "    zbox = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    ).to_crs(utm_crs).total_bounds\n",
    "\n",
    "# --- plot ---\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "legend_items = []\n",
    "\n",
    "if region_utm is not None and P[\"DRAW_REGION\"]:\n",
    "    region_utm.boundary.plot(ax=ax, color=P[\"REGION_COLOR\"], linewidth=P[\"REGION_LW\"],\n",
    "                             alpha=P[\"REGION_ALPHA\"], zorder=3)\n",
    "    if P[\"SHOW_LEGEND\"]:\n",
    "        legend_items.append(Line2D([0],[0], color=P[\"REGION_COLOR\"], lw=P[\"REGION_LW\"],\n",
    "                                   label=P[\"REGION_LABEL\"]))\n",
    "\n",
    "if edges_utm is not None and P[\"DRAW_EDGES\"]:\n",
    "    edges_utm.plot(ax=ax, color=P[\"EDGE_COLOR\"], linewidth=P[\"EDGE_LW\"],\n",
    "                   alpha=P[\"EDGE_ALPHA\"], zorder=1)\n",
    "    if P[\"SHOW_LEGEND\"]:\n",
    "        legend_items.append(Line2D([0],[0], color=P[\"EDGE_COLOR\"], lw=P[\"EDGE_LW\"]*5,\n",
    "                                   label=P[\"EDGE_LABEL\"]))\n",
    "\n",
    "if bldg_utm is not None and P[\"DRAW_BUILDINGS\"]:\n",
    "    bldg_utm.plot(ax=ax, color=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "                  linewidth=P[\"BLDG_LW\"], alpha=P[\"BLDG_ALPHA\"], zorder=2)\n",
    "    if P[\"SHOW_LEGEND\"]:\n",
    "        legend_items.append(Patch(facecolor=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "                                  label=P[\"BLDG_LABEL\"]))\n",
    "\n",
    "if nodes_utm is not None and P[\"DRAW_NODES\"]:\n",
    "    nshow = nodes_utm if len(nodes_utm) <= P[\"NODE_MAX_PLOT\"] else nodes_utm.sample(P[\"NODE_MAX_PLOT\"], random_state=0)\n",
    "    nshow.plot(ax=ax, color=P[\"NODE_COLOR\"], markersize=P[\"NODE_SIZE\"],\n",
    "               alpha=P[\"NODE_ALPHA\"], zorder=4)\n",
    "    if P[\"SHOW_LEGEND\"]:\n",
    "        legend_items.append(Line2D([0],[0], marker=\"o\", linestyle=\"None\",\n",
    "                                   markersize=max(4, int((P[\"NODE_SIZE\"]**0.5)/1.5)),\n",
    "                                   markerfacecolor=P[\"NODE_COLOR\"], markeredgecolor=\"none\",\n",
    "                                   label=P[\"NODE_LABEL\"]))\n",
    "\n",
    "if use_zoom:\n",
    "    xmin, ymin, xmax, ymax = zbox\n",
    "    ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"], fontsize=P[\"TITLE_FONTSIZE\"])\n",
    "\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    add_north(ax, x=P[\"NA_X\"], y=P[\"NA_Y\"], length=P[\"NA_LEN\"],\n",
    "              color=P[\"NA_COLOR\"], lw=P[\"NA_LW\"], fs=P[\"NA_FONTSIZE\"], label=P[\"NA_LABEL\"])\n",
    "\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    add_scalebar(ax, dx=P[\"SB_DX\"], units=P[\"SB_UNITS\"], loc=P[\"SB_LOC\"],\n",
    "                 alpha=P[\"SB_BOX_ALPHA\"], color=P[\"SB_COLOR\"])\n",
    "\n",
    "if P[\"SHOW_LEGEND\"] and legend_items:\n",
    "    ax.legend(handles=legend_items, loc=P[\"LEGEND_LOC\"],\n",
    "              frameon=P[\"LEGEND_FRAME\"], facecolor=P[\"LEGEND_FACE\"],\n",
    "              edgecolor=P[\"LEGEND_EDGE\"])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- save ---\n",
    "out_img_dir = Path(r\"./Outputs/Images\"); out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_png = out_img_dir / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "print(f\" Figure saved to: {out_png}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43334b0-c6ba-4fa4-900d-eca0980bc3ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== A7) Summary ===============================\n",
    "\n",
    "def _count(name):\n",
    "    obj = globals().get(name, None)\n",
    "    return 0 if (obj is None or getattr(obj, \"empty\", False)) else len(obj)\n",
    "\n",
    "print(\"\\n===== Section A Summary =====\")\n",
    "print(f\"Buildings (downloaded RAW, pre-clip): {_count('bld_3857_raw')}\")\n",
    "print(f\"Buildings (clipped to AOI):           {_count('bld_3857')}\")\n",
    "print(f\"OSM Edges:                              {_count('edges')}\")\n",
    "print(f\"OSM Nodes:                              {_count('nodes')}\")\n",
    "print(\"==========================================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79eb62-1a6d-4d57-bca9-06e564fd68f0",
   "metadata": {},
   "source": [
    "## B) Calculation of Damaged Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba2b23-7cb9-4335-add6-df00bb9cebf9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== B0) Imports ===============================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import shapes\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.ops import unary_union\n",
    "from shapely.prepared import prep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import yaml\n",
    "import time\n",
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378c366-3cd4-4350-be70-6c520c732124",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== B1) Data, Outputs, and User Parameters ===================\n",
    "\n",
    "# Directories\n",
    "DATA_DIR   = r\"./Data\"\n",
    "OUT_BASE     = r\"./Outputs\"\n",
    "\n",
    "# Fallback to Section A outputs if memory is missing\n",
    "A_OUT_DIR    = os.path.join(OUT_BASE, \"A\")\n",
    "\n",
    "# This section's (B) outputs\n",
    "OUT_DIR      = os.path.join(OUT_BASE, \"B\")\n",
    "IMAGES_DIR   = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Data\n",
    "DPM_PATH = Path(os.path.join(DATA_DIR, require(\"DPM_FILE\", str)))\n",
    "\n",
    "# Outputs\n",
    "EVAL_OUT_SHP      = Path(os.path.join(OUT_DIR, \"Evaluated_Buildings.shp\"))\n",
    "DAMAGED_OUT_SHP   = Path(os.path.join(OUT_DIR, \"Damaged_Buildings.shp\"))\n",
    "UNDAMAGED_OUT_SHP = Path(os.path.join(OUT_DIR, \"Undamaged_Buildings.shp\"))\n",
    "DAMAGED_POLY_PATH = Path(os.path.join(OUT_DIR, \"damaged_polygons_DPM.shp\"))  # for plotting\n",
    "DAMAGED_MASK_TIF  = Path(os.path.join(OUT_DIR, \"AOI_DPM_DamagedMask_ge84.tif\"))\n",
    "\n",
    "# Threshold\n",
    "DPM_THRESHOLD = require(\"DPM_THRESHOLD\", float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59dfec-7be1-497f-8079-978c93835746",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ==================== B2) Load AOI & Buildings =================\n",
    "\n",
    "# AOI polygon (EPSG:4326) — prefer memory from Section A\n",
    "if 'aoi_gdf_ll' not in globals():\n",
    "    # Load from Section A outputs\n",
    "    aoi_path = Path(os.path.join(A_OUT_DIR, \"region_boundary.geojson\"))\n",
    "    if not aoi_path.exists():\n",
    "        raise FileNotFoundError(\"AOI not in memory and region_boundary.geojson not found in Outputs_Final\\\\A.\")\n",
    "    aoi_gdf_ll = gpd.read_file(aoi_path).to_crs(4326)\n",
    "\n",
    "# Buildings — prefer memory\n",
    "if 'bld_3857' in globals() and bld_3857 is not None and not bld_3857.empty:\n",
    "    buildings = bld_3857.copy()\n",
    "else:\n",
    "    buildings_path = Path(os.path.join(A_OUT_DIR, \"buildings_selected_region.shp\"))\n",
    "    if not buildings_path.exists():\n",
    "        raise FileNotFoundError(\"Buildings not in memory and buildings_selected_region.shp not found in Outputs_Final\\\\A.\")\n",
    "    buildings = gpd.read_file(buildings_path)\n",
    "    if buildings.crs is None:\n",
    "        raise ValueError(\"Loaded buildings have no CRS; please re-run Section A.\")\n",
    "\n",
    "# Clean geometries\n",
    "buildings = buildings[~buildings.geometry.is_empty & buildings.geometry.notnull()].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7996049-d437-4baf-a3d6-78ea9d7133ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= B3) Clip DPM raster to AOI =========================\n",
    "with rio.open(DPM_PATH) as src:\n",
    "    AOI_RCRS = aoi_gdf_ll.to_crs(src.crs)\n",
    "    aoi_geom = [AOI_RCRS.union_all().__geo_interface__]\n",
    "    out_img, out_transform = mask(src, aoi_geom, crop=True, all_touched=True)\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"height\": out_img.shape[1],\n",
    "        \"width\" : out_img.shape[2],\n",
    "        \"transform\": out_transform,\n",
    "        \"driver\": \"GTiff\",\n",
    "    })\n",
    "    nd   = src.nodata\n",
    "    rcrs = src.crs\n",
    "\n",
    "tif_clip = Path(os.path.join(OUT_DIR, \"AOI_DPM_Clipped.tif\"))\n",
    "with rio.open(tif_clip, \"w\", **out_meta) as dst:\n",
    "    dst.write(out_img)\n",
    "\n",
    "print(f\" Clipped DPM saved → {tif_clip}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efd1ac-2646-4ffe-a877-2f018ba2a02b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========== B4) Threshold → damaged mask GeoTIFF → polygons =========\n",
    "with rio.open(tif_clip) as src:\n",
    "    arr = src.read(1)\n",
    "    nd  = src.nodata\n",
    "    t   = src.transform\n",
    "    rcrs = src.crs\n",
    "\n",
    "valid = (~np.isnan(arr)) if nd is None else (arr != nd)\n",
    "damage_mask = (valid) & (arr >= DPM_THRESHOLD)\n",
    "damage_mask_u8 = damage_mask.astype(\"uint8\")     # 1 = damaged, 0 = not\n",
    "\n",
    "# Save binary damaged mask\n",
    "mask_meta = out_meta.copy()\n",
    "mask_meta.update({\"count\": 1, \"dtype\": \"uint8\", \"nodata\": 0})\n",
    "with rio.open(DAMAGED_MASK_TIF, \"w\", **mask_meta) as dst:\n",
    "    dst.write(damage_mask_u8, 1)\n",
    "print(f\" Damaged binary mask saved → {DAMAGED_MASK_TIF}\")\n",
    "\n",
    "# Vectorize damaged pixels for plotting\n",
    "dam_polys = [\n",
    "    shape(geom)\n",
    "    for geom, val in shapes(damage_mask_u8, mask=damage_mask_u8.astype(bool), transform=t)\n",
    "    if val == 1\n",
    "]\n",
    "damaged_gdf = gpd.GeoDataFrame(geometry=dam_polys, crs=rcrs) if len(dam_polys) else gpd.GeoDataFrame(geometry=[], crs=rcrs)\n",
    "damaged_gdf.to_file(DAMAGED_POLY_PATH)\n",
    "print(f\" Damaged polygons (for plotting) saved → {DAMAGED_POLY_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0da63-928b-4851-beb8-568589f868b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =========== B5) Tiled Labeling ============\n",
    "\n",
    "print(\"Initializing tiled labeling...\")\n",
    "\n",
    "# Tiling params\n",
    "TILE_M    = require(\"TILE_M\", float)\n",
    "OVERLAP_M = require(\"OVERLAP_M\", float)\n",
    "DISSOLVE_IN_TILE = require(\"DISSOLVE_IN_TILE\", bool)\n",
    "\n",
    "# Read raster\n",
    "print(\"Reading clipped raster...\")\n",
    "with rio.open(tif_clip) as ds:\n",
    "    rcrs     = ds.crs\n",
    "    r_bounds = ds.bounds\n",
    "    nd       = ds.nodata\n",
    "\n",
    "# Prepare buildings\n",
    "print(\"Preparing building footprints...\")\n",
    "buildings_r = buildings.to_crs(rcrs) if buildings.crs != rcrs else buildings.copy()\n",
    "buildings_r = buildings_r[~buildings_r.geometry.is_empty & buildings_r.geometry.notnull()].copy()\n",
    "\n",
    "try:\n",
    "    invalid_mask = ~buildings_r.is_valid\n",
    "    if invalid_mask.any():\n",
    "        print(\"Fixing invalid building geometries...\")\n",
    "        buildings_r.loc[invalid_mask, \"geometry\"] = buildings_r.loc[invalid_mask, \"geometry\"].buffer(0)\n",
    "except Exception:\n",
    "    print(\"Warning: Some building geometries could not be fixed.\")\n",
    "\n",
    "print(f\"Total buildings: {len(buildings_r)}\")\n",
    "\n",
    "# Build tile grid\n",
    "print(\"Building tile grid...\")\n",
    "minx, miny, maxx, maxy = r_bounds\n",
    "xs = np.arange(minx, maxx, TILE_M - OVERLAP_M)\n",
    "ys = np.arange(miny, maxy, TILE_M - OVERLAP_M)\n",
    "\n",
    "tiles = []\n",
    "for x in xs:\n",
    "    x1 = min(x + TILE_M, maxx)\n",
    "    if x1 <= x: continue\n",
    "    for y in ys:\n",
    "        y1 = min(y + TILE_M, maxy)\n",
    "        if y1 <= y: continue\n",
    "        tiles.append((x, y, x1, y1))\n",
    "\n",
    "print(f\"Number of tiles: {len(tiles)}\")\n",
    "\n",
    "damaged_mask_buildings = np.zeros(len(buildings_r), dtype=bool)\n",
    "_ = buildings_r.sindex\n",
    "\n",
    "\n",
    "def _vectorize_damaged_in_bounds(bounds):\n",
    "    print(\"    Extracting damaged pixels...\")\n",
    "    with rio.open(tif_clip) as ds:\n",
    "        win = from_bounds(*bounds, transform=ds.transform)\n",
    "        win = win.intersection(rio.windows.Window(0, 0, ds.width, ds.height))\n",
    "\n",
    "        if win.width <= 0 or win.height <= 0:\n",
    "            print(\"    Tile outside raster bounds. Skipping.\")\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=rcrs)\n",
    "\n",
    "        arr = ds.read(1, window=win)\n",
    "        sub_transform = ds.window_transform(win)\n",
    "\n",
    "        valid = (~np.isnan(arr)) if ds.nodata is None else (arr != ds.nodata)\n",
    "        dmg = (valid) & (arr >= DPM_THRESHOLD)\n",
    "\n",
    "        if not dmg.any():\n",
    "            print(\"    No damaged pixels found in tile.\")\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=rcrs)\n",
    "\n",
    "        print(\"    Vectorizing damaged regions...\")\n",
    "        dam_polys = [\n",
    "            shape(geom) for geom, val in shapes(\n",
    "                dmg.astype(np.uint8), mask=dmg, transform=sub_transform\n",
    "            ) if val == 1\n",
    "        ]\n",
    "\n",
    "        if not dam_polys:\n",
    "            print(\"    No valid polygons produced from damaged pixels.\")\n",
    "            return gpd.GeoDataFrame(geometry=[], crs=rcrs)\n",
    "\n",
    "        if DISSOLVE_IN_TILE:\n",
    "            print(\"    Dissolving polygons within tile...\")\n",
    "            u = unary_union(dam_polys)\n",
    "            geoms = list(u.geoms) if getattr(u, \"geom_type\", \"\") == \"MultiPolygon\" else [u]\n",
    "        else:\n",
    "            geoms = dam_polys\n",
    "\n",
    "        return gpd.GeoDataFrame(geometry=geoms, crs=rcrs)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "for idx, tb in enumerate(tiles, start=1):\n",
    "\n",
    "    print(f\"\\nProcessing tile {idx}/{len(tiles)}...\")\n",
    "    dmg_tile = _vectorize_damaged_in_bounds(tb)\n",
    "\n",
    "    if dmg_tile.empty:\n",
    "        print(\"    No damage polygons in this tile.\")\n",
    "        continue\n",
    "\n",
    "    print(\"    Finding buildings that intersect tile...\")\n",
    "    try:\n",
    "        L, R = buildings_r.sindex.query_bulk(\n",
    "            gpd.GeoSeries([box(*tb)], crs=rcrs), predicate=\"intersects\"\n",
    "        )\n",
    "        if R.size == 0:\n",
    "            print(\"    No buildings found in this tile.\")\n",
    "            continue\n",
    "        cand = buildings_r.iloc[np.unique(R)]\n",
    "    except Exception:\n",
    "        print(\"    Spatial index failed; using fallback method...\")\n",
    "        cand = buildings_r[buildings_r.intersects(box(*tb))]\n",
    "        if cand.empty:\n",
    "            print(\"    No buildings found in fallback method.\")\n",
    "            continue\n",
    "\n",
    "    print(f\"    Candidate buildings: {len(cand)}\")\n",
    "    print(\"    Checking which buildings intersect damaged areas...\")\n",
    "\n",
    "    p = prep(dmg_tile.unary_union)\n",
    "    hit = cand.geometry.apply(p.intersects).to_numpy()\n",
    "\n",
    "    hit_count = int(hit.sum())\n",
    "    if hit_count > 0:\n",
    "        print(f\"    Buildings marked as damaged: {hit_count}\")\n",
    "        damaged_mask_buildings[cand.index.values[hit]] = True\n",
    "    else:\n",
    "        print(\"    No buildings damaged in this tile.\")\n",
    "\n",
    "\n",
    "# Final labeling\n",
    "print(\"\\nAssigning final damage labels...\")\n",
    "\n",
    "buildings_r[\"Damaged\"] = np.where(damaged_mask_buildings, \"yes\", \"no\")\n",
    "damaged_only   = buildings_r[buildings_r[\"Damaged\"] == \"yes\"].copy()\n",
    "undamaged_only = buildings_r[buildings_r[\"Damaged\"] == \"no\"].copy()\n",
    "\n",
    "print(\"Saving outputs...\")\n",
    "buildings_r.to_file(EVAL_OUT_SHP)\n",
    "damaged_only.to_file(DAMAGED_OUT_SHP)\n",
    "undamaged_only.to_file(UNDAMAGED_OUT_SHP)\n",
    "\n",
    "print(f\"Evaluated buildings: {len(buildings_r)}\")\n",
    "print(f\"  Damaged   (≥ {DPM_THRESHOLD}): {len(damaged_only)}\")\n",
    "print(f\"  Undamaged (< {DPM_THRESHOLD}): {len(undamaged_only)}\")\n",
    "print(\"Saved files:\")\n",
    "print(\" \", EVAL_OUT_SHP)\n",
    "print(\" \", DAMAGED_OUT_SHP)\n",
    "print(\" \", UNDAMAGED_OUT_SHP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a629344-6242-47a3-a0e4-f4bda30ec550",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =================== B6) PLOT: BUILDINGS + DAMAGED PIXELS ===================\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Buildings_with_DamagedPixels_LOCAL_UTM.png\",  # output PNG filename\n",
    "\n",
    "    # ---- Optional manual zoom in EPSG:4326 (set all to None for autoscale) ----\n",
    "    \"lon_min\": 36.140,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.165,             # max longitude (None = auto)\n",
    "    \"lat_min\": 36.190,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 36.205,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & labels ----\n",
    "    \"FIGSIZE\": (10, 9),            # figure size in inches (w, h)\n",
    "    \"DPI\": 300,                    # export resolution\n",
    "    \"TITLE\": \"Buildings + Damaged Pixels (Local UTM, ≥ threshold)\",\n",
    "    \"XLABEL\": \"Easting (m)\",\n",
    "    \"YLABEL\": \"Northing (m)\",\n",
    "\n",
    "    # ---- Buildings style ----\n",
    "    \"BLDG_FACE\": \"#9e9e9e\",        # fill color for all buildings\n",
    "    \"BLDG_EDGE\": \"none\",           # outline color\n",
    "    \"BLDG_LW\": 0.2,                # outline width (if not 'none')\n",
    "    \"BLDG_ALPHA\": 1.0,             # layer transparency (0..1)\n",
    "\n",
    "    # ---- Damaged polygons style ----\n",
    "    \"DMG_FACE\": \"red\",             # fill color for damaged polygons\n",
    "    \"DMG_EDGE\": \"none\",            # outline color\n",
    "    \"DMG_ALPHA\": 0.5,              # layer transparency (0..1)\n",
    "\n",
    "    # ---- AOI boundary (optional if available) ----\n",
    "    \"DRAW_AOI\": True,              # draw AOI if aoi_gdf_ll exists\n",
    "    \"AOI_COLOR\": \"black\",          # AOI boundary color\n",
    "    \"AOI_LW\": 1.5,                 # AOI boundary width\n",
    "\n",
    "    # ---- North arrow ----\n",
    "    \"ADD_NORTH_ARROW\": True,       # draw north arrow\n",
    "    \"NA_X\": 0.05,                  # arrow x-position (axes fraction)\n",
    "    \"NA_Y\": 0.15,                  # arrow y-position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,                # arrow length  (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",               # arrow label\n",
    "    \"NA_COLOR\": \"black\",           # arrow color\n",
    "    \"NA_LW\": 2,                    # arrow line width\n",
    "    \"NA_FONTSIZE\": 14,             # 'N' font size\n",
    "\n",
    "    # ---- Scalebar ----\n",
    "    \"ADD_SCALEBAR\": True,          # draw scalebar\n",
    "    \"SB_UNITS\": \"m\",               # scalebar units\n",
    "    \"SB_LOC\": \"lower right\",       # scalebar location\n",
    "    \"SB_BOX_ALPHA\": 0.8,           # scalebar box transparency\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"LEGEND_LOC\": \"upper right\",   # legend location\n",
    "    \"LBL_BUILDINGS\": \"Buildings\",  # legend label for buildings\n",
    "    \"LBL_DAMAGED\": \"Damaged pixels\", # legend label for damaged polygons\n",
    "    \"LBL_AOI\": \"AOI Boundary\"      # legend label for AOI boundary\n",
    "}\n",
    "\n",
    "# ----- Methodology -----\n",
    "\n",
    "# Local UTM from damaged polygons\n",
    "utm_crs = damaged_gdf.to_crs(4326).estimate_utm_crs()\n",
    "\n",
    "# Reproject to local UTM\n",
    "b_all_utm = buildings_r.to_crs(utm_crs)\n",
    "dmg_utm   = damaged_gdf.to_crs(utm_crs)\n",
    "\n",
    "# Optional lon/lat bbox → project to UTM and set frame\n",
    "use_bbox = all(P[k] is not None for k in [\"lon_min\",\"lon_max\",\"lat_min\",\"lat_max\"])\n",
    "if use_bbox:\n",
    "    aoi_ll  = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = aoi_ll.to_crs(utm_crs).total_bounds\n",
    "else:\n",
    "    bounds = [b_all_utm.total_bounds, dmg_utm.total_bounds]\n",
    "    xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "    xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "\n",
    "b_all_utm.plot(ax=ax, color=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "               linewidth=P[\"BLDG_LW\"], alpha=P[\"BLDG_ALPHA\"], zorder=1)\n",
    "dmg_utm.plot(ax=ax, facecolor=P[\"DMG_FACE\"], edgecolor=P[\"DMG_EDGE\"],\n",
    "             alpha=P[\"DMG_ALPHA\"], zorder=2)\n",
    "\n",
    "# Optional AOI boundary\n",
    "if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals():\n",
    "    aoi_gdf_ll.to_crs(utm_crs).boundary.plot(ax=ax, color=P[\"AOI_COLOR\"],\n",
    "                                             linewidth=P[\"AOI_LW\"], zorder=5)\n",
    "\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# North arrow\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "# Scalebar\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"], box_alpha=P[\"SB_BOX_ALPHA\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor=P[\"BLDG_FACE\"], edgecolor=\"none\", label=P[\"LBL_BUILDINGS\"]),\n",
    "    Patch(facecolor=P[\"DMG_FACE\"], edgecolor=\"none\", alpha=P[\"DMG_ALPHA\"], label=P[\"LBL_DAMAGED\"]),\n",
    "]\n",
    "if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals():\n",
    "    legend_elements.append(Line2D([0], [0], color=P[\"AOI_COLOR\"], lw=P[\"AOI_LW\"], label=P[\"LBL_AOI\"]))\n",
    "ax.legend(handles=legend_elements, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "display(Image(filename=out_png))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18e15c-86ff-46a6-87e0-940aacef2c61",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ========== B7) PLOT: DAMAGED vs UNDAMAGED (LOCAL UTM) =========\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Damaged_vs_Undamaged_Buildings_LocalUTM.png\",  # output PNG filename\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326; set all to None for auto extent ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & labels ----\n",
    "    \"FIGSIZE\": (10, 9),              # figure size (w, h) inches\n",
    "    \"DPI\": 300,                      # export resolution\n",
    "    \"TITLE\": \"Buildings: Damaged (red) vs Undamaged (gray) — Local UTM\",\n",
    "    \"XLABEL\": \"Easting (m)\",\n",
    "    \"YLABEL\": \"Northing (m)\",\n",
    "\n",
    "    # ---- Undamaged style ----\n",
    "    \"UND_FACE\": \"#bdbdbd\",           # fill color\n",
    "    \"UND_EDGE\": \"none\",              # outline color\n",
    "    \"UND_LW\": 0.2,                   # outline width\n",
    "    \"UND_ALPHA\": 1.0,                # transparency (0..1)\n",
    "    \"LBL_UND\": \"Undamaged\",          # legend label\n",
    "\n",
    "    # ---- Damaged style ----\n",
    "    \"DAM_FACE\": \"#d73027\",           # fill color\n",
    "    \"DAM_EDGE\": \"none\",              # outline color\n",
    "    \"DAM_LW\": 0.2,                   # outline width\n",
    "    \"DAM_ALPHA\": 1.0,                # transparency (0..1)\n",
    "    \"LBL_DAM\": \"Damaged\",            # legend label\n",
    "\n",
    "    # ---- AOI boundary (optional) ----\n",
    "    \"DRAW_AOI\": True,                # draw AOI boundary (expects aoi_gdf_ll upstream)\n",
    "    \"AOI_COLOR\": \"black\",            # AOI boundary color\n",
    "    \"AOI_LW\": 1.5,                   # AOI boundary width\n",
    "    \"LBL_AOI\": \"AOI Boundary\",       # legend label\n",
    "\n",
    "    # ---- North arrow ----\n",
    "    \"ADD_NORTH_ARROW\": True,         # draw north arrow\n",
    "    \"NA_X\": 0.05,                    # arrow x-position (axes fraction)\n",
    "    \"NA_Y\": 0.15,                    # arrow y-position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,                  # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",                 # arrow text\n",
    "    \"NA_COLOR\": \"black\",             # arrow color\n",
    "    \"NA_LW\": 2,                      # arrow line width\n",
    "    \"NA_FONTSIZE\": 14,               # 'N' font size\n",
    "\n",
    "    # ---- Scalebar ----\n",
    "    \"ADD_SCALEBAR\": True,            # draw scalebar\n",
    "    \"SB_UNITS\": \"m\",                 # scalebar units\n",
    "    \"SB_LOC\": \"lower right\",         # scalebar location\n",
    "    \"SB_BOX_ALPHA\": 0.8,             # scalebar box transparency\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"LEGEND_LOC\": \"upper right\"      # legend placement\n",
    "}\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Choose UTM from labeled layers\n",
    "seed = damaged_only if not damaged_only.empty else undamaged_only\n",
    "utm_crs = seed.to_crs(4326).estimate_utm_crs()\n",
    "\n",
    "# Reproject\n",
    "dam_utm = damaged_only.to_crs(utm_crs)\n",
    "und_utm = undamaged_only.to_crs(utm_crs)\n",
    "\n",
    "# Optional lon/lat bbox → UTM frame\n",
    "use_bbox = all(P[k] is not None for k in (\"lon_min\", \"lon_max\", \"lat_min\", \"lat_max\"))\n",
    "if use_bbox:\n",
    "    aoi_ll = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = aoi_ll.to_crs(utm_crs).total_bounds\n",
    "else:\n",
    "    bounds = [und_utm.total_bounds, dam_utm.total_bounds]\n",
    "    xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "    xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "\n",
    "if not und_utm.empty:\n",
    "    und_utm.plot(ax=ax, color=P[\"UND_FACE\"], edgecolor=P[\"UND_EDGE\"],\n",
    "                 linewidth=P[\"UND_LW\"], alpha=P[\"UND_ALPHA\"], zorder=1)\n",
    "if not dam_utm.empty:\n",
    "    dam_utm.plot(ax=ax, color=P[\"DAM_FACE\"], edgecolor=P[\"DAM_EDGE\"],\n",
    "                 linewidth=P[\"DAM_LW\"], alpha=P[\"DAM_ALPHA\"], zorder=2)\n",
    "\n",
    "# Optional AOI boundary\n",
    "if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals():\n",
    "    aoi_gdf_ll.to_crs(utm_crs).boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"], zorder=5)\n",
    "\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# North arrow\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "# Scalebar\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"], box_alpha=P[\"SB_BOX_ALPHA\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor=P[\"UND_FACE\"], edgecolor=\"none\", label=P[\"LBL_UND\"]),\n",
    "    Patch(facecolor=P[\"DAM_FACE\"], edgecolor=\"none\", label=P[\"LBL_DAM\"]),\n",
    "]\n",
    "if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals():\n",
    "    legend_elements.append(Line2D([0], [0], color=P[\"AOI_COLOR\"], lw=P[\"AOI_LW\"], label=P[\"LBL_AOI\"]))\n",
    "ax.legend(handles=legend_elements, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "display(Image(filename=out_png))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d8b2d-4d74-4f02-ae39-0401e416b9dd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============================== B8) Summary ==============================\n",
    "def _crs_str(crs):\n",
    "    try:\n",
    "        return str(crs) if crs is not None else \"(no CRS)\"\n",
    "    except Exception:\n",
    "        return \"(unknown CRS)\"\n",
    "\n",
    "# Datasets\n",
    "_b  = buildings_r\n",
    "_bd = damaged_only\n",
    "_bu = undamaged_only\n",
    "\n",
    "# OSM nodes/edges\n",
    "if 'nodes' in globals() and nodes is not None and not nodes.empty:\n",
    "    _nodes = nodes\n",
    "else:\n",
    "    npath = Path(os.path.join(A_OUT_DIR, \"osm_nodes.shp\"))\n",
    "    _nodes = gpd.read_file(npath) if npath.exists() else None\n",
    "\n",
    "if 'edges' in globals() and edges is not None and not edges.empty:\n",
    "    _edges = edges\n",
    "else:\n",
    "    epath = Path(os.path.join(A_OUT_DIR, \"osm_edges.shp\"))\n",
    "    _edges = gpd.read_file(epath) if epath.exists() else None\n",
    "\n",
    "# Damaged pixels\n",
    "dam_pixels = 0\n",
    "if DAMAGED_MASK_TIF.exists():\n",
    "    with rio.open(DAMAGED_MASK_TIF) as src:\n",
    "        arr = src.read(1)\n",
    "        dam_pixels = int(np.count_nonzero(arr == 1))\n",
    "        mask_crs = src.crs\n",
    "else:\n",
    "    mask_crs = None\n",
    "\n",
    "print(\"===== Section B Summary (AOI only) =====\")\n",
    "print(f\"Total buildings:           {len(_b):,}\")\n",
    "print(f\"  Damaged (>= threshold):  {len(_bd):,}\")\n",
    "print(f\"  Undamaged:               {len(_bu):,}\")\n",
    "print(f\"Total OSM nodes:           {len(_nodes) if _nodes is not None else 0:,}\")\n",
    "print(f\"Total OSM edges:           {len(_edges) if _edges is not None else 0:,}\")\n",
    "print(f\"Total damaged pixels:      {dam_pixels:,}\")\n",
    "\n",
    "print(\"\\n===== Output files (Section B) =====\")\n",
    "print(\"All Buildings (labeled):   \", EVAL_OUT_SHP)\n",
    "print(\"Damaged Buildings:         \", DAMAGED_OUT_SHP)\n",
    "print(\"Undamaged Buildings:       \", UNDAMAGED_OUT_SHP)\n",
    "print(\"Damaged Pixels (mask):     \", DAMAGED_MASK_TIF)\n",
    "print(\"Damaged Polygons:          \", DAMAGED_POLY_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64642c9-a679-46ff-a8f4-353584ccf84f",
   "metadata": {},
   "source": [
    "## C) Affected Population Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4801da-f706-4371-b63c-4f7056de7222",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== C0) Imports ===============================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import shapes\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "from shapely.geometry import shape, box\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import yaml\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995752b-ceb5-4f55-8418-4afca997978f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== C1) User Options, Data, Outputs =============\n",
    "\n",
    "# Unified directories\n",
    "DATA_DIR = r\"./Data\"\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "\n",
    "# Prior-section fallbacks\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "B_OUT_DIR  = os.path.join(OUT_BASE, \"B\")\n",
    "\n",
    "# This section's outputs\n",
    "OUT_DIR    = os.path.join(OUT_BASE, \"C\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Population raster\n",
    "POP_RASTER = os.path.join(DATA_DIR, require(\"POP_FILE\", str))\n",
    "\n",
    "# Evaluated buildings from Section B\n",
    "EVAL_OUT_SHP = (\n",
    "    EVAL_OUT_SHP\n",
    "    if \"EVAL_OUT_SHP\" in globals()\n",
    "    else Path(os.path.join(B_OUT_DIR, \"Evaluated_Buildings.shp\"))\n",
    ")\n",
    "\n",
    "# Outputs for this section\n",
    "OUT_SHP_VOL      = Path(os.path.join(OUT_DIR, \"Evaluated_Buildings_withVol.shp\"))\n",
    "OUT_SHP_VOL_POP  = Path(os.path.join(OUT_DIR, \"Evaluated_Buildings_withVol_Pop.shp\"))\n",
    "\n",
    "# Height settings\n",
    "HEIGHT_COL     = \"height\"                  # keep as-is unless you prefer to read from config\n",
    "DEFAULT_HEIGHT = optional(\"DEFAULT_HEIGHT\")  # e.g., 3.0 to force a default height (meters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c748c-535d-4352-b1e0-eec8775520a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======== C2) Load AOI & Evaluated Buildings ========\n",
    "\n",
    "# AOI polygon (EPSG:4326)\n",
    "if \"aoi_gdf_ll\" not in globals() or aoi_gdf_ll is None or aoi_gdf_ll.empty:\n",
    "    aoi_path = Path(os.path.join(A_OUT_DIR, \"region_boundary.geojson\"))\n",
    "    if not aoi_path.exists():\n",
    "        raise FileNotFoundError(\"AOI not in memory and region_boundary.geojson not found in Outputs_Final\\\\A.\")\n",
    "    aoi_gdf_ll = gpd.read_file(aoi_path).to_crs(4326)\n",
    "\n",
    "# Evaluated buildings\n",
    "if \"buildings_r\" in globals() and buildings_r is not None and not buildings_r.empty:\n",
    "    b_eval = buildings_r.copy()\n",
    "else:\n",
    "    b_eval = gpd.read_file(EVAL_OUT_SHP)\n",
    "    if b_eval.empty:\n",
    "        raise RuntimeError(\"Evaluated_Buildings.shp is empty.\")\n",
    "    if b_eval.crs is None:\n",
    "        raise ValueError(\"Evaluated_Buildings.shp has no CRS defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e9fe2-fe9a-44d5-8aad-8f1b04db1340",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== C3) Compute Volume (m³) and Save =====================\n",
    "\n",
    "# Ensure AOI strictness\n",
    "try:\n",
    "    b_eval = gpd.overlay(b_eval, aoi_gdf_ll.to_crs(b_eval.crs), how=\"intersection\")\n",
    "except Exception:\n",
    "    b_eval = gpd.sjoin(b_eval, aoi_gdf_ll[[\"geometry\"]].to_crs(b_eval.crs),\n",
    "                       predicate=\"intersects\", how=\"inner\").drop(columns=\"index_right\")\n",
    "\n",
    "# Compute area in m² using a projected CRS (local UTM if needed)\n",
    "if not getattr(b_eval.crs, \"is_projected\", False):\n",
    "    utm_crs = b_eval.to_crs(4326).estimate_utm_crs()\n",
    "    b_area = b_eval.to_crs(utm_crs)\n",
    "else:\n",
    "    b_area = b_eval\n",
    "\n",
    "area_m2 = b_area.geometry.area.values\n",
    "\n",
    "# Heights\n",
    "if HEIGHT_COL in b_eval.columns:\n",
    "    h = pd.to_numeric(b_eval[HEIGHT_COL], errors=\"coerce\").fillna(0.0).to_numpy()\n",
    "elif DEFAULT_HEIGHT is not None:\n",
    "    h = np.full(len(b_eval), float(DEFAULT_HEIGHT), dtype=float)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Height column '{HEIGHT_COL}' not found. \"\n",
    "        f\"Either set HEIGHT_COL correctly or provide DEFAULT_HEIGHT.\"\n",
    "    )\n",
    "\n",
    "# Volume\n",
    "b_eval[\"Volume\"] = area_m2 * h\n",
    "\n",
    "# Save\n",
    "b_eval.to_file(OUT_SHP_VOL)\n",
    "print(f\" Added 'Volume' (m³) and saved → {OUT_SHP_VOL}\")\n",
    "print(f\" Count: {len(b_eval):,} | CRS: {b_eval.crs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02150cfd-4ed9-4b5a-a599-2bdb61969229",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# === C4) AOI Population → Allocate to Buildings by Volume (m³) ===\n",
    "\n",
    "# Ensure Volume-enabled buildings\n",
    "b = b_eval.copy() if \"Volume\" in b_eval.columns else gpd.read_file(OUT_SHP_VOL)\n",
    "if b.empty:\n",
    "    raise RuntimeError(\"Volume-enabled buildings are empty.\")\n",
    "if \"Volume\" not in b.columns:\n",
    "    raise ValueError(\"Expected 'Volume' column in buildings.\")\n",
    "\n",
    "# Clip population raster to AOI and sum\n",
    "with rio.open(POP_RASTER) as src:\n",
    "    aoi_in_rcrs = aoi_gdf_ll.to_crs(src.crs)\n",
    "    aoi_geom = [aoi_in_rcrs.union_all().__geo_interface__]\n",
    "    pop_clip, _ = mask(src, aoi_geom, crop=True, all_touched=True)\n",
    "    pop_arr = pop_clip[0].astype(float)\n",
    "    nodata  = src.nodata\n",
    "    if nodata is not None:\n",
    "        pop_arr = np.where(pop_arr == nodata, 0.0, pop_arr)\n",
    "    pop_arr = np.nan_to_num(pop_arr, nan=0.0)\n",
    "    total_population = int(round(pop_arr.sum()))\n",
    "\n",
    "print(f\" Total population within AOI: {total_population:,}\")\n",
    "\n",
    "# Allocate ∝ Volume\n",
    "vol = pd.to_numeric(b[\"Volume\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "vol[~np.isfinite(vol)] = 0.0\n",
    "vol_sum = float(vol.sum())\n",
    "if vol_sum <= 0:\n",
    "    raise ValueError(\"Total building Volume is zero/invalid; cannot allocate population.\")\n",
    "\n",
    "alloc   = (vol / vol_sum) * total_population\n",
    "pop_int = np.floor(alloc).astype(int)\n",
    "remainder = int(total_population - int(pop_int.sum()))\n",
    "if remainder > 0:\n",
    "    frac = alloc - pop_int\n",
    "    top_idx = np.argsort(frac)[::-1][:remainder]\n",
    "    pop_int[top_idx] += 1\n",
    "\n",
    "b[\"Pop_Est\"] = pop_int  # integer population per building\n",
    "b.to_file(OUT_SHP_VOL_POP)\n",
    "print(f\" Saved buildings with Volume + Pop_Est → {OUT_SHP_VOL_POP}\")\n",
    "print(f\"   Buildings: {len(b):,} | CRS: {b.crs}\")\n",
    "print(f\"   Sum Pop_Est (should match AOI total): {int(b['Pop_Est'].sum()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4f03d2-7ade-43c3-bde7-14b8e782c70a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========== C5) Plot: Affected Population by Building ==========\n",
    "# Preconditions\n",
    "if b.empty:\n",
    "    raise RuntimeError(\"No buildings to plot.\")\n",
    "if \"Damaged\" not in b.columns or \"Pop_Est\" not in b.columns:\n",
    "    raise ValueError(\"Required columns 'Damaged' and 'Pop_Est' missing.\")\n",
    "\n",
    "# --------------------------- USER CONTROLS ---------------------------\n",
    "P = {\n",
    "    \"OUT_NAME\": \"Affected_Population_by_Building.png\",\n",
    "\n",
    "    # Manual zoom in EPSG:4326 (set all to None for auto extent)\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # Figure & labels\n",
    "    \"FIGSIZE\": (10, 9),\n",
    "    \"DPI\": 300,\n",
    "    \"TITLE\": \"Affected Population by Building\",\n",
    "    \"XLABEL\": \"Easting (m)\",\n",
    "    \"YLABEL\": \"Northing (m)\",\n",
    "\n",
    "    # Binning (0–10 … 100+) and palette (11 colors → 11 bins)\n",
    "    \"BIN_MIN\": 0,\n",
    "    \"BIN_MAX\": 100,\n",
    "    \"BIN_STEP\": 10,\n",
    "    \"PALETTE\": [\n",
    "        \"#fee5d9\",\"#fcbba1\",\"#fc9272\",\"#fb6a4a\",\n",
    "        \"#ef3b2c\",\"#cb181d\",\"#a50f15\",\"#67000d\",\n",
    "        \"#4a0010\",\"#2e0006\",\"#1a0004\"\n",
    "    ],\n",
    "\n",
    "    # Styles\n",
    "    \"UND_FACE\": \"white\", \"UND_EDGE\": \"black\", \"UND_LW\": 0.3, \"UND_ALPHA\": 1.0,\n",
    "    \"DAM_EDGE\": \"black\", \"DAM_LW\": 0.2, \"DAM_ALPHA\": 1.0,\n",
    "\n",
    "    # AOI boundary\n",
    "    \"DRAW_AOI\": True, \"AOI_COLOR\": \"black\", \"AOI_LW\": 1.0,\n",
    "\n",
    "    # North arrow & scalebar\n",
    "    \"ADD_NORTH_ARROW\": True, \"NA_X\": 0.05, \"NA_Y\": 0.15, \"NA_LEN\": 0.08,\n",
    "    \"NA_LABEL\": \"N\", \"NA_COLOR\": \"black\", \"NA_LW\": 2, \"NA_FONTSIZE\": 14,\n",
    "    \"ADD_SCALEBAR\": True, \"SB_UNITS\": \"m\", \"SB_LOC\": \"lower right\",\n",
    "\n",
    "    # Legend\n",
    "    \"LEGEND_LOC\": \"upper right\"\n",
    "}\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Reproject to local UTM for plotting in meters\n",
    "utm_crs = b.to_crs(4326).estimate_utm_crs()\n",
    "b_utm   = b.to_crs(utm_crs)\n",
    "dam_utm = b_utm[b_utm[\"Damaged\"] == \"yes\"].copy()\n",
    "und_utm = b_utm[b_utm[\"Damaged\"] == \"no\"].copy()\n",
    "\n",
    "# Create equal-width bins up to BIN_MAX and a 100+ bin\n",
    "edges      = np.arange(P[\"BIN_MIN\"], P[\"BIN_MAX\"] + P[\"BIN_STEP\"], P[\"BIN_STEP\"])\n",
    "edges_ext  = np.append(edges, np.inf)\n",
    "labels     = [f\"{edges[i]}–{edges[i+1]}\" for i in range(len(edges)-1)] + [f\"{P['BIN_MAX']}+\"]\n",
    "\n",
    "dam_utm[\"pop_bin\"] = pd.cut(\n",
    "    dam_utm[\"Pop_Est\"].astype(float),\n",
    "    bins=edges_ext, right=False, labels=labels, include_lowest=True\n",
    ")\n",
    "palette = P[\"PALETTE\"][:len(labels)]\n",
    "\n",
    "# Optional zoom window (lon/lat → UTM)\n",
    "use_bbox = all(P[k] is not None for k in (\"lon_min\", \"lon_max\", \"lat_min\", \"lat_max\"))\n",
    "if use_bbox:\n",
    "    zoom_ll = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = zoom_ll.to_crs(utm_crs).total_bounds\n",
    "else:\n",
    "    xmin, ymin, xmax, ymax = b_utm.total_bounds\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "legend_elems = []\n",
    "\n",
    "# Undamaged outlines\n",
    "if not und_utm.empty:\n",
    "    und_utm.plot(ax=ax, facecolor=P[\"UND_FACE\"], edgecolor=P[\"UND_EDGE\"],\n",
    "                 linewidth=P[\"UND_LW\"], alpha=P[\"UND_ALPHA\"], zorder=1)\n",
    "    legend_elems.append(Patch(facecolor=P[\"UND_FACE\"], edgecolor=P[\"UND_EDGE\"], label=\"Undamaged\"))\n",
    "\n",
    "# Damaged buildings colored by pop_bin\n",
    "for lab, color in zip(labels, palette):\n",
    "    sub = dam_utm[dam_utm[\"pop_bin\"] == lab]\n",
    "    if not sub.empty:\n",
    "        sub.plot(ax=ax, facecolor=color, edgecolor=P[\"DAM_EDGE\"],\n",
    "                 linewidth=P[\"DAM_LW\"], alpha=P[\"DAM_ALPHA\"], zorder=2)\n",
    "        legend_elems.append(Patch(facecolor=color, edgecolor=P[\"DAM_EDGE\"], label=f\"Affected Pop. {lab}\"))\n",
    "\n",
    "# AOI boundary\n",
    "if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals():\n",
    "    aoi_gdf_ll.to_crs(utm_crs).boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"], zorder=4)\n",
    "    legend_elems.append(Line2D([0], [0], color=P[\"AOI_COLOR\"], lw=P[\"AOI_LW\"], label=\"AOI Boundary\"))\n",
    "\n",
    "# Frame & decor\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]),\n",
    "                xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "ax.legend(handles=legend_elems, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\" Saved: {out_png}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cac568-e664-473e-acb2-b02f0cdf7e7e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== C6) Summary ===============================\n",
    "if \"Damaged\" in b.columns and \"Pop_Est\" in b.columns:\n",
    "    affected_pop   = int(b.loc[b[\"Damaged\"] == \"yes\", \"Pop_Est\"].sum())\n",
    "    unaffected_pop = int(b.loc[b[\"Damaged\"] == \"no\",  \"Pop_Est\"].sum())\n",
    "    total_pop      = affected_pop + unaffected_pop\n",
    "\n",
    "    print(\"\\n Population Summary (within AOI):\")\n",
    "    print(f\"   Affected population (Damaged buildings):     {affected_pop:,}\")\n",
    "    print(f\"   Unaffected population (Undamaged buildings): {unaffected_pop:,}\")\n",
    "    print(f\"   Total population (check):                    {total_pop:,}\")\n",
    "else:\n",
    "    print(\" Columns 'Damaged' and/or 'Pop_Est' not found in building dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346d11b-65a7-42b2-8492-067dbaf55e5b",
   "metadata": {},
   "source": [
    "## D) Relief Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42024653-7bbd-4a05-92e1-973a060b7bba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== D0) Imports ===============================\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import geopandas as gpd\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b61bd-431f-48cb-adca-e3a34940bba3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== D1) Data, Outputs, and Constants  =============\n",
    "OUT_BASE    = r\"./Outputs\"\n",
    "C_OUT_DIR   = os.path.join(OUT_BASE, \"C\")\n",
    "IMAGES_DIR  = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Fallback shapefile from Section C (buildings with Volume + Pop_Est + Damaged)\n",
    "C_BLD_POP_SHP = os.path.join(C_OUT_DIR, \"Evaluated_Buildings_withVol_Pop.shp\")\n",
    "\n",
    "# WHO / Sphere-like planning constants (with 10% buffer)\n",
    "GUIDELINES = require(\"GUIDELINES\", dict)\n",
    "\n",
    "# Planning durations\n",
    "DUR_AFFECTED   = require(\"DUR_AFFECTED\", int)   # days\n",
    "DUR_UNAFFECTED = require(\"DUR_UNAFFECTED\", int) # days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7be777-2a2c-4026-b34b-08c4e4cb4e89",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =================== D2) Get population by damage class ======================\n",
    "# Totals for Damaged==yes and Damaged==no.\n",
    "\n",
    "def _load_buildings_memory_or_c():\n",
    "    if \"b\" in globals() and b is not None and not b.empty:\n",
    "        return b\n",
    "    if os.path.exists(C_BLD_POP_SHP):\n",
    "        return gpd.read_file(C_BLD_POP_SHP)\n",
    "    raise FileNotFoundError(\"No buildings with Pop_Est available in memory or at Outputs_Final\\\\C.\")\n",
    "\n",
    "b_src = _load_buildings_memory_or_c()\n",
    "if \"Damaged\" not in b_src.columns or \"Pop_Est\" not in b_src.columns:\n",
    "    raise ValueError(\"Buildings data must include 'Damaged' and 'Pop_Est' columns.\")\n",
    "\n",
    "# Normalize labels and compute class totals\n",
    "b_src[\"Damaged\"] = b_src[\"Damaged\"].astype(str).str.strip().str.lower()\n",
    "affected_pop   = int(pd.to_numeric(b_src.loc[b_src[\"Damaged\"] == \"yes\", \"Pop_Est\"], errors=\"coerce\").fillna(0).sum())\n",
    "unaffected_pop = int(pd.to_numeric(b_src.loc[b_src[\"Damaged\"] == \"no\",  \"Pop_Est\"], errors=\"coerce\").fillna(0).sum())\n",
    "total_pop      = affected_pop + unaffected_pop\n",
    "\n",
    "print(f\" Population — Affected (90d): {affected_pop:,} | Unaffected (14d): {unaffected_pop:,} | Total: {total_pop:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12957c6a-de59-46c9-8d8d-600f2ea8dc80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================== D3) Supply calculators ===========================\n",
    "def calc_water_liters(pop, days):\n",
    "    return pop * GUIDELINES[\"water_l_per_person_per_day\"] * days * GUIDELINES[\"buffer_factor\"]\n",
    "\n",
    "def calc_food_kcal(pop, days):\n",
    "    return pop * GUIDELINES[\"food_kcal_per_person_per_day\"] * days * GUIDELINES[\"buffer_factor\"]\n",
    "\n",
    "def calc_shelter_area(pop):\n",
    "    # Shelter capacity buffer not applied\n",
    "    return pop * GUIDELINES[\"shelter_m2_per_person\"]\n",
    "\n",
    "def calc_iehk_kits(pop, days):\n",
    "    if pop <= 0:\n",
    "        return 0\n",
    "    kits_fraction = (pop / GUIDELINES[\"iehk_pop_served\"]) * (days / GUIDELINES[\"iehk_duration_days\"])\n",
    "    return math.ceil(kits_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313b256-17df-4a57-a901-1ae624f0b377",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =================== D4) Compute Results for both conditions =====================\n",
    "records = []\n",
    "\n",
    "# Affected (90d)\n",
    "aw_liters  = calc_water_liters(affected_pop, DUR_AFFECTED)\n",
    "af_kcal    = calc_food_kcal(affected_pop, DUR_AFFECTED)\n",
    "as_m2      = calc_shelter_area(affected_pop)\n",
    "ai_kits    = calc_iehk_kits(affected_pop, DUR_AFFECTED)\n",
    "\n",
    "records.append({\n",
    "    \"Class\": \"Affected (90d)\", \"Days\": DUR_AFFECTED, \"Population\": affected_pop,\n",
    "    \"Water_L\": aw_liters, \"Water_m3\": aw_liters/1000.0,\n",
    "    \"Food_kcal\": af_kcal, \"Food_Mkcal\": af_kcal/1e6,\n",
    "    \"Shelter_m2\": as_m2, \"IEHK_kits\": ai_kits\n",
    "})\n",
    "\n",
    "# Unaffected (14d)\n",
    "uw_liters  = calc_water_liters(unaffected_pop, DUR_UNAFFECTED)\n",
    "uf_kcal    = calc_food_kcal(unaffected_pop, DUR_UNAFFECTED)\n",
    "us_m2      = calc_shelter_area(unaffected_pop)\n",
    "ui_kits    = calc_iehk_kits(unaffected_pop, DUR_UNAFFECTED)\n",
    "\n",
    "records.append({\n",
    "    \"Class\": \"Unaffected (14d)\", \"Days\": DUR_UNAFFECTED, \"Population\": unaffected_pop,\n",
    "    \"Water_L\": uw_liters, \"Water_m3\": uw_liters/1000.0,\n",
    "    \"Food_kcal\": uf_kcal, \"Food_Mkcal\": uf_kcal/1e6,\n",
    "    \"Shelter_m2\": us_m2, \"IEHK_kits\": ui_kits\n",
    "})\n",
    "\n",
    "df_supply = pd.DataFrame.from_records(records)\n",
    "\n",
    "# Totals for final summary\n",
    "totals = {\n",
    "    \"Population_total\": total_pop,\n",
    "    \"Water_L_total\":   df_supply[\"Water_L\"].sum(),\n",
    "    \"Water_m3_total\":  df_supply[\"Water_m3\"].sum(),\n",
    "    \"Food_kcal_total\": df_supply[\"Food_kcal\"].sum(),\n",
    "    \"Food_Mkcal_total\":df_supply[\"Food_Mkcal\"].sum(),\n",
    "    \"Shelter_m2_total\":df_supply[\"Shelter_m2\"].sum(),\n",
    "    \"IEHK_kits_total\": int(df_supply[\"IEHK_kits\"].sum()),  # already ceil per class\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b1cac2-b73d-4a00-9e34-c72df7dfcc03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= D5) All Bar Charts ===============================\n",
    "def _series_with_total(df, colname):\n",
    "    vals = {\n",
    "        \"Affected (90d)\":   float(df.loc[df[\"Class\"] == \"Affected (90d)\", colname].iloc[0]) if (df[\"Class\"] == \"Affected (90d)\").any() else 0.0,\n",
    "        \"Unaffected (14d)\": float(df.loc[df[\"Class\"] == \"Unaffected (14d)\", colname].iloc[0]) if (df[\"Class\"] == \"Unaffected (14d)\").any() else 0.0,\n",
    "    }\n",
    "    vals[\"Total\"] = vals[\"Affected (90d)\"] + vals[\"Unaffected (14d)\"]\n",
    "    labels = [\"Affected (90d)\", \"Unaffected (14d)\", \"Total\"]\n",
    "    values = [vals[l] for l in labels]\n",
    "    return labels, values\n",
    "\n",
    "\n",
    "def _bar_and_save(labels, values, title, ylabel, fname, value_fmt=\"{:,.0f}\"):\n",
    "    COLORS = {\n",
    "        \"Affected (90d)\": \"#d73027\",   # red\n",
    "        \"Unaffected (14d)\": \"#9e9e9e\", # gray\n",
    "        \"Damaged\": \"#d73027\",\n",
    "        \"Undamaged\": \"#9e9e9e\",\n",
    "        \"Total\": \"#2e2e2e\",            # dark\n",
    "    }\n",
    "    bar_colors = [COLORS.get(l, \"#9e9e9e\") for l in labels]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(labels, values, edgecolor=\"black\", color=bar_colors)\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, h, value_fmt.format(h),\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.title(title, fontsize=12)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_png = Path(IMAGES_DIR) / fname\n",
    "    plt.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    try:\n",
    "        display(Image(filename=str(out_png), width=300))\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(f\" Saved: {out_png}\")\n",
    "\n",
    "#  1) Water (m³)\n",
    "_labels, _vals = _series_with_total(df_supply, \"Water_m3\")\n",
    "_bar_and_save(_labels, _vals, \"Water Required (m³)\", \"Total Water (m³)\",\n",
    "              \"D_Water_required_m3_from_memory.png\", \"{:,.0f}\")\n",
    "\n",
    "#  2) Food (Million kcal)\n",
    "_labels, _vals = _series_with_total(df_supply, \"Food_Mkcal\")\n",
    "_bar_and_save(_labels, _vals, \"Food Required (Million kcal)\", \"Total Food (Million kcal)\",\n",
    "              \"D_Food_required_MillionKcal_from_memory.png\", \"{:,.0f}\")\n",
    "\n",
    "#  3) Shelter (m²)\n",
    "_labels, _vals = _series_with_total(df_supply, \"Shelter_m2\")\n",
    "_bar_and_save(_labels, _vals, \"Shelter Area Needed (m²)\", \"Total Shelter (m²)\",\n",
    "              \"D_Shelter_area_required_m2_from_memory.png\", \"{:,.0f}\")\n",
    "\n",
    "#  4) IEHK kits\n",
    "_labels, _vals = _series_with_total(df_supply, \"IEHK_kits\")\n",
    "_bar_and_save(_labels, _vals, \"Medical IEHK Kits Required\", \"Equivalent IEHK Kits\",\n",
    "              \"D_IEHK_kits_required_from_memory.png\", \"{:,.0f}\")\n",
    "\n",
    "#  5) Buildings: Damaged vs Undamaged + Total\n",
    "_b = b_src if (\"b_src\" in globals() and b_src is not None) else _load_buildings_memory_or_c()\n",
    "_dam = int((_b[\"Damaged\"].astype(str).str.lower() == \"yes\").sum())\n",
    "_und = int((_b[\"Damaged\"].astype(str).str.lower() == \"no\").sum())\n",
    "labels_bld = [\"Damaged\", \"Undamaged\", \"Total\"]\n",
    "vals_bld   = [_dam, _und, _dam + _und]\n",
    "\n",
    "_bar_and_save(labels_bld, vals_bld,\n",
    "              \"Buildings: Damaged vs Undamaged\",\n",
    "              \"Number of Buildings\",\n",
    "              \"D_Buildings_Damaged_vs_Undamaged.png\", \"{:,.0f}\")\n",
    "\n",
    "#  6) Population: Affected vs Unaffected + Total\n",
    "labels_pop = [\"Affected (90d)\", \"Unaffected (14d)\", \"Total\"]\n",
    "vals_pop   = [affected_pop, unaffected_pop, total_pop]\n",
    "\n",
    "_bar_and_save(labels_pop, vals_pop,\n",
    "              \"Population: Affected vs Unaffected\",\n",
    "              \"People\",\n",
    "              \"D_Population_Affected_vs_Unaffected.png\", \"{:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266cbfb-a9d5-4fc1-a916-ae94a5fd41d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= D6) Summary =========================\n",
    "def _fmt(x, unit=\"\"):\n",
    "    if isinstance(x, (int, float)):\n",
    "        return f\"{x:,.0f}{unit}\"\n",
    "    return str(x)\n",
    "\n",
    "print(\"\\n===== HUMANITARIAN SUPPLY SUMMARY  =====\")\n",
    "\n",
    "# Prepare list for export table\n",
    "summary_rows = []\n",
    "\n",
    "# Per horizon (Affected / Unaffected)\n",
    "for _, row in df_supply.iterrows():\n",
    "    cls  = row[\"Class\"]\n",
    "    days = row[\"Days\"]\n",
    "    pop  = int(row[\"Population\"])\n",
    "    summary_rows.append({\n",
    "        \"Category\": cls,\n",
    "        \"People\": pop,\n",
    "        \"Duration_days\": days,\n",
    "        \"Water_L\": round(row[\"Water_L\"], 2),\n",
    "        \"Water_m3\": round(row[\"Water_m3\"], 2),\n",
    "        \"Food_kcal\": round(row[\"Food_kcal\"], 2),\n",
    "        \"Food_Mkcal\": round(row[\"Food_Mkcal\"], 2),\n",
    "        \"Shelter_m2\": round(row[\"Shelter_m2\"], 2),\n",
    "        \"IEHK_kits\": int(row[\"IEHK_kits\"]),\n",
    "    })\n",
    "\n",
    "    print(f\"\\n— {cls} —\")\n",
    "    print(f\"  People:            {_fmt(pop)}\")\n",
    "    print(f\"  Duration:          {days} days\")\n",
    "    print(f\"  Water:             {_fmt(row['Water_L'], ' L')}  ({_fmt(row['Water_m3'])} m³)\")\n",
    "    print(f\"  Food:              {_fmt(row['Food_kcal'])} kcal  ({_fmt(row['Food_Mkcal'])} million kcal)\")\n",
    "    print(f\"  Shelter:           {_fmt(row['Shelter_m2'])} m² (min {_fmt(GUIDELINES['shelter_m2_per_person'])} m²/person)\")\n",
    "    print(f\"  IEHK Kits (ceil):  {_fmt(row['IEHK_kits'])}\")\n",
    "\n",
    "# Totals\n",
    "summary_rows.append({\n",
    "    \"Category\": \"TOTAL\",\n",
    "    \"People\": int(totals[\"Population_total\"]),\n",
    "    \"Duration_days\": \"Mixed (90+14)\",\n",
    "    \"Water_L\": round(totals[\"Water_L_total\"], 2),\n",
    "    \"Water_m3\": round(totals[\"Water_m3_total\"], 2),\n",
    "    \"Food_kcal\": round(totals[\"Food_kcal_total\"], 2),\n",
    "    \"Food_Mkcal\": round(totals[\"Food_Mkcal_total\"], 2),\n",
    "    \"Shelter_m2\": round(totals[\"Shelter_m2_total\"], 2),\n",
    "    \"IEHK_kits\": int(totals[\"IEHK_kits_total\"]),\n",
    "})\n",
    "\n",
    "print(\"\\n— TOTALS (Affected 90d + Unaffected 14d) —\")\n",
    "print(f\"  Total People:      {_fmt(totals['Population_total'])}\")\n",
    "print(f\"  Total Water:       {_fmt(totals['Water_L_total'], ' L')}  ({_fmt(totals['Water_m3_total'])} m³)\")\n",
    "print(f\"  Total Food:        {_fmt(totals['Food_kcal_total'])} kcal  ({_fmt(totals['Food_Mkcal_total'])} million kcal)\")\n",
    "print(f\"  Total Shelter:     {_fmt(totals['Shelter_m2_total'])} m²\")\n",
    "print(f\"  Total IEHK Kits:   {_fmt(totals['IEHK_kits_total'])}\")\n",
    "\n",
    "print(\"\\nAssumptions: 20 L p⁻¹ d⁻¹ water, 2,100 kcal p⁻¹ d⁻¹ food, 4 m² p⁻¹ shelter; \"\n",
    "      \"IEHK = 10 000 people per 90 days; 10 % buffer applied to water & food.\")\n",
    "print(\"Durations: Affected = 90 days, Unaffected = 14 days.\")\n",
    "print(\"================================================================\")\n",
    "\n",
    "# --- Save summary to CSV (under Outputs\\D) ---\n",
    "D_OUT_DIR = Path(OUT_BASE) / \"D\"\n",
    "D_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_summary_csv = D_OUT_DIR / \"D_Supply_Summary_Table.csv\"\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(out_summary_csv, index=False)\n",
    "\n",
    "print(f\" Summary table saved → {out_summary_csv}\")\n",
    "display(df_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c41089-a92b-49a4-8037-ae7706939537",
   "metadata": {},
   "source": [
    "## E) Buffer and Damaged Edge Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06cc10-2f17-49c8-b359-cd66a38ac463",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== E0) Imports ===============================\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "from shapely.prepared import prep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from IPython.display import Image, display\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf638c9-458f-433e-89d9-9ce9d9f21b30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== E1) User Options & Paths ===============================\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "B_OUT_DIR  = os.path.join(OUT_BASE, \"B\")\n",
    "C_OUT_DIR  = os.path.join(OUT_BASE, \"C\")\n",
    "E_OUT_DIR  = os.path.join(OUT_BASE, \"E\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(E_OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# --- User-controllable numerical parameters from Configuration ---\n",
    "HEIGHT_COL        = require(\"HEIGHT_COL\", str)      # building height column\n",
    "BUFFER_FALLBACK_M = require(\"BUFFER_FALLBACK_M\", float)  # meters when height missing\n",
    "SIMPLIFY_TOL_M    = require(\"SIMPLIFY_TOL_M\", float)     # simplify buffers for speed\n",
    "TILE_M            = require(\"TILE_M_E\", float)      # tile side in meters (E section)\n",
    "OVERLAP_M         = require(\"OVERLAP_M_E\", float)   # overlap between tiles\n",
    "\n",
    "# --- Data: damaged buildings ---\n",
    "if 'damaged_only' in globals() and damaged_only is not None and not damaged_only.empty:\n",
    "    bldg_damaged_src = damaged_only.copy()\n",
    "elif 'b' in globals() and b is not None and not b.empty and (\"Damaged\" in b.columns):\n",
    "    bldg_damaged_src = b[b[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "elif 'buildings_r' in globals() and buildings_r is not None and not buildings_r.empty and (\"Damaged\" in buildings_r.columns):\n",
    "    bldg_damaged_src = buildings_r[buildings_r[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "else:\n",
    "    c_eval_pop = os.path.join(C_OUT_DIR, \"Evaluated_Buildings_withVol_Pop.shp\")\n",
    "    if os.path.exists(c_eval_pop):\n",
    "        _tmp = gpd.read_file(c_eval_pop)\n",
    "        if \"Damaged\" not in _tmp.columns:\n",
    "            raise RuntimeError(\"Fallback buildings file lacks 'Damaged' column.\")\n",
    "        bldg_damaged_src = _tmp[_tmp[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "    else:\n",
    "        raise RuntimeError(\"No damaged buildings found (memory/C outputs unavailable).\")\n",
    "\n",
    "if bldg_damaged_src.empty:\n",
    "    raise SystemExit(\"No damaged buildings; nothing to buffer.\")\n",
    "\n",
    "# --- Data: OSM edges ---\n",
    "if 'edges' in globals() and isinstance(edges, gpd.GeoDataFrame) and not edges.empty:\n",
    "    edges_src = edges.copy()\n",
    "else:\n",
    "    edges_path = os.path.join(A_OUT_DIR, \"osm_edges.shp\")\n",
    "    if not os.path.exists(edges_path):\n",
    "        raise RuntimeError(\"OSM edges not found in memory or Outputs_Final\\\\A.\")\n",
    "    edges_src = gpd.read_file(edges_path)\n",
    "    if edges_src is None or edges_src.empty:\n",
    "        raise RuntimeError(\"Loaded edges are empty.\")\n",
    "\n",
    "# --- Output file paths ---\n",
    "EVAL_EDGES_SHP        = Path(os.path.join(E_OUT_DIR, \"Evaluated_Edges.shp\"))\n",
    "DAMAGED_EDGES_SHP     = Path(os.path.join(E_OUT_DIR, \"Damaged_Edges.shp\"))\n",
    "UNDAMAGED_EDGES_SHP   = Path(os.path.join(E_OUT_DIR, \"Undamaged_Edges.shp\"))\n",
    "BUFFER_ISLANDS_GPKG   = Path(os.path.join(E_OUT_DIR, \"Buffer_Damaged_Buildings.gpkg\"))\n",
    "PER_BUILDING_BUFF_GPKG= Path(os.path.join(E_OUT_DIR, \"PerBuilding_Buffers.gpkg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc5851-2caf-4d83-9104-2527cadbdc8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======== E2) Local UTM =========\n",
    "seed_wgs84 = bldg_damaged_src.to_crs(4326)\n",
    "utm_crs = seed_wgs84.estimate_utm_crs()\n",
    "print(\"Local UTM for buffers & edge tests →\", utm_crs)\n",
    "\n",
    "bldg_damaged = bldg_damaged_src.to_crs(utm_crs)\n",
    "edges_utm    = edges_src.to_crs(utm_crs)\n",
    "\n",
    "# Cheap validity repairs\n",
    "try:\n",
    "    inv_b = ~bldg_damaged.is_valid\n",
    "    if inv_b.any():\n",
    "        bldg_damaged.loc[inv_b, \"geometry\"] = bldg_damaged.loc[inv_b, \"geometry\"].buffer(0)\n",
    "    inv_e = ~edges_utm.is_valid\n",
    "    if inv_e.any():\n",
    "        edges_utm.loc[inv_e, \"geometry\"] = edges_utm.loc[inv_e, \"geometry\"].buffer(0)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557998e-dc8d-4ff3-b70c-032e5a65eed3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== E3) Per-building buffers  ==============\n",
    "\n",
    "if HEIGHT_COL in bldg_damaged.columns:\n",
    "    h_m = gpd.pd.to_numeric(bldg_damaged[HEIGHT_COL], errors='coerce')\n",
    "else:\n",
    "    h_m = gpd.pd.Series(np.nan, index=bldg_damaged.index, dtype=float)\n",
    "\n",
    "h_m = h_m.fillna(BUFFER_FALLBACK_M).astype(float)\n",
    "bldg_damaged[\"buf_m\"] = h_m.values\n",
    "print(f\"Buffer stats (m): min={h_m.min():.2f}, median={h_m.median():.2f}, max={h_m.max():.2f}, n={len(h_m)}\")\n",
    "\n",
    "# Geometry-by-geometry buffers\n",
    "per_buffers = [geom.buffer(dist) for geom, dist in zip(bldg_damaged.geometry, bldg_damaged[\"buf_m\"])]\n",
    "per_buffer_gdf = gpd.GeoDataFrame(\n",
    "    bldg_damaged.drop(columns=\"geometry\").copy(),\n",
    "    geometry=per_buffers,\n",
    "    crs=utm_crs\n",
    ")\n",
    "print(f\"Per-building buffers created: {len(per_buffer_gdf)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faece370-214b-43fe-936d-1d55149d9609",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== E4) Dissolve buffers → islands ==============\n",
    "dissolved = unary_union(per_buffer_gdf.geometry.values)\n",
    "islands = list(dissolved.geoms) if getattr(dissolved, \"geom_type\", \"\") == \"MultiPolygon\" else [dissolved]\n",
    "\n",
    "buffer_islands = gpd.GeoDataFrame(\n",
    "    {\"island_id\": range(len(islands))},\n",
    "    geometry=islands,\n",
    "    crs=utm_crs\n",
    ")\n",
    "print(f\"Dissolved islands: {len(buffer_islands)}\")\n",
    "\n",
    "# Optional light simplify for speed\n",
    "buffers_simpl = buffer_islands.copy()\n",
    "buffers_simpl[\"geometry\"] = buffers_simpl.geometry.simplify(SIMPLIFY_TOL_M, preserve_topology=True)\n",
    "\n",
    "# Save QA layers\n",
    "if not buffer_islands.empty: buffer_islands.to_file(BUFFER_ISLANDS_GPKG, driver=\"GPKG\")\n",
    "if not per_buffer_gdf.empty: per_buffer_gdf.to_file(PER_BUILDING_BUFF_GPKG, driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8641a-8653-420d-b71a-b3e8e1c5fb74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===================== E5) Tile the AOI and classify edges ====================\n",
    "if buffers_simpl.empty:\n",
    "    raise SystemExit(\"No buffer islands exist; cannot evaluate edges.\")\n",
    "\n",
    "minx, miny, maxx, maxy = buffers_simpl.total_bounds\n",
    "xs = np.arange(minx, maxx, TILE_M - OVERLAP_M)\n",
    "ys = np.arange(miny, maxy, TILE_M - OVERLAP_M)\n",
    "\n",
    "# Pre-build spatial index\n",
    "_ = edges_utm.sindex\n",
    "edge_damaged_mask = np.zeros(len(edges_utm), dtype=bool)\n",
    "\n",
    "for x in xs:\n",
    "    x1 = min(x + TILE_M, maxx)\n",
    "    if x1 <= x: continue\n",
    "    for y in ys:\n",
    "        y1 = min(y + TILE_M, maxy)\n",
    "        if y1 <= y: continue\n",
    "\n",
    "        tile_box_geom = box(x, y, x1, y1)\n",
    "\n",
    "        # Candidate islands\n",
    "        try:\n",
    "            Lb, Rb = buffers_simpl.sindex.query_bulk(\n",
    "                gpd.GeoSeries([tile_box_geom], crs=utm_crs), predicate=\"intersects\"\n",
    "            )\n",
    "            if Rb.size == 0: \n",
    "                continue\n",
    "            isl_tile = buffers_simpl.iloc[np.unique(Rb)]\n",
    "        except Exception:\n",
    "            isl_tile = buffers_simpl[buffers_simpl.intersects(tile_box_geom)]\n",
    "            if isl_tile.empty: \n",
    "                continue\n",
    "\n",
    "        p = prep(isl_tile.union_all())\n",
    "\n",
    "        # Candidate edges\n",
    "        try:\n",
    "            Le, Re = edges_utm.sindex.query_bulk(\n",
    "                gpd.GeoSeries([tile_box_geom], crs=utm_crs), predicate=\"intersects\"\n",
    "            )\n",
    "            if Re.size == 0:\n",
    "                continue\n",
    "            cand = edges_utm.iloc[np.unique(Re)]\n",
    "        except Exception:\n",
    "            cand = edges_utm[edges_utm.intersects(tile_box_geom)]\n",
    "            if cand.empty: \n",
    "                continue\n",
    "\n",
    "        # Any intersection → damaged\n",
    "        hit = cand.geometry.apply(p.intersects).to_numpy()\n",
    "        if hit.any():\n",
    "            edge_damaged_mask[cand.index.values[hit]] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87115c-7f9a-409b-b73e-84305b925176",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== E6) Build evaluated / damaged / undamaged edge layers ==============\n",
    "edges_eval = edges_utm.copy()\n",
    "edges_eval[\"Damaged\"] = np.where(edge_damaged_mask, \"yes\", \"no\")\n",
    "\n",
    "edges_dmg = edges_eval.loc[edges_eval[\"Damaged\"] == \"yes\"].copy()\n",
    "edges_ok  = edges_eval.loc[edges_eval[\"Damaged\"] == \"no\"].copy()\n",
    "\n",
    "# Keep geometry-only in the split outputs\n",
    "keep_cols = []\n",
    "if keep_cols:\n",
    "    keep_cols = [c for c in keep_cols if c in edges_eval.columns]\n",
    "    edges_dmg = gpd.GeoDataFrame(edges_dmg[keep_cols].copy(), geometry=edges_dmg.geometry, crs=edges_dmg.crs)\n",
    "    edges_ok  = gpd.GeoDataFrame(edges_ok[keep_cols].copy(),  geometry=edges_ok.geometry,  crs=edges_ok.crs)\n",
    "else:\n",
    "    edges_dmg = gpd.GeoDataFrame(geometry=edges_dmg.geometry, crs=edges_dmg.crs)\n",
    "    edges_ok  = gpd.GeoDataFrame(geometry=edges_ok.geometry,  crs=edges_ok.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f188c4d-a934-44bd-9ffe-c27ca5206cbc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== E7) Save edges ===============================\n",
    "edges_eval.to_file(EVAL_EDGES_SHP)\n",
    "edges_dmg.to_file(DAMAGED_EDGES_SHP)\n",
    "edges_ok.to_file(UNDAMAGED_EDGES_SHP)\n",
    "\n",
    "print(f\" Evaluated edges: {len(edges_eval)}\")\n",
    "print(f\"  Damaged   (touches buffer): {len(edges_dmg)}\")\n",
    "print(f\"  Undamaged:                  {len(edges_ok)}\")\n",
    "print(\" Saved:\")\n",
    "print(\"  \", EVAL_EDGES_SHP)\n",
    "print(\"  \", DAMAGED_EDGES_SHP)\n",
    "print(\"  \", UNDAMAGED_EDGES_SHP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c69f9-a25b-40bd-884e-e4dffe30bce3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============ E8) Plot: Buffers, Buildings, Damaged (Local UTM) ============\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Buffer_Zones.png\",        # output PNG filename (saved under IMAGES_DIR)\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326 (set all to None for auto extent) ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & labels ----\n",
    "    \"FIGSIZE\": (10, 9),                    # figure size (w, h) inches\n",
    "    \"DPI\": 300,                            # export resolution\n",
    "    \"TITLE\": \"Buffer Zones, Buildings, and Damaged Buildings\",\n",
    "    \"XLABEL\": \"Easting (m)\",               # x-axis label (projected meters)\n",
    "    \"YLABEL\": \"Northing (m)\",              # y-axis label (projected meters)\n",
    "\n",
    "    # ---- Buffer polygons style ----\n",
    "    \"BUF_FACE\": \"black\",                   # buffer fill color\n",
    "    \"BUF_EDGE\": \"none\",                    # buffer outline color\n",
    "    \"BUF_ALPHA\": 0.5,                      # buffer transparency\n",
    "\n",
    "    # ---- All buildings (context) ----\n",
    "    \"BLDG_FACE\": \"white\",                  # building fill color\n",
    "    \"BLDG_EDGE\": \"black\",                  # building outline color\n",
    "    \"BLDG_LW\": 0.3,                        # building outline width\n",
    "    \"BLDG_ALPHA\": 1.0,                     # building transparency\n",
    "\n",
    "    # ---- Damaged buildings ----\n",
    "    \"DAM_FACE\": \"#d73027\",                 # damaged fill color\n",
    "    \"DAM_EDGE\": \"black\",                   # damaged outline color\n",
    "    \"DAM_LW\": 0.2,                         # damaged outline width\n",
    "    \"DAM_ALPHA\": 1.0,                      # damaged transparency\n",
    "\n",
    "    # ---- AOI boundary (optional) ----\n",
    "    \"DRAW_AOI\": True,                      # draw AOI boundary (expects aoi_gdf_ll upstream)\n",
    "    \"AOI_COLOR\": \"black\",                  # AOI line color\n",
    "    \"AOI_LW\": 1.0,                         # AOI line width\n",
    "    \"LBL_AOI\": \"AOI Boundary\",             # legend label\n",
    "\n",
    "    # ---- North arrow & scalebar ----\n",
    "    \"ADD_NORTH_ARROW\": True,               # draw north arrow\n",
    "    \"NA_X\": 0.05, \"NA_Y\": 0.15,            # arrow position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,                        # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",                       # arrow text\n",
    "    \"NA_COLOR\": \"black\",                   # arrow color\n",
    "    \"NA_LW\": 2,                            # arrow line width\n",
    "    \"NA_FONTSIZE\": 14,                     # 'N' font size\n",
    "    \"ADD_SCALEBAR\": True,                  # draw scalebar\n",
    "    \"SB_UNITS\": \"m\",                       # scalebar units\n",
    "    \"SB_LOC\": \"lower right\",               # scalebar location\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"LBL_BUFFERS\": \"Buffer zones\",\n",
    "    \"LBL_BUILDINGS\": \"Buildings\",\n",
    "    \"LBL_DAMAGED\": \"Damaged buildings\",\n",
    "    \"LEGEND_LOC\": \"upper right\"            # legend placement\n",
    "}\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Buildings \"Damaged\"\n",
    "if 'b' in globals() and isinstance(b, gpd.GeoDataFrame) and not b.empty and (\"Damaged\" in b.columns):\n",
    "    b_src = b.copy()\n",
    "elif 'buildings_r' in globals() and isinstance(buildings_r, gpd.GeoDataFrame) and not buildings_r.empty and (\"Damaged\" in buildings_r.columns):\n",
    "    b_src = buildings_r.copy()\n",
    "else:\n",
    "    eval_b = os.path.join(B_OUT_DIR, \"Evaluated_Buildings.shp\")\n",
    "    if not os.path.exists(eval_b):\n",
    "        raise RuntimeError(\"No evaluated buildings found for plotting.\")\n",
    "    b_src = gpd.read_file(eval_b)\n",
    "    if \"Damaged\" not in b_src.columns:\n",
    "        raise ValueError(\"Loaded buildings file has no 'Damaged' column.\")\n",
    "\n",
    "# Buffers fallback to per-building\n",
    "buffers_src = buffer_islands if 'buffer_islands' in globals() else per_buffer_gdf\n",
    "if buffers_src is None or buffers_src.empty:\n",
    "    raise RuntimeError(\"No buffer polygons found for plotting.\")\n",
    "\n",
    "# Optional AOI\n",
    "aoi_src = aoi_gdf_ll if 'aoi_gdf_ll' in globals() else None\n",
    "\n",
    "# Reproject to local UTM\n",
    "seed = buffers_src if not buffers_src.empty else b_src\n",
    "utm_plot    = seed.to_crs(4326).estimate_utm_crs()\n",
    "b_utm       = b_src.to_crs(utm_plot)\n",
    "buffers_utm = buffers_src.to_crs(utm_plot)\n",
    "aoi_utm     = aoi_src.to_crs(utm_plot) if isinstance(aoi_src, gpd.GeoDataFrame) else None\n",
    "dam_utm     = b_utm[b_utm[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "\n",
    "# Frame\n",
    "use_bbox = all(P[k] is not None for k in (\"lon_min\",\"lon_max\",\"lat_min\",\"lat_max\"))\n",
    "if use_bbox:\n",
    "    aoi_ll_zoom = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = aoi_ll_zoom.to_crs(utm_plot).total_bounds\n",
    "else:\n",
    "    bounds = []\n",
    "    if not b_utm.empty:       bounds.append(b_utm.total_bounds)\n",
    "    if not buffers_utm.empty: bounds.append(buffers_utm.total_bounds)\n",
    "    if aoi_utm is not None and not aoi_utm.empty: bounds.append(aoi_utm.total_bounds)\n",
    "    xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "    xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "legend_elems = []\n",
    "\n",
    "# Buffers\n",
    "buffers_utm.plot(ax=ax, facecolor=P[\"BUF_FACE\"], edgecolor=P[\"BUF_EDGE\"],\n",
    "                 alpha=P[\"BUF_ALPHA\"], zorder=1)\n",
    "legend_elems.append(Patch(facecolor=P[\"BUF_FACE\"], edgecolor=P[\"BUF_EDGE\"],\n",
    "                          alpha=P[\"BUF_ALPHA\"], label=P[\"LBL_BUFFERS\"]))\n",
    "\n",
    "# All buildings\n",
    "b_utm.plot(ax=ax, facecolor=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "           linewidth=P[\"BLDG_LW\"], alpha=P[\"BLDG_ALPHA\"], zorder=2)\n",
    "legend_elems.append(Patch(facecolor=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "                          label=P[\"LBL_BUILDINGS\"]))\n",
    "\n",
    "# Damaged buildings\n",
    "dam_utm.plot(ax=ax, facecolor=P[\"DAM_FACE\"], edgecolor=P[\"DAM_EDGE\"],\n",
    "             linewidth=P[\"DAM_LW\"], alpha=P[\"DAM_ALPHA\"], zorder=3)\n",
    "legend_elems.append(Patch(facecolor=P[\"DAM_FACE\"], edgecolor=P[\"DAM_EDGE\"],\n",
    "                          label=P[\"LBL_DAMAGED\"]))\n",
    "\n",
    "# AOI boundary\n",
    "if P[\"DRAW_AOI\"] and aoi_utm is not None and not aoi_utm.empty:\n",
    "    aoi_utm.boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"], zorder=4)\n",
    "    legend_elems.append(Line2D([0],[0], color=P[\"AOI_COLOR\"], lw=P[\"AOI_LW\"], label=P[\"LBL_AOI\"]))\n",
    "\n",
    "# Frame + decor\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "\n",
    "ax.legend(handles=legend_elems, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "# Save + show\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\" Saved: {out_png}\")\n",
    "display(Image(filename=str(out_png)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d4a47-bae1-4faa-884c-07a974745581",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== E9) Summary ===============================\n",
    "n_eval   = len(edges_eval) if 'edges_eval' in globals() else 0\n",
    "n_dmg    = len(edges_dmg)  if 'edges_dmg'  in globals() else 0\n",
    "n_ok     = len(edges_ok)   if 'edges_ok'   in globals() else 0\n",
    "n_island = len(buffer_islands) if 'buffer_islands' in globals() else 0\n",
    "avg_buf  = float(per_buffer_gdf[\"buf_m\"].mean()) if ('per_buffer_gdf' in globals() and \"buf_m\" in per_buffer_gdf.columns) else float(\"nan\")\n",
    "\n",
    "print(\"\\n===== Section E Summary =====\")\n",
    "print(f\"Total edges evaluated:        {n_eval:,}\")\n",
    "print(f\"  Damaged edges (touching):   {n_dmg:,}\")\n",
    "print(f\"  Undamaged edges:            {n_ok:,}\")\n",
    "print(f\"Buffer islands (dissolved):   {n_island:,}\")\n",
    "print(f\"Per-building buffer (m):      mean ≈ {avg_buf:.2f}\")\n",
    "print(\"\\nOutputs:\")\n",
    "print(f\"  Evaluated_Edges:            {EVAL_EDGES_SHP}\")\n",
    "print(f\"  Damaged_Edges:              {DAMAGED_EDGES_SHP}\")\n",
    "print(f\"  Undamaged_Edges:            {UNDAMAGED_EDGES_SHP}\")\n",
    "print(f\"  Buffer islands (QA, gpkg):  {BUFFER_ISLANDS_GPKG}\")\n",
    "print(f\"  Per-building buffers (gpkg):{PER_BUILDING_BUFF_GPKG}\")\n",
    "print(f\"  Figure:                     {Path(IMAGES_DIR) / 'Buffer_Zones.png'}\")\n",
    "print(\"========================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb144fa-cf7a-499f-8456-1c10fdf5e81d",
   "metadata": {},
   "source": [
    "## F) Tunnels and Bridges Damage Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3f2a6-d31f-409c-8a9a-8cd3c84e1ada",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== F0) Imports ===============================\n",
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.prepared import prep\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from IPython.display import Image, display\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fdd9a-fc7f-4143-ad93-c89b1b0dc425",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== F1) User Options & Paths ======================\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "B_OUT_DIR  = os.path.join(OUT_BASE, \"B\")\n",
    "C_OUT_DIR  = os.path.join(OUT_BASE, \"C\")\n",
    "E_OUT_DIR  = os.path.join(OUT_BASE, \"E\")\n",
    "F_OUT_DIR  = os.path.join(OUT_BASE, \"F\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(F_OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# --- Data ---\n",
    "# Evaluated edges (with Damaged yes/no) from Section E\n",
    "if 'edges_eval' in globals() and isinstance(edges_eval, gpd.GeoDataFrame) and not edges_eval.empty:\n",
    "    edges_eval_src = edges_eval.copy()\n",
    "elif 'EVAL_EDGES_SHP' in globals() and Path(EVAL_EDGES_SHP).exists():\n",
    "    edges_eval_src = gpd.read_file(EVAL_EDGES_SHP)\n",
    "else:\n",
    "    _eval_e = Path(E_OUT_DIR) / \"Evaluated_Edges.shp\"\n",
    "    if _eval_e.exists():\n",
    "        edges_eval_src = gpd.read_file(_eval_e)\n",
    "    else:\n",
    "        raise RuntimeError(\"Evaluated edges not found. Run Section E first.\")\n",
    "\n",
    "# Damaged pixels vector\n",
    "if 'damaged_gdf' in globals() and isinstance(damaged_gdf, gpd.GeoDataFrame) and not damaged_gdf.empty:\n",
    "    dmg_vec_pref = damaged_gdf.copy()\n",
    "else:\n",
    "    dmg_vec_pref = None\n",
    "\n",
    "# Binary damaged mask GeoTIFF from Section B\n",
    "DAMAGED_MASK_TIF = globals().get(\"DAMAGED_MASK_TIF\", Path(C_OUT_DIR) / \"AOI_DPM_DamagedMask_ge84.tif\")\n",
    "\n",
    "# --- Output file paths ---\n",
    "EVAL_EDGES_TB_SHP       = Path(F_OUT_DIR) / \"Evaluated_Edges_withTunnels_Bridges.shp\"\n",
    "DAMAGED_EDGES_TB_SHP    = Path(F_OUT_DIR) / \"Damaged_Edges_withTunnels_Bridges.shp\"\n",
    "UNDAMAGED_EDGES_TB_SHP  = Path(F_OUT_DIR) / \"Undamaged_Edges_withTunnels_Bridges.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30380e62-e13c-4098-8100-56a0bfd79fd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =========== F2) Damaged pixels vector memory ===========\n",
    "if dmg_vec_pref is not None and not dmg_vec_pref.empty:\n",
    "    dmg_vec = dmg_vec_pref.to_crs(edges_eval_src.crs) if dmg_vec_pref.crs != edges_eval_src.crs else dmg_vec_pref.copy()\n",
    "else:\n",
    "    if not (isinstance(DAMAGED_MASK_TIF, (str, Path)) and Path(DAMAGED_MASK_TIF).exists()):\n",
    "        print(\"No damaged pixels available; skipping TB override.\")\n",
    "        edges_eval_tb = edges_eval_src.copy()\n",
    "        edges_dmg_tb  = edges_eval_tb.loc[edges_eval_tb[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "        edges_ok_tb   = edges_eval_tb.loc[edges_eval_tb[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "\n",
    "        edges_eval_tb.to_file(EVAL_EDGES_TB_SHP)\n",
    "        gpd.GeoDataFrame(geometry=edges_dmg_tb.geometry, crs=edges_dmg_tb.crs).to_file(DAMAGED_EDGES_TB_SHP)\n",
    "        gpd.GeoDataFrame(geometry=edges_ok_tb.geometry,  crs=edges_ok_tb.crs).to_file(UNDAMAGED_EDGES_TB_SHP)\n",
    "\n",
    "        print(f\" Evaluated edges: {len(edges_eval_tb)}\")\n",
    "        print(f\"  Damaged   (buffer OR TB override): {len(edges_dmg_tb)}\")\n",
    "        print(f\"  Undamaged:                         {len(edges_ok_tb)}\")\n",
    "        print(\" Saved:\\n   \", EVAL_EDGES_TB_SHP, \"\\n   \", DAMAGED_EDGES_TB_SHP, \"\\n   \", UNDAMAGED_EDGES_TB_SHP)\n",
    "    else:\n",
    "        with rio.open(DAMAGED_MASK_TIF) as ds:\n",
    "            arr = ds.read(1)\n",
    "            t   = ds.transform\n",
    "            mask = (arr == 1)\n",
    "            if not mask.any():\n",
    "                dmg_vec = gpd.GeoDataFrame(geometry=[], crs=ds.crs)\n",
    "            else:\n",
    "                dam_polys = [shape(geom) for geom, val in shapes(mask.astype(np.uint8), mask=mask, transform=t) if val == 1]\n",
    "                dmg_vec = gpd.GeoDataFrame(geometry=dam_polys, crs=ds.crs)\n",
    "\n",
    "        if dmg_vec.crs is not None and dmg_vec.crs != edges_eval_src.crs:\n",
    "            dmg_vec = dmg_vec.to_crs(edges_eval_src.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d06c8-8f8a-44ab-a481-cf03c9ca7b92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =========== F3) Identify tunnel/bridge edges (robust yes/no parsing) ===========\n",
    "def _yes_like(series):\n",
    "    s = series.astype(str).str.lower().str.strip()\n",
    "    return s.isin([\"yes\", \"true\", \"1\", \"y\", \"t\"])\n",
    "\n",
    "has_bridge = _yes_like(edges_eval_src[\"bridge\"]) if \"bridge\" in edges_eval_src.columns else gpd.pd.Series(False, index=edges_eval_src.index)\n",
    "has_tunnel = _yes_like(edges_eval_src[\"tunnel\"]) if \"tunnel\" in edges_eval_src.columns else gpd.pd.Series(False, index=edges_eval_src.index)\n",
    "tb_mask = has_bridge | has_tunnel\n",
    "tb_edges = edges_eval_src.loc[tb_mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc5f1d-5128-4bd6-9e40-5da4383a1b8d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======= F4) TB ∩ damage intersects → indices to force as Damaged =======\n",
    "if dmg_vec is None or dmg_vec.empty or tb_edges.empty:\n",
    "    print(\"No TB edges and/or no damaged pixels; using original edge classifications.\")\n",
    "    tb_hit_idx = gpd.pd.Index([])\n",
    "else:\n",
    "    try:\n",
    "        inv_tb = ~tb_edges.is_valid\n",
    "        if inv_tb.any():\n",
    "            tb_edges.loc[inv_tb, \"geometry\"] = tb_edges.loc[inv_tb, \"geometry\"].buffer(0)\n",
    "        inv_d = ~dmg_vec.is_valid\n",
    "        if inv_d.any():\n",
    "            dmg_vec.loc[inv_d, \"geometry\"] = dmg_vec.loc[inv_d, \"geometry\"].buffer(0)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    _ = dmg_vec.sindex\n",
    "    hits = gpd.sjoin(tb_edges[[\"geometry\"]], dmg_vec[[\"geometry\"]], how=\"inner\", predicate=\"intersects\")\n",
    "    tb_hit_idx = hits.index.unique()\n",
    "\n",
    "print(f\"Tunnel/Bridge edges total: {len(tb_edges)} | intersecting damaged pixels: {len(tb_hit_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c82bdc-4fc7-4fc2-8d3c-e7ca5a4a15af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ================== F5) Apply overrides → split → save ==================\n",
    "edges_eval_tb = edges_eval_src.copy()\n",
    "if len(tb_hit_idx) > 0:\n",
    "    edges_eval_tb.loc[tb_hit_idx, \"Damaged\"] = \"yes\"\n",
    "\n",
    "edges_dmg_tb = edges_eval_tb.loc[edges_eval_tb[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "edges_ok_tb  = edges_eval_tb.loc[edges_eval_tb[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "\n",
    "# Save\n",
    "edges_eval_tb.to_file(EVAL_EDGES_TB_SHP)\n",
    "gpd.GeoDataFrame(geometry=edges_dmg_tb.geometry, crs=edges_dmg_tb.crs).to_file(DAMAGED_EDGES_TB_SHP)\n",
    "gpd.GeoDataFrame(geometry=edges_ok_tb.geometry,  crs=edges_ok_tb.crs).to_file(UNDAMAGED_EDGES_TB_SHP)\n",
    "\n",
    "print(f\" Evaluated edges: {len(edges_eval_tb)}\")\n",
    "print(f\"  Damaged   (buffer OR TB override): {len(edges_dmg_tb)}\")\n",
    "print(f\"  Undamaged:                         {len(edges_ok_tb)}\")\n",
    "print(\" Saved:\")\n",
    "print(\"   \", EVAL_EDGES_TB_SHP)\n",
    "print(\"   \", DAMAGED_EDGES_TB_SHP)\n",
    "print(\"   \", UNDAMAGED_EDGES_TB_SHP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f5205-466f-4d04-b48c-1149a574fe7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ================== F6) Plot: Damaged Edges, TB, Buildings ==================\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Damaged_Edges_Tunnels_Bridges.png\",  # output PNG name (saved to IMAGES_DIR)\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326 (set all to None for auto extent) ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & labels ----\n",
    "    \"FIGSIZE\": (11, 10),    # figure size (w, h) inches\n",
    "    \"DPI\": 300,             # export resolution\n",
    "    \"TITLE\": \"Damaged Edges, Tunnels/Bridges, and Buildings\",\n",
    "    \"XLABEL\": \"Easting (m)\",   # projected meters\n",
    "    \"YLABEL\": \"Northing (m)\",  # projected meters\n",
    "\n",
    "    # ---- Base edges (all) ----\n",
    "    \"EDGE_ALL_COLOR\": \"#9e9e9e\",  # color for all edges\n",
    "    \"EDGE_ALL_LW\": 0.6,           # linewidth\n",
    "    \"EDGE_ALL_ALPHA\": 1.0,        # transparency\n",
    "    \"LBL_EDGE_ALL\": \"All edges\",  # legend label\n",
    "\n",
    "    # ---- Damaged edges ----\n",
    "    \"EDGE_DMG_COLOR\": \"black\",\n",
    "    \"EDGE_DMG_LW\": 1.0,\n",
    "    \"EDGE_DMG_ALPHA\": 1.0,\n",
    "    \"LBL_EDGE_DMG\": \"Damaged edges\",\n",
    "\n",
    "    # ---- Damaged tunnels/bridges subset ----\n",
    "    \"TB_COLOR\": \"#1f78b4\",\n",
    "    \"TB_LW\": 1.6,\n",
    "    \"TB_ALPHA\": 1.0,\n",
    "    \"LBL_TB\": \"Damaged tunnels/bridges\",\n",
    "\n",
    "    # ---- Buildings (all) ----\n",
    "    \"BLDG_FACE\": \"white\",\n",
    "    \"BLDG_EDGE\": \"black\",\n",
    "    \"BLDG_LW\": 0.3,\n",
    "    \"BLDG_ALPHA\": 1.0,\n",
    "    \"LBL_BLDG\": \"Buildings\",\n",
    "\n",
    "    # ---- Damaged buildings ----\n",
    "    \"BLDG_DAM_FACE\": \"#d73027\",\n",
    "    \"BLDG_DAM_EDGE\": \"black\",\n",
    "    \"BLDG_DAM_LW\": 0.2,\n",
    "    \"BLDG_DAM_ALPHA\": 1.0,\n",
    "    \"LBL_BLDG_DAM\": \"Damaged buildings\",\n",
    "\n",
    "    # ---- AOI boundary (optional if provided upstream) ----\n",
    "    \"DRAW_AOI\": True,\n",
    "    \"AOI_COLOR\": \"black\",\n",
    "    \"AOI_LW\": 1.0,\n",
    "    \"LBL_AOI\": \"AOI boundary\",\n",
    "\n",
    "    # ---- North arrow & scalebar ----\n",
    "    \"ADD_NORTH_ARROW\": True,\n",
    "    \"NA_X\": 0.05, \"NA_Y\": 0.15,   # arrow position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,               # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",\n",
    "    \"NA_COLOR\": \"black\", \"NA_LW\": 2, \"NA_FONTSIZE\": 14,\n",
    "    \"ADD_SCALEBAR\": True,         # scalebar\n",
    "    \"SB_UNITS\": \"m\",\n",
    "    \"SB_LOC\": \"lower right\",      # scalebar location\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"LEGEND_LOC\": \"upper right\"   # legend placement\n",
    "}\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Edges (prefer TB-evaluated, then evaluated, then basic evaluated set)\n",
    "if 'edges_eval_tb' in globals() and isinstance(edges_eval_tb, gpd.GeoDataFrame) and not edges_eval_tb.empty:\n",
    "    e_src = edges_eval_tb.copy()\n",
    "elif 'edges_eval_src' in globals() and isinstance(edges_eval_src, gpd.GeoDataFrame) and not edges_eval_src.empty:\n",
    "    e_src = edges_eval_src.copy()\n",
    "elif EVAL_EDGES_TB_SHP.exists():\n",
    "    e_src = gpd.read_file(EVAL_EDGES_TB_SHP)\n",
    "else:\n",
    "    e_src = gpd.read_file(EVAL_EDGES_SHP) if 'EVAL_EDGES_SHP' in globals() and Path(EVAL_EDGES_SHP).exists() else None\n",
    "    if e_src is None:\n",
    "        raise RuntimeError(\"No evaluated edges available for plotting.\")\n",
    "if \"Damaged\" not in e_src.columns:\n",
    "    raise ValueError(\"Edges layer must include 'Damaged'.\")\n",
    "\n",
    "# Buildings (must have Damaged)\n",
    "if 'b' in globals() and isinstance(b, gpd.GeoDataFrame) and not b.empty and (\"Damaged\" in b.columns):\n",
    "    b_src = b.copy()\n",
    "elif 'buildings_r' in globals() and isinstance(buildings_r, gpd.GeoDataFrame) and not buildings_r.empty and (\"Damaged\" in buildings_r.columns):\n",
    "    b_src = buildings_r.copy()\n",
    "elif 'EVAL_OUT_SHP' in globals() and Path(EVAL_OUT_SHP).exists():\n",
    "    b_src = gpd.read_file(EVAL_OUT_SHP)\n",
    "    if \"Damaged\" not in b_src.columns:\n",
    "        raise ValueError(\"Loaded buildings file has no 'Damaged' column.\")\n",
    "else:\n",
    "    _b_eval = Path(B_OUT_DIR) / \"Evaluated_Buildings.shp\"\n",
    "    if not _b_eval.exists():\n",
    "        raise RuntimeError(\"No evaluated buildings found for plotting.\")\n",
    "    b_src = gpd.read_file(_b_eval)\n",
    "\n",
    "aoi_src = aoi_gdf_ll if 'aoi_gdf_ll' in globals() else None\n",
    "\n",
    "# Common local UTM\n",
    "seed   = b_src if not b_src.empty else e_src\n",
    "utm_crs = seed.to_crs(4326).estimate_utm_crs()\n",
    "e_utm   = e_src.to_crs(utm_crs)\n",
    "b_utm   = b_src.to_crs(utm_crs)\n",
    "aoi_utm = aoi_src.to_crs(utm_crs) if isinstance(aoi_src, gpd.GeoDataFrame) else None\n",
    "\n",
    "# Subsets\n",
    "edge_is_dmg   = e_utm[\"Damaged\"].astype(str).str.lower().eq(\"yes\")\n",
    "edges_all_utm = e_utm\n",
    "edges_dmg_utm = e_utm[edge_is_dmg].copy()\n",
    "\n",
    "def _yes_like(series):\n",
    "    s = series.astype(str).str.lower().str.strip()\n",
    "    return s.isin([\"yes\", \"true\", \"1\", \"y\", \"t\"])\n",
    "\n",
    "has_bridge = _yes_like(e_utm[\"bridge\"]) if \"bridge\" in e_utm.columns else gpd.pd.Series(False, index=e_utm.index)\n",
    "has_tunnel = _yes_like(e_utm[\"tunnel\"]) if \"tunnel\" in e_utm.columns else gpd.pd.Series(False, index=e_utm.index)\n",
    "tb_dmg_utm = e_utm[(edge_is_dmg) & (has_bridge | has_tunnel)].copy()\n",
    "\n",
    "b_dmg = b_utm[b_utm[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "\n",
    "# Optional lon/lat zoom → UTM frame\n",
    "use_bbox = all(P[k] is not None for k in (\"lon_min\",\"lon_max\",\"lat_min\",\"lat_max\"))\n",
    "if use_bbox:\n",
    "    aoi_ll_zoom = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = aoi_ll_zoom.to_crs(utm_crs).total_bounds\n",
    "else:\n",
    "    bounds = []\n",
    "    if not edges_all_utm.empty: bounds.append(edges_all_utm.total_bounds)\n",
    "    if not b_utm.empty:         bounds.append(b_utm.total_bounds)\n",
    "    if aoi_utm is not None and not aoi_utm.empty: bounds.append(aoi_utm.total_bounds)\n",
    "    xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "    xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "legend_items = []\n",
    "\n",
    "# All edges\n",
    "edges_all_utm.plot(ax=ax, color=P[\"EDGE_ALL_COLOR\"], linewidth=P[\"EDGE_ALL_LW\"],\n",
    "                   alpha=P[\"EDGE_ALL_ALPHA\"], zorder=1)\n",
    "legend_items.append(Line2D([0],[0], color=P[\"EDGE_ALL_COLOR\"], lw=2.5, label=P[\"LBL_EDGE_ALL\"]))\n",
    "\n",
    "# Buildings (all)\n",
    "b_utm.plot(ax=ax, facecolor=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"],\n",
    "           linewidth=P[\"BLDG_LW\"], alpha=P[\"BLDG_ALPHA\"], zorder=2)\n",
    "legend_items.append(Patch(facecolor=P[\"BLDG_FACE\"], edgecolor=P[\"BLDG_EDGE\"], label=P[\"LBL_BLDG\"]))\n",
    "\n",
    "# Damaged buildings\n",
    "b_dmg.plot(ax=ax, facecolor=P[\"BLDG_DAM_FACE\"], edgecolor=P[\"BLDG_DAM_EDGE\"],\n",
    "           linewidth=P[\"BLDG_DAM_LW\"], alpha=P[\"BLDG_DAM_ALPHA\"], zorder=3)\n",
    "legend_items.append(Patch(facecolor=P[\"BLDG_DAM_FACE\"], edgecolor=P[\"BLDG_DAM_EDGE\"], label=P[\"LBL_BLDG_DAM\"]))\n",
    "\n",
    "# Damaged edges\n",
    "edges_dmg_utm.plot(ax=ax, color=P[\"EDGE_DMG_COLOR\"], linewidth=P[\"EDGE_DMG_LW\"],\n",
    "                   alpha=P[\"EDGE_DMG_ALPHA\"], zorder=4)\n",
    "legend_items.append(Line2D([0],[0], color=P[\"EDGE_DMG_COLOR\"], lw=3, label=P[\"LBL_EDGE_DMG\"]))\n",
    "\n",
    "# Damaged tunnels/bridges\n",
    "tb_dmg_utm.plot(ax=ax, color=P[\"TB_COLOR\"], linewidth=P[\"TB_LW\"],\n",
    "                alpha=P[\"TB_ALPHA\"], zorder=5)\n",
    "legend_items.append(Line2D([0],[0], color=P[\"TB_COLOR\"], lw=3, label=P[\"LBL_TB\"]))\n",
    "\n",
    "# AOI boundary (optional)\n",
    "if P[\"DRAW_AOI\"] and aoi_utm is not None and not aoi_utm.empty:\n",
    "    aoi_utm.boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"], zorder=6)\n",
    "    legend_items.append(Line2D([0],[0], color=P[\"AOI_COLOR\"], lw=P[\"AOI_LW\"], label=P[\"LBL_AOI\"]))\n",
    "\n",
    "# Frame + decor\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# North arrow\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "# Scalebar\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "\n",
    "# Legend\n",
    "ax.legend(handles=legend_items, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "# Save + show\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\" Saved: {out_png}\")\n",
    "display(Image(filename=str(out_png)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7086a5c1-30ab-4804-8f5e-a542f84d2017",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== F7) Summary ===============================\n",
    "n_eval = len(edges_eval_tb) if 'edges_eval_tb' in globals() else len(edges_eval_src)\n",
    "n_dmg  = len(edges_dmg_tb)  if 'edges_dmg_tb'  in globals() else int((edges_eval_src[\"Damaged\"].astype(str).str.lower()==\"yes\").sum())\n",
    "n_ok   = len(edges_ok_tb)   if 'edges_ok_tb'   in globals() else int((edges_eval_src[\"Damaged\"].astype(str).str.lower()==\"no\").sum())\n",
    "n_tb   = int(tb_edges.shape[0]) if 'tb_edges' in globals() else 0\n",
    "n_tb_hit = int(len(tb_hit_idx)) if 'tb_hit_idx' in globals() else 0\n",
    "\n",
    "print(\"\\n===== Section F Summary =====\")\n",
    "print(f\"Evaluated edges (total):                 {n_eval:,}\")\n",
    "print(f\"  Damaged edges (after TB override):     {n_dmg:,}\")\n",
    "print(f\"  Undamaged edges:                       {n_ok:,}\")\n",
    "print(f\"Tunnel/Bridge edges (OSM):               {n_tb:,}\")\n",
    "print(f\"  TB edges intersecting damaged pixels:  {n_tb_hit:,}\")\n",
    "print(\"Outputs:\")\n",
    "print(f\"  Evaluated_Edges_withTunnels_Bridges:   {EVAL_EDGES_TB_SHP}\")\n",
    "print(f\"  Damaged_Edges_withTunnels_Bridges:     {DAMAGED_EDGES_TB_SHP}\")\n",
    "print(f\"  Undamaged_Edges_withTunnels_Bridges:   {UNDAMAGED_EDGES_TB_SHP}\")\n",
    "print(f\"  Figure:                                 {Path(IMAGES_DIR) / 'Damaged_Edges_Tunnels_Bridges.png'}\")\n",
    "print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da03c53-6f97-430b-923f-4fd25782e1fb",
   "metadata": {},
   "source": [
    "## G) Damaged Node Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5728da-a67d-49b6-96ee-a26003de754f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== G0) Imports ===============================\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from shapely.geometry import box\n",
    "from IPython.display import Image, display\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a483f5-1d1e-4433-bac7-8c2516fc91fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== G1) User Options & Paths ======================\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "E_OUT_DIR  = os.path.join(OUT_BASE, \"E\")\n",
    "F_OUT_DIR  = os.path.join(OUT_BASE, \"F\")\n",
    "G_OUT_DIR  = os.path.join(OUT_BASE, \"G\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(G_OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Preferred evaluated-edges data\n",
    "EDGE_VARS_MEM = [\"edges_eval_tb\", \"edges_eval_src\", \"edges_eval\"]\n",
    "EDGE_PATHS_FS = [os.path.join(F_OUT_DIR, \"Evaluated_Edges_withTunnels_Bridges.shp\"),\n",
    "                 os.path.join(E_OUT_DIR, \"Evaluated_Edges.shp\")]\n",
    "\n",
    "# Preferred nodes data\n",
    "NODES_VAR_MEM = \"nodes\"\n",
    "NODES_PATH_FS = os.path.join(A_OUT_DIR, \"osm_nodes.shp\")\n",
    "\n",
    "# Output files\n",
    "EVAL_NODES_TB_SHP   = Path(G_OUT_DIR) / \"Evaluated_Nodes_withTunnels_Bridges.shp\"\n",
    "DAMAGED_NODES_TB_SHP= Path(G_OUT_DIR) / \"Damaged_Nodes_withTunnels_Bridges.shp\"\n",
    "UNDAM_NODES_TB_SHP  = Path(G_OUT_DIR) / \"Undamaged_Nodes_withTunnels_Bridges.shp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c129b0-4edf-4a25-9c27-a4633595b719",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== G2) Load Data (edges & nodes) ======================\n",
    "\n",
    "# 1) Edges with 'Damaged'\n",
    "edges_eval_candidates = []\n",
    "\n",
    "# --- From in-memory variables ---\n",
    "for var in EDGE_VARS_MEM:\n",
    "    if var in globals():\n",
    "        g = globals()[var]\n",
    "        if isinstance(g, gpd.GeoDataFrame) and not g.empty and (\"Damaged\" in g.columns):\n",
    "            edges_eval_candidates.append(g.copy())\n",
    "\n",
    "# --- From filesystem paths ---\n",
    "for p in EDGE_PATHS_FS:\n",
    "    if Path(p).exists():\n",
    "        g = gpd.read_file(p)\n",
    "        if not g.empty and (\"Damaged\" in g.columns):\n",
    "            edges_eval_candidates.append(g)\n",
    "\n",
    "if not edges_eval_candidates:\n",
    "    raise RuntimeError(\"No evaluated edges with a 'Damaged' column found.\")\n",
    "\n",
    "edges_eval_in = edges_eval_candidates[0]\n",
    "\n",
    "def ensure_uv_columns(edge_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Ensure columns 'u' and 'v' exist. If MultiIndex (u,v,key), reset index and map to 'u'/'v'.\n",
    "    \"\"\"\n",
    "    if edge_gdf.empty:\n",
    "        return edge_gdf\n",
    "    # If 'u' and 'v' already exist, just return\n",
    "    if {'u', 'v'}.issubset(edge_gdf.columns):\n",
    "        return edge_gdf\n",
    "    # If MultiIndex, try to interpret first two levels as u, v\n",
    "    if isinstance(edge_gdf.index, pd.MultiIndex):\n",
    "        df = edge_gdf.reset_index()\n",
    "        idx_names = list(edge_gdf.index.names)\n",
    "        rename_map = {}\n",
    "        if len(idx_names) >= 1:\n",
    "            rename_map[idx_names[0] if idx_names[0] else 'level_0'] = 'u'\n",
    "        if len(idx_names) >= 2:\n",
    "            rename_map[idx_names[1] if idx_names[1] else 'level_1'] = 'v'\n",
    "        df = df.rename(columns=rename_map)\n",
    "        if 'u' not in df.columns or 'v' not in df.columns:\n",
    "            raise KeyError(\"Could not map MultiIndex index levels to 'u'/'v'. Inspect edges.\")\n",
    "        return df\n",
    "    raise KeyError(\"Edges lack 'u'/'v' columns and are not a MultiIndex—inspect edges schema.\")\n",
    "\n",
    "edges_u = ensure_uv_columns(edges_eval_in)\n",
    "\n",
    "# 2) Nodes (OSM)\n",
    "if NODES_VAR_MEM in globals() and isinstance(globals()[NODES_VAR_MEM], gpd.GeoDataFrame) and not globals()[NODES_VAR_MEM].empty:\n",
    "    nodes_src = globals()[NODES_VAR_MEM].copy()\n",
    "elif Path(NODES_PATH_FS).exists():\n",
    "    nodes_src = gpd.read_file(NODES_PATH_FS)\n",
    "else:\n",
    "    raise RuntimeError(\"No OSM nodes found (memory or Outputs_Final\\\\A).\")\n",
    "\n",
    "# Ensure node index matches edge u/v IDs (use 'osmid' as index if present)\n",
    "if \"osmid\" in nodes_src.columns:\n",
    "    nodes_src = nodes_src.set_index(\"osmid\", drop=False)\n",
    "else:\n",
    "    raise RuntimeError(\"nodes_src has no 'osmid' column; cannot align with edge u/v node IDs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd9a8b-4ac2-401c-8e44-b7441704e096",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== G3) Classify nodes: all-incident-edges-damaged rule ==============\n",
    "# Normalize 'Damaged' yes/no on edges\n",
    "edge_dam = edges_u[\"Damaged\"].astype(str).str.lower().str.strip().eq(\"yes\")\n",
    "edges_dmg = edges_u[edge_dam].copy()\n",
    "\n",
    "print(f\" Evaluated edges (data): {len(edges_u):,}\")\n",
    "print(f\"   Damaged edges:           {len(edges_dmg):,}\")\n",
    "print(f\"   Undamaged edges:         {len(edges_u) - len(edges_dmg):,}\")\n",
    "\n",
    "def node_degree_counts(edge_gdf: gpd.GeoDataFrame) -> pd.Series:\n",
    "    if edge_gdf.empty:\n",
    "        return pd.Series(dtype=int)\n",
    "    # degree = number of incident edges (counts of u and v)\n",
    "    return pd.concat([edge_gdf['u'], edge_gdf['v']]).value_counts()\n",
    "\n",
    "deg_total   = node_degree_counts(edges_u)\n",
    "deg_damaged = node_degree_counts(edges_dmg)\n",
    "\n",
    "deg_df = (\n",
    "    pd.DataFrame({'deg_total': deg_total})\n",
    "      .join(deg_damaged.rename('deg_damaged'), how='left')\n",
    "      .fillna({'deg_damaged': 0})\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Rule: node is \"yes\" only if ALL incident edges are damaged (and degree ≥ 1)\n",
    "node_is_damaged = (deg_df['deg_damaged'] == deg_df['deg_total']) & (deg_df['deg_total'] >= 1)\n",
    "deg_df['Damaged'] = node_is_damaged.map({True: \"yes\", False: \"no\"})\n",
    "\n",
    "# Join onto nodes (index should be node IDs)\n",
    "nodes_eval = nodes_src.join(deg_df, how='left')\n",
    "\n",
    "# Isolated nodes (no incident edges) → undamaged by definition\n",
    "nodes_eval[['deg_total','deg_damaged']] = nodes_eval[['deg_total','deg_damaged']].fillna(0).astype(int)\n",
    "nodes_eval['Damaged'] = nodes_eval['Damaged'].fillna(\"no\").astype(str)\n",
    "\n",
    "nodes_dmg = nodes_eval[nodes_eval['Damaged'].str.lower().eq(\"yes\")].copy()\n",
    "nodes_ok  = nodes_eval[nodes_eval['Damaged'].str.lower().ne(\"yes\")].copy()\n",
    "\n",
    "print(f\" Evaluated nodes:                        {len(nodes_eval):,}\")\n",
    "print(f\"   Damaged nodes (all incident damaged):  {len(nodes_dmg):,}\")\n",
    "print(f\"   Undamaged nodes:                       {len(nodes_ok):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958612b-0fa3-45f8-b922-4f4a7b1c9632",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== G4) Save nodes ===============================\n",
    "def _safe_save_nodes(gdf: gpd.GeoDataFrame, path: str):\n",
    "    \"\"\"Reset index to avoid duplicate 'osmid' when writing to file.\"\"\"\n",
    "    if gdf is None or gdf.empty:\n",
    "        return\n",
    "    gdf_out = gdf.reset_index(drop=True)\n",
    "    gdf_out.to_file(path)\n",
    "\n",
    "_safe_save_nodes(nodes_eval, EVAL_NODES_TB_SHP)\n",
    "_safe_save_nodes(nodes_dmg, DAMAGED_NODES_TB_SHP)\n",
    "_safe_save_nodes(nodes_ok,  UNDAM_NODES_TB_SHP)\n",
    "\n",
    "print(\" Saved:\")\n",
    "print(\"  \", EVAL_NODES_TB_SHP)\n",
    "print(\"  \", DAMAGED_NODES_TB_SHP)\n",
    "print(\"  \", UNDAM_NODES_TB_SHP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f75491-dd4f-43f7-8d20-74213952a3ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======= G5) Plot: Nodes  =======\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Damaged_Nodes.png\",      # output PNG name (saved to IMAGES_DIR)\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326 (set all to None for auto extent) ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & labels ----\n",
    "    \"FIGSIZE\": (11, 10),                  # figure size (w, h) inches\n",
    "    \"DPI\": 300,                           # export resolution\n",
    "    \"TITLE\": \"Damaged Nodes (black) & Edges (red) with Network Context\",\n",
    "    \"XLABEL\": \"Easting (m)\",              # projected meters\n",
    "    \"YLABEL\": \"Northing (m)\",             # projected meters\n",
    "\n",
    "    # ---- Edges style ----\n",
    "    \"EDGE_ALL_COLOR\": \"#b0b0b0\",          # undamaged edges color (gray)\n",
    "    \"EDGE_ALL_LW\": 0.6,                   # linewidth\n",
    "    \"EDGE_ALL_ALPHA\": 1.0,                # transparency\n",
    "    \"EDGE_DMG_COLOR\": \"#d73027\",          # damaged edges color (red)\n",
    "    \"EDGE_DMG_LW\": 1.2,\n",
    "    \"EDGE_DMG_ALPHA\": 1.0,\n",
    "    \"LBL_EDGE_OK\": \"Undamaged edges\",     # legend label\n",
    "    \"LBL_EDGE_DMG\": \"Damaged edges\",      # legend label\n",
    "\n",
    "    # ---- Nodes style ----\n",
    "    \"NODE_OK_COLOR\": \"#1f78b4\",           # undamaged nodes (blue)\n",
    "    \"NODE_OK_SIZE\": 12,\n",
    "    \"NODE_OK_ALPHA\": 1.0,\n",
    "    \"NODE_DMG_COLOR\": \"black\",            # damaged nodes (black)\n",
    "    \"NODE_DMG_SIZE\": 18,\n",
    "    \"NODE_DMG_ALPHA\": 1.0,\n",
    "    \"LBL_NODE_OK\": \"Undamaged nodes\",     # legend label\n",
    "    \"LBL_NODE_DMG\": \"Damaged nodes\",      # legend label\n",
    "\n",
    "    # ---- AOI boundary (optional if provided upstream) ----\n",
    "    \"DRAW_AOI\": True,\n",
    "    \"AOI_COLOR\": \"black\",\n",
    "    \"AOI_LW\": 1.0,\n",
    "\n",
    "    # ---- North arrow & scalebar ----\n",
    "    \"ADD_NORTH_ARROW\": True,\n",
    "    \"NA_X\": 0.05, \"NA_Y\": 0.15,           # position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,                       # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",\n",
    "    \"NA_COLOR\": \"black\", \"NA_LW\": 2, \"NA_FONTSIZE\": 14,\n",
    "    \"ADD_SCALEBAR\": True,                 # Scalebar\n",
    "    \"SB_UNITS\": \"m\",\n",
    "    \"SB_LOC\": \"lower right\",              # scalebar location\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"LEGEND_LOC\": \"upper right\"           # legend placement\n",
    "}\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Reuse evaluated edges/nodes from memory in this section (unchanged logic)\n",
    "e_src = edges_u.copy()\n",
    "n_src = nodes_eval.copy()\n",
    "aoi_src = aoi_gdf_ll if 'aoi_gdf_ll' in globals() else None\n",
    "\n",
    "# Common CRS (local UTM from edges)\n",
    "utm_crs   = e_src.to_crs(4326).estimate_utm_crs()\n",
    "edges_utm = e_src.to_crs(utm_crs)\n",
    "nodes_utm = n_src.to_crs(utm_crs)\n",
    "aoi_utm   = aoi_src.to_crs(utm_crs) if isinstance(aoi_src, gpd.GeoDataFrame) else None\n",
    "\n",
    "# Splits\n",
    "dam_col = edges_utm[\"Damaged\"].astype(str).str.lower().str.strip()\n",
    "e_all   = edges_utm\n",
    "e_dmg   = edges_utm[dam_col.eq(\"yes\")].copy()\n",
    "n_dmg   = nodes_utm[nodes_utm[\"Damaged\"].astype(str).str.lower().eq(\"yes\")].copy()\n",
    "n_ok    = nodes_utm[nodes_utm[\"Damaged\"].astype(str).str.lower().ne(\"yes\")].copy()\n",
    "\n",
    "# Optional lon/lat zoom → UTM frame\n",
    "use_bbox = all(P[k] is not None for k in (\"lon_min\",\"lon_max\",\"lat_min\",\"lat_max\"))\n",
    "if use_bbox:\n",
    "    aoi_ll_zoom = gpd.GeoDataFrame(\n",
    "        geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                      max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                      max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "        crs=4326\n",
    "    )\n",
    "    xmin, ymin, xmax, ymax = aoi_ll_zoom.to_crs(utm_crs).total_bounds\n",
    "else:\n",
    "    bounds = []\n",
    "    if not e_all.empty:     bounds.append(e_all.total_bounds)\n",
    "    if not nodes_utm.empty: bounds.append(nodes_utm.total_bounds)\n",
    "    if aoi_utm is not None and not aoi_utm.empty: bounds.append(aoi_utm.total_bounds)\n",
    "    xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "    xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "legend_items = []\n",
    "\n",
    "# Edges (ok + damaged)\n",
    "e_all.plot(ax=ax, color=P[\"EDGE_ALL_COLOR\"], linewidth=P[\"EDGE_ALL_LW\"],\n",
    "           alpha=P[\"EDGE_ALL_ALPHA\"], zorder=1)\n",
    "legend_items.append(Line2D([0],[0], color=P[\"EDGE_ALL_COLOR\"], lw=2, label=P[\"LBL_EDGE_OK\"]))\n",
    "\n",
    "e_dmg.plot(ax=ax, color=P[\"EDGE_DMG_COLOR\"], linewidth=P[\"EDGE_DMG_LW\"],\n",
    "           alpha=P[\"EDGE_DMG_ALPHA\"], zorder=2)\n",
    "legend_items.append(Line2D([0],[0], color=P[\"EDGE_DMG_COLOR\"], lw=2.5, label=P[\"LBL_EDGE_DMG\"]))\n",
    "\n",
    "# Nodes (ok + damaged)\n",
    "if not n_ok.empty:\n",
    "    n_ok.plot(ax=ax, color=P[\"NODE_OK_COLOR\"], markersize=P[\"NODE_OK_SIZE\"],\n",
    "              alpha=P[\"NODE_OK_ALPHA\"], zorder=3)\n",
    "    legend_items.append(Line2D([0],[0], marker=\"o\", linestyle=\"None\",\n",
    "                               markerfacecolor=P[\"NODE_OK_COLOR\"], markeredgecolor=\"none\",\n",
    "                               markersize=8, label=P[\"LBL_NODE_OK\"]))\n",
    "if not n_dmg.empty:\n",
    "    n_dmg.plot(ax=ax, color=P[\"NODE_DMG_COLOR\"], markersize=P[\"NODE_DMG_SIZE\"],\n",
    "               alpha=P[\"NODE_DMG_ALPHA\"], zorder=4)\n",
    "    legend_items.append(Line2D([0],[0], marker=\"o\", linestyle=\"None\",\n",
    "                               markerfacecolor=P[\"NODE_DMG_COLOR\"], markeredgecolor=\"none\",\n",
    "                               markersize=8, label=P[\"LBL_NODE_DMG\"]))\n",
    "\n",
    "# AOI boundary (optional)\n",
    "if P[\"DRAW_AOI\"] and aoi_utm is not None and not aoi_utm.empty:\n",
    "    aoi_utm.boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"], zorder=5)\n",
    "\n",
    "# Frame + decor\n",
    "ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "# North arrow\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                clip_on=False, zorder=20)\n",
    "\n",
    "# Scalebar\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"]))\n",
    "\n",
    "ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "ax.set_title(P[\"TITLE\"])\n",
    "\n",
    "ax.legend(handles=legend_items, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "out_png = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_png, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(f\" Saved: {out_png}\")\n",
    "display(Image(filename=str(out_png)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c1f1a-e36a-4d9a-9735-32de67bad949",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== G6) Summary ===============================\n",
    "n_edges_total = len(edges_u)\n",
    "n_edges_dmg   = int(edge_dam.sum())\n",
    "n_nodes_total = len(nodes_eval)\n",
    "n_nodes_dmg   = len(nodes_dmg)\n",
    "n_nodes_ok    = len(nodes_ok)\n",
    "\n",
    "print(\"\\n===== Section G Summary =====\")\n",
    "print(f\"Edges evaluated (total):                 {n_edges_total:,}\")\n",
    "print(f\"  Damaged edges:                         {n_edges_dmg:,}\")\n",
    "print(f\"Nodes evaluated (total):                 {n_nodes_total:,}\")\n",
    "print(f\"  Damaged nodes (all incident damaged):  {n_nodes_dmg:,}\")\n",
    "print(f\"  Undamaged nodes:                       {n_nodes_ok:,}\")\n",
    "print(\"Outputs:\")\n",
    "print(f\"  Evaluated Nodes:                       {EVAL_NODES_TB_SHP}\")\n",
    "print(f\"  Damaged Nodes:                         {DAMAGED_NODES_TB_SHP}\")\n",
    "print(f\"  Undamaged Nodes:                       {UNDAM_NODES_TB_SHP}\")\n",
    "print(f\"  Figure:                                {Path(IMAGES_DIR) / 'Damaged_Nodes.png'}\")\n",
    "print(\"=======================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535c92e-c9a9-4838-b48c-38796b3601b6",
   "metadata": {},
   "source": [
    "## H) Utility 1: Shortest Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ede11-49c1-4687-a152-c3df55e654c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============================== H0) Imports ===============================\n",
    "import os, json, math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "from shapely.geometry import Point, box\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from IPython.display import Image, display\n",
    "import yaml\n",
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae83c0-ee9b-4bf3-9930-550b0c7dc31a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== H1) User Options & Paths ======================\n",
    "# --- Origin/Destination in configuration\n",
    "orig_node = optional(\"orig_node\")                 # e.g., 157370362\n",
    "dest_node = optional(\"dest_node\")                 # e.g., 13081265302\n",
    "orig_lonlat = tuple(require(\"orig_lonlat\"))       # (lon, lat) used if node IDs are None\n",
    "dest_lonlat = tuple(require(\"dest_lonlat\"))\n",
    "\n",
    "# How many distinct shortest routes to collect in configuration\n",
    "ROUTE_TARGET = require(\"ROUTE_TARGET\", int)\n",
    "\n",
    "# --- Output ---\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "E_OUT_DIR  = os.path.join(OUT_BASE, \"E\")\n",
    "F_OUT_DIR  = os.path.join(OUT_BASE, \"F\")\n",
    "H_OUT_DIR  = os.path.join(OUT_BASE, \"H\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "\n",
    "SP_OUT_DIR = os.path.join(H_OUT_DIR, \"Shortest_Path\")\n",
    "os.makedirs(SP_OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Shortest-path outputs →\", SP_OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e652cb7-4c4e-431f-80cd-da66ac44fd92",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ======================== H2) Helper Functions ========================\n",
    "def haversine_m(lat1, lon1, lat2, lon2):\n",
    "    R = 6371008.8\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat/2)**2\n",
    "         + math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2)\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "def ensure_nodes_index_xy(nodes_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    For routing:\n",
    "      - Ensure index is 'osmid' (matching edge u/v IDs),\n",
    "      - Ensure CRS is EPSG:4326 (lon/lat),\n",
    "      - Force columns 'x' and 'y' to be geometry.x / geometry.y in that CRS.\n",
    "    \"\"\"\n",
    "    n = nodes_gdf.copy()\n",
    "\n",
    "    # --- Index: use OSMID if present ---\n",
    "    if \"osmid\" in n.columns:\n",
    "        if n.index.name != \"osmid\":\n",
    "            n = n.set_index(\"osmid\", drop=False)\n",
    "    else:\n",
    "        # fallback: create osmid from existing index\n",
    "        if n.index.name != \"osmid\":\n",
    "            n = n.reset_index().rename(columns={\"index\": \"osmid\"})\n",
    "            n = n.set_index(\"osmid\", drop=False)\n",
    "\n",
    "    # --- CRS: make sure geometries are in WGS84 lon/lat ---\n",
    "    if n.crs is None:\n",
    "        n = n.set_crs(4326, allow_override=True)\n",
    "    if n.crs.to_epsg() != 4326:\n",
    "        n = n.to_crs(4326)\n",
    "\n",
    "    # --- x, y: ALWAYS recompute from geometry (ignore any old x/y) ---\n",
    "    n[\"x\"] = n.geometry.x  # longitude\n",
    "    n[\"y\"] = n.geometry.y  # latitude\n",
    "\n",
    "    return n\n",
    "\n",
    "def ensure_edges_index(edges_gdf):\n",
    "    e = edges_gdf.copy()\n",
    "    for must in (\"u\",\"v\"):\n",
    "        if must not in e.columns:\n",
    "            raise ValueError(f\"Edges missing required column '{must}'.\")\n",
    "    if \"key\" not in e.columns:\n",
    "        e[\"key\"] = e.groupby([\"u\",\"v\"]).cumcount()\n",
    "    if (not isinstance(e.index, pd.MultiIndex)) or (list(e.index.names) != [\"u\",\"v\",\"key\"]):\n",
    "        e = e.set_index([\"u\",\"v\",\"key\"], drop=False)\n",
    "    drop_cols = [c for c in (\"u\",\"v\",\"key\") if c in e.columns]\n",
    "    if drop_cols:\n",
    "        e = e.drop(columns=drop_cols)\n",
    "    return e\n",
    "\n",
    "def ensure_lengths(edges_gdf):\n",
    "    e = edges_gdf.copy()\n",
    "    if \"length\" in e.columns and e[\"length\"].notna().all():\n",
    "        return e\n",
    "    try:\n",
    "        utm = e.estimate_utm_crs()\n",
    "        e[\"length\"] = e.to_crs(utm).geometry.length\n",
    "    except Exception:\n",
    "        def approx_len_m(geom):\n",
    "            try:\n",
    "                coords = list(geom.coords)\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "            s = 0.0\n",
    "            for (x1,y1),(x2,y2) in zip(coords[:-1], coords[1:]):\n",
    "                s += haversine_m(y1,x1,y2,x2)\n",
    "            return s\n",
    "        e[\"length\"] = e.geometry.apply(approx_len_m)\n",
    "    return e\n",
    "\n",
    "def build_graph(nodes_gdf, edges_gdf):\n",
    "    if nodes_gdf.crs is None:\n",
    "        nodes_gdf = nodes_gdf.set_crs(4326, allow_override=True)\n",
    "    if edges_gdf.crs is None:\n",
    "        edges_gdf = edges_gdf.set_crs(nodes_gdf.crs, allow_override=True)\n",
    "    return ox.convert.graph_from_gdfs(nodes_gdf, edges_gdf)\n",
    "\n",
    "def nearest_node_from_lonlat(G, lon, lat):\n",
    "    \"\"\"\n",
    "    Find the closest graph node to (lon, lat) using explicit haversine\n",
    "    distance between your (lon, lat) and each node's (x, y) = (lon, lat).\n",
    "    \"\"\"\n",
    "    best_n, best_d = None, float(\"inf\")\n",
    "    for n, d in G.nodes(data=True):\n",
    "        x = d.get(\"x\", None)  # longitude\n",
    "        y = d.get(\"y\", None)  # latitude\n",
    "        if x is None or y is None:\n",
    "            continue\n",
    "        dist = haversine_m(lat, lon, y, x)  # (lat1, lon1, lat2, lon2)\n",
    "        if dist < best_d:\n",
    "            best_d, best_n = dist, n\n",
    "    return best_n\n",
    "\n",
    "def get_route_length(G, route):\n",
    "    if not route or len(route) < 2:\n",
    "        return 0.0\n",
    "    total = 0.0\n",
    "    for u, v in zip(route[:-1], route[1:]):\n",
    "        data = G.get_edge_data(u, v)\n",
    "        if not data:\n",
    "            continue\n",
    "        total += min(d.get(\"length\", 0.0) for d in data.values())\n",
    "    return total\n",
    "\n",
    "def export_nodes_csv_rows(G, route):\n",
    "    rows = []\n",
    "    if not route:\n",
    "        return rows\n",
    "    try:\n",
    "        step_lengths = ox.utils_graph.get_route_edge_attributes(G, route, \"length\")\n",
    "    except Exception:\n",
    "        step_lengths = []\n",
    "        for u, v in zip(route[:-1], route[1:]):\n",
    "            data = G.get_edge_data(u, v) or {}\n",
    "            step_lengths.append(min(d.get(\"length\", 0.0) for d in data.values()) if data else 0.0)\n",
    "    cum = 0.0\n",
    "    for seq, n in enumerate(route):\n",
    "        if seq > 0 and seq - 1 < len(step_lengths):\n",
    "            cum += step_lengths[seq - 1]\n",
    "        lon = G.nodes[n].get(\"x\"); lat = G.nodes[n].get(\"y\")\n",
    "        rows.append({\"seq\": seq, \"node\": n, \"lon\": lon, \"lat\": lat, \"cum_length_m\": cum})\n",
    "    return rows\n",
    "\n",
    "def _route_signature(route):\n",
    "    return tuple(route) if route else tuple()\n",
    "\n",
    "def add_north_arrow(ax, x=0.05, y=0.15, length=0.08):\n",
    "    ax.annotate(\"N\", xy=(x, y), xytext=(x, y - length),\n",
    "                xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                ha=\"center\", va=\"center\", fontsize=12, fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=2, color=\"black\"),\n",
    "                clip_on=False, zorder=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1493268-7977-4c90-a467-739f55902f62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= H3) Load Data =========================\n",
    "if 'nodes' in globals() and isinstance(nodes, gpd.GeoDataFrame) and not nodes.empty:\n",
    "    nodes_raw = nodes.copy()\n",
    "else:\n",
    "    nodes_path = Path(A_OUT_DIR) / \"osm_nodes.shp\"\n",
    "    if nodes_path.exists():\n",
    "        nodes_raw = gpd.read_file(nodes_path)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"Nodes layer not found (memory or Outputs_Final\\\\A).\")\n",
    "\n",
    "# Evaluated edges\n",
    "edges_eval_candidates = []\n",
    "for _var in (\"edges_eval_tb\", \"edges_eval_src\", \"edges_eval\"):\n",
    "    if _var in globals():\n",
    "        _g = globals()[_var]\n",
    "        if isinstance(_g, gpd.GeoDataFrame) and not _g.empty and (\"Damaged\" in _g.columns):\n",
    "            edges_eval_candidates.append(_g.copy())\n",
    "\n",
    "for _p in (Path(F_OUT_DIR) / \"Evaluated_Edges_withTunnels_Bridges.shp\",\n",
    "           Path(E_OUT_DIR) / \"Evaluated_Edges.shp\"):\n",
    "    if _p.exists():\n",
    "        g = gpd.read_file(_p)\n",
    "        if not g.empty and (\"Damaged\" in g.columns):\n",
    "            edges_eval_candidates.append(g)\n",
    "\n",
    "if not edges_eval_candidates:\n",
    "    raise RuntimeError(\"Evaluated edges with 'Damaged' column not found (memory or disk).\")\n",
    "\n",
    "edges_eval_tb = edges_eval_candidates[0]\n",
    "\n",
    "# Keep ONLY undamaged edges for routing\n",
    "dam_col = edges_eval_tb[\"Damaged\"].astype(str).str.lower().str.strip()\n",
    "edges_ok = edges_eval_tb[~dam_col.eq(\"yes\")].copy()\n",
    "print(f\"Routing over {len(edges_ok):,} undamaged edges (of {len(edges_eval_tb):,} total).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6d641-f6a3-4c55-b78a-cb26ca4de4a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ===================== H4) Normalize & Build Graph =====================\n",
    "nodes_norm  = ensure_nodes_index_xy(nodes_raw)\n",
    "edges_norm  = ensure_edges_index(edges_ok)\n",
    "edges_norm  = ensure_lengths(edges_norm)\n",
    "\n",
    "G = build_graph(nodes_norm, edges_norm)\n",
    "\n",
    "# Resolve Origin /Destination nodes (ID first; else nearest by lon/lat)\n",
    "if orig_node is None:\n",
    "    orig_node = nearest_node_from_lonlat(G, *orig_lonlat)\n",
    "if dest_node is None:\n",
    "    dest_node = nearest_node_from_lonlat(G, *dest_lonlat)\n",
    "\n",
    "orig_x = G.nodes[orig_node].get(\"x\")\n",
    "orig_y = G.nodes[orig_node].get(\"y\")\n",
    "dest_x = G.nodes[dest_node].get(\"x\")\n",
    "dest_y = G.nodes[dest_node].get(\"y\")\n",
    "\n",
    "print(f\"Graph built → nodes: {G.number_of_nodes():,} | edges: {G.number_of_edges():,}\")\n",
    "print(f\"Requested origin lon/lat:      {orig_lonlat}\")\n",
    "print(f\"Requested destination lon/lat: {dest_lonlat}\")\n",
    "print(f\"Snapped origin node:      {orig_node}  → ({orig_x:.6f}, {orig_y:.6f})\")\n",
    "print(f\"Snapped destination node: {dest_node}  → ({dest_x:.6f}, {dest_y:.6f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af42a8-2dce-4c64-a07b-994d77f011b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============== H5) Shortest Paths (expanding-radius variants) ===============\n",
    "# First: direct shortest\n",
    "try:\n",
    "    route0 = ox.routing.shortest_path(G, orig_node, dest_node, weight=\"length\")\n",
    "except Exception:\n",
    "    try:\n",
    "        route0 = nx.shortest_path(G, orig_node, dest_node, weight=\"length\", method=\"dijkstra\")\n",
    "    except Exception:\n",
    "        route0 = None\n",
    "\n",
    "routes_list, sigset = [], set()\n",
    "if route0:\n",
    "    routes_list.append(route0); sigset.add(_route_signature(route0))\n",
    "    print(f\"Direct path found: {len(route0)} nodes, {get_route_length(G, route0):.1f} m\")\n",
    "else:\n",
    "    print(\"No direct path found yet—will try expanding-radius search.\")\n",
    "\n",
    "# Precompute single-source distances from origin\n",
    "try:\n",
    "    lengths, paths = nx.single_source_dijkstra(G, source=orig_node, weight=\"length\")\n",
    "except Exception as e:\n",
    "    lengths, paths = {}, {}\n",
    "    print(\" single_source_dijkstra failed:\", e)\n",
    "\n",
    "# Node GeoDataFrame in lon/lat and meters for radius filtering\n",
    "node_ids, node_pts_ll = [], []\n",
    "for n, d in G.nodes(data=True):\n",
    "    if \"x\" in d and \"y\" in d:\n",
    "        node_ids.append(n); node_pts_ll.append(Point(d[\"x\"], d[\"y\"]))\n",
    "nodes_ll = gpd.GeoDataFrame({\"node\": node_ids}, geometry=node_pts_ll, crs=4326)\n",
    "\n",
    "try:\n",
    "    utm = nodes_ll.estimate_utm_crs()\n",
    "except Exception:\n",
    "    utm = 3857\n",
    "nodes_m = nodes_ll.to_crs(utm)\n",
    "\n",
    "# Centers in meters\n",
    "start_lon, start_lat = G.nodes[orig_node][\"x\"], G.nodes[orig_node][\"y\"]\n",
    "dest_lon,  dest_lat  = G.nodes[dest_node][\"x\"],  G.nodes[dest_node][\"y\"]\n",
    "start_m = gpd.GeoSeries([Point(start_lon, start_lat)], crs=4326).to_crs(utm).iloc[0]\n",
    "dest_m  = gpd.GeoSeries([Point(dest_lon,  dest_lat)],  crs=4326).to_crs(utm).iloc[0]\n",
    "d_m = start_m.distance(dest_m)\n",
    "base_step = max(25.0, 0.01 * d_m)  # 1% of straight-line distance, min 25 m\n",
    "\n",
    "has_sindex = getattr(nodes_m, \"sindex\", None) is not None\n",
    "R = base_step\n",
    "max_radius = max(d_m, 15000.0)\n",
    "iters = 0\n",
    "\n",
    "while len(routes_list) < ROUTE_TARGET and R <= max_radius:\n",
    "    iters += 1\n",
    "    circle = dest_m.buffer(R)\n",
    "\n",
    "    if has_sindex:\n",
    "        idx = list(nodes_m.sindex.query(circle.envelope))\n",
    "        cand = nodes_m.iloc[idx]\n",
    "        cand = cand[cand.geometry.within(circle)]\n",
    "    else:\n",
    "        cand = nodes_m[nodes_m.geometry.distance(dest_m) <= R]\n",
    "\n",
    "    reachable = []\n",
    "    if not cand.empty and lengths:\n",
    "        reachable = [nid for nid in cand[\"node\"].tolist() if nid in lengths]\n",
    "\n",
    "    reachable_sorted = sorted(reachable, key=lambda nid: lengths[nid]) if reachable else []\n",
    "\n",
    "    new_routes = 0\n",
    "    for nid in reachable_sorted:\n",
    "        rpath = paths.get(nid)\n",
    "        if not rpath:\n",
    "            continue\n",
    "        sig = _route_signature(rpath)\n",
    "        if sig in sigset:\n",
    "            continue\n",
    "        routes_list.append(rpath)\n",
    "        sigset.add(sig)\n",
    "        new_routes += 1\n",
    "        if len(routes_list) >= ROUTE_TARGET:\n",
    "            break\n",
    "\n",
    "    pct = (R / d_m * 100.0) if d_m > 0 else float(\"inf\")\n",
    "    print(f\"[Iter {iters}] R={R:.0f} m ({pct:.1f}%) | cand={0 if cand.empty else len(cand)} | \"\n",
    "          f\"reach={len(reachable)} | new={new_routes} | total={len(routes_list)}\")\n",
    "\n",
    "    if len(routes_list) >= ROUTE_TARGET:\n",
    "        break\n",
    "    R += base_step\n",
    "\n",
    "print(f\"\\n Total iterations: {iters}\")\n",
    "print(f\" Routes collected: {len(routes_list)} (target {ROUTE_TARGET})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11519a58-e553-4a86-aead-822c869788f7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# =============== H6) Export CSV + PNGs ===============\n",
    "P = {\n",
    "    # ---- Output names ----\n",
    "    \"CSV_NAME\": \"All_Routes_Combined.csv\",      # filename for the combined CSV of all routes\n",
    "    \"OUT_NAME_FMT\": \"Shortest_path_{i}.png\",    # per-route PNG name; {i} will be replaced by route index\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326 (set all to None for auto extent) ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & export ----\n",
    "    \"FIGSIZE\": (7.5, 6.5),                      # figure size (width, height) in inches\n",
    "    \"DPI\": 200,                                  # PNG resolution; lower = smaller files\n",
    "    \"XLABEL\": \"Easting (m)\",                    # x-axis label\n",
    "    \"YLABEL\": \"Northing (m)\",                   # y-axis label\n",
    "    \"LEGEND_LOC\": \"upper right\",                # legend location (matplotlib position code)\n",
    "\n",
    "    # ---- Base road network style ----\n",
    "    \"BASE_COLOR\": \"#cccccc\",                    # base network line color\n",
    "    \"BASE_LW\": 0.7,                             # base network line width\n",
    "    \"BASE_ALPHA\": 1.0,                          # base network transparency (0..1)\n",
    "    \"LBL_BASE\": \"Road network\",                 # legend label for base network\n",
    "\n",
    "    # ---- AOI boundary (optional if provided upstream) ----\n",
    "    \"DRAW_AOI\": True,                           # draw AOI boundary if available\n",
    "    \"AOI_COLOR\": \"black\",                       # AOI boundary color\n",
    "    \"AOI_LW\": 1.0,                              # AOI boundary line width\n",
    "    \"AOI_ALPHA\": 1.0,                           # AOI boundary transparency\n",
    "    \"LBL_AOI\": \"AOI boundary\",                  # legend label for AOI boundary\n",
    "    \"LEG_AOI_LW\": 1.2,                          # legend line width for AOI item\n",
    "\n",
    "    # ---- Route style ----\n",
    "    \"ROUTE_COLOR\": \"red\",                       # route line color\n",
    "    \"ROUTE_LW\": 2.6,                            # route line width\n",
    "    \"ROUTE_ALPHA\": 1.0,                         # route transparency\n",
    "    \"LBL_ROUTE\": \"Route\",                       # legend label for route\n",
    "\n",
    "    # ---- Start/Destination markers ----\n",
    "    \"START_COLOR\": \"#1b9e77\",                   # start marker color\n",
    "    \"START_SIZE\": 48,                           # start marker size\n",
    "    \"DEST_COLOR\": \"black\",                      # destination marker color\n",
    "    \"DEST_SIZE\": 40,                            # destination marker size\n",
    "    \"LBL_START\": \"Start\",                       # legend label for start\n",
    "    \"LBL_DEST\": \"Destination\",                  # legend label for destination\n",
    "    \"LEG_MARKER_SIZE\": 8,                       # legend marker size for start/dest items\n",
    "\n",
    "    # ---- North arrow ----\n",
    "    \"ADD_NORTH_ARROW\": True,                    # toggle north arrow\n",
    "    \"NA_X\": 0.05, \"NA_Y\": 0.15,                 # arrow position (axes fraction)\n",
    "    \"NA_LEN\": 0.08,                             # arrow length (axes fraction)\n",
    "    \"NA_LABEL\": \"N\",                            # arrow label\n",
    "    \"NA_COLOR\": \"black\", \"NA_LW\": 2, \"NA_FONTSIZE\": 14,  # arrow color/line width/font size\n",
    "\n",
    "    # ---- Scalebar ----\n",
    "    \"ADD_SCALEBAR\": True,                       # toggle scalebar\n",
    "    \"SB_UNITS\": \"m\",                            # scalebar units\n",
    "    \"SB_LOC\": \"lower right\",                    # scalebar location\n",
    "    \"SB_BOX_ALPHA\": 0.8,                        # scalebar box transparency\n",
    "\n",
    "    # ---- Title ----\n",
    "    \"TITLE_PREFIX\": \"Shortest Path\"             # title prefix → \"<prefix> i — length = Xm\"\n",
    "}\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def _route_to_gdfs_ll(G, route):\n",
    "    res = ox.routing.route_to_gdf(G, route, weight=\"length\")\n",
    "    if isinstance(res, tuple):\n",
    "        return res[0], res[1]\n",
    "    xs = [G.nodes[n][\"x\"] for n in route]\n",
    "    ys = [G.nodes[n][\"y\"] for n in route]\n",
    "    nodes_ll = gpd.GeoDataFrame({\"node\": route, \"seq\": range(len(route))},\n",
    "                                geometry=gpd.points_from_xy(xs, ys), crs=4326)\n",
    "    return res, nodes_ll\n",
    "\n",
    "# Base network in meters (CRS from edges_ok)\n",
    "base_utm = edges_ok.estimate_utm_crs()\n",
    "base_m   = edges_ok.to_crs(base_utm)\n",
    "\n",
    "# Optional AOI (in same meters CRS)\n",
    "aoi_m = aoi_gdf_ll.to_crs(base_utm) if P[\"DRAW_AOI\"] and 'aoi_gdf_ll' in globals() else None\n",
    "\n",
    "# --- Save combined CSV for all routes (unchanged methodology) ---\n",
    "all_rows = []\n",
    "for i, r in enumerate(routes_list[:ROUTE_TARGET]):\n",
    "    for row in export_nodes_csv_rows(G, r):\n",
    "        row[\"route_id\"] = i\n",
    "        all_rows.append(row)\n",
    "\n",
    "csv_path = Path(SP_OUT_DIR) / P[\"CSV_NAME\"]\n",
    "pd.DataFrame(all_rows).to_csv(csv_path, index=False)\n",
    "print(f\" Saved CSV → {csv_path}\")\n",
    "\n",
    "# --- Plot & save (smaller images; one PNG per route) ---\n",
    "def _plot_route_png(i, r):\n",
    "    edges_ll, nodes_ll = _route_to_gdfs_ll(G, r)\n",
    "    edges_m = edges_ll.to_crs(base_utm)\n",
    "    nodes_m = nodes_ll.to_crs(base_utm)\n",
    "\n",
    "    # Start/End markers (project to meters CRS)\n",
    "    start_lon, start_lat = G.nodes[orig_node][\"x\"], G.nodes[orig_node][\"y\"]\n",
    "    dest_lon,  dest_lat  = G.nodes[dest_node][\"x\"],  G.nodes[dest_node][\"y\"]\n",
    "    start_m = gpd.GeoSeries([Point(start_lon, start_lat)], crs=4326).to_crs(base_utm)\n",
    "    dest_m  = gpd.GeoSeries([Point(dest_lon,  dest_lat)],  crs=4326).to_crs(base_utm)\n",
    "\n",
    "    # Frame (zoom if user provided bbox; else auto from layers)\n",
    "    if all(P[k] is not None for k in (\"lon_min\",\"lon_max\",\"lat_min\",\"lat_max\")):\n",
    "        zoom_ll = gpd.GeoDataFrame(\n",
    "            geometry=[box(min(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                          min(P[\"lat_min\"], P[\"lat_max\"]),\n",
    "                          max(P[\"lon_min\"], P[\"lon_max\"]),\n",
    "                          max(P[\"lat_min\"], P[\"lat_max\"]))],\n",
    "            crs=4326\n",
    "        ).to_crs(base_utm)\n",
    "        xmin, ymin, xmax, ymax = zoom_ll.total_bounds\n",
    "    else:\n",
    "        bounds = []\n",
    "        if not base_m.empty:  bounds.append(base_m.total_bounds)\n",
    "        if not edges_m.empty: bounds.append(edges_m.total_bounds)\n",
    "        if aoi_m is not None and not aoi_m.empty: bounds.append(aoi_m.total_bounds)\n",
    "        xmin = min(b[0] for b in bounds); ymin = min(b[1] for b in bounds)\n",
    "        xmax = max(b[2] for b in bounds); ymax = max(b[3] for b in bounds)\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"])\n",
    "    if not base_m.empty:\n",
    "        base_m.plot(ax=ax, color=P[\"BASE_COLOR\"], linewidth=P[\"BASE_LW\"],\n",
    "                    alpha=P[\"BASE_ALPHA\"], zorder=1)\n",
    "    if aoi_m is not None and not aoi_m.empty:\n",
    "        aoi_m.boundary.plot(ax=ax, color=P[\"AOI_COLOR\"], linewidth=P[\"AOI_LW\"],\n",
    "                            alpha=P[\"AOI_ALPHA\"], zorder=2)\n",
    "\n",
    "    edges_m.plot(ax=ax, color=P[\"ROUTE_COLOR\"], linewidth=P[\"ROUTE_LW\"],\n",
    "                 alpha=P[\"ROUTE_ALPHA\"], zorder=3)\n",
    "    if len(nodes_m) >= 2:\n",
    "        nodes_m.iloc[[0, -1]].plot(ax=ax, color=P[\"ROUTE_COLOR\"],\n",
    "                                   markersize=max(P[\"ROUTE_LW\"]*5, 10), zorder=4)\n",
    "\n",
    "    start_m.plot(ax=ax, color=P[\"START_COLOR\"], markersize=P[\"START_SIZE\"], marker=\"o\", zorder=5)\n",
    "    dest_m.plot(ax=ax,  color=P[\"DEST_COLOR\"],  markersize=P[\"DEST_SIZE\"],  marker=\"o\", zorder=5)\n",
    "\n",
    "    ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    # North arrow\n",
    "    if P[\"ADD_NORTH_ARROW\"]:\n",
    "        ax.annotate(P[\"NA_LABEL\"], xy=(P[\"NA_X\"], P[\"NA_Y\"]), xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                    xycoords=\"axes fraction\", textcoords=\"axes fraction\",\n",
    "                    ha=\"center\", va=\"center\", fontsize=P[\"NA_FONTSIZE\"], fontweight=\"bold\",\n",
    "                    arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                    clip_on=False, zorder=20)\n",
    "\n",
    "    # Scalebar\n",
    "    if P[\"ADD_SCALEBAR\"]:\n",
    "        ax.add_artist(ScaleBar(1, P[\"SB_UNITS\"], location=P[\"SB_LOC\"], box_alpha=P[\"SB_BOX_ALPHA\"]))\n",
    "\n",
    "    ax.set_aspect(\"equal\"); ax.ticklabel_format(style=\"plain\")\n",
    "    ax.set_xlabel(P[\"XLABEL\"]); ax.set_ylabel(P[\"YLABEL\"])\n",
    "    length_m = get_route_length(G, r)\n",
    "    ax.set_title(f\"{P['TITLE_PREFIX']} {i} — length = {length_m:.1f} m\")\n",
    "\n",
    "    legend_items = [\n",
    "        Line2D([0],[0], color=P[\"BASE_COLOR\"], lw=3, label=P[\"LBL_BASE\"]),\n",
    "        Line2D([0],[0], color=P[\"ROUTE_COLOR\"], lw=3, label=P[\"LBL_ROUTE\"]),\n",
    "        Line2D([0],[0], marker=\"o\", color=\"none\", markerfacecolor=P[\"START_COLOR\"],\n",
    "               markersize=P[\"LEG_MARKER_SIZE\"], label=P[\"LBL_START\"]),\n",
    "        Line2D([0],[0], marker=\"o\", color=\"none\", markerfacecolor=P[\"DEST_COLOR\"],\n",
    "               markersize=P[\"LEG_MARKER_SIZE\"], label=P[\"LBL_DEST\"]),\n",
    "        Line2D([0],[0], color=P[\"AOI_COLOR\"], lw=P[\"LEG_AOI_LW\"], label=P[\"LBL_AOI\"])\n",
    "    ]\n",
    "    ax.legend(handles=legend_items, loc=P[\"LEGEND_LOC\"], frameon=True)\n",
    "\n",
    "    out_png_i = Path(SP_OUT_DIR) / P[\"OUT_NAME_FMT\"].format(i=i)\n",
    "    fig.savefig(out_png_i, dpi=P[\"DPI\"], bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\" Saved: {out_png_i}\")\n",
    "    display(Image(filename=str(out_png_i)))\n",
    "\n",
    "# Render all requested routes\n",
    "for i, r in enumerate(routes_list[:ROUTE_TARGET]):\n",
    "    _plot_route_png(i, r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335d132-1dd1-48eb-b8a3-e4738f34962f",
   "metadata": {},
   "source": [
    "## I) Utility 2: Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9f3cc-1440-4209-a524-099833c0a224",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I0) Imports  =========================\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap, ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from shapely.geometry import Point, box\n",
    "from IPython.display import Image, display\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import yaml\n",
    "from math import radians, sin, asin, sqrt, cos\n",
    "from matplotlib import colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6656e6d-a564-4b8e-a8a5-5110075021f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ====================== I1) User Options & Paths ======================\n",
    "# --- Spatial subset for BC (lon/lat degrees). Set USE_BBOX=False to use full area in configuration\n",
    "USE_BBOX = require(\"USE_BBOX\", bool)\n",
    "lon_min, lon_max = require(\"lon_min\", float), require(\"lon_max\", float)\n",
    "lat_min, lat_max = require(\"lat_min\", float), require(\"lat_max\", float)\n",
    "\n",
    "# --- Betweenness centrality options ---\n",
    "USE_APPROX_BC = require(\"USE_APPROX_BC\", bool)     # True: randomized approx (fast), False: exact (slow)\n",
    "K_SAMPLES     = require(\"K_SAMPLES\", int)          # used only if USE_APPROX_BC=True (clipped to #nodes)\n",
    "BC_WEIGHT     = require(\"BC_WEIGHT\", str)          # edge weight for BC\n",
    "BC_NORMALIZED = require(\"BC_NORMALIZED\", bool)     # normalize BC values to [0,1] scale\n",
    "\n",
    "# --- Outputs ---\n",
    "OUT_BASE   = r\"./Outputs\"\n",
    "A_OUT_DIR  = os.path.join(OUT_BASE, \"A\")\n",
    "E_OUT_DIR  = os.path.join(OUT_BASE, \"E\")\n",
    "F_OUT_DIR  = os.path.join(OUT_BASE, \"F\")\n",
    "I_OUT_DIR  = os.path.join(OUT_BASE, \"I\")\n",
    "IMAGES_DIR = os.path.join(OUT_BASE, \"Images\")\n",
    "os.makedirs(I_OUT_DIR, exist_ok=True)\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    _have_scalebar = True\n",
    "except Exception:\n",
    "    _have_scalebar = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82eb0c-2f56-4d1b-837d-edb68de66e5a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ============== I2) Gather UNDAMAGED nodes/edges ===============\n",
    "nodes_ok_src = globals().get(\"nodes_ok\", None)\n",
    "edges_ok_src = globals().get(\"edges_ok\", None)\n",
    "\n",
    "if (nodes_ok_src is None or getattr(nodes_ok_src, \"empty\", True)) and (\"nodes_eval\" in globals()):\n",
    "    n_ = globals()[\"nodes_eval\"]\n",
    "    if isinstance(n_, gpd.GeoDataFrame) and not n_.empty and (\"Damaged\" in n_.columns):\n",
    "        nodes_ok_src = n_[n_[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "\n",
    "if (edges_ok_src is None or getattr(edges_ok_src, \"empty\", True)) and (\"edges_eval\" in globals()):\n",
    "    e_ = globals()[\"edges_eval\"]\n",
    "    if isinstance(e_, gpd.GeoDataFrame) and not e_.empty and (\"Damaged\" in e_.columns):\n",
    "        edges_ok_src = e_[e_[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "\n",
    "if (edges_ok_src is None or getattr(edges_ok_src, \"empty\", True)):\n",
    "    cand_edges = [\n",
    "        Path(F_OUT_DIR) / \"Evaluated_Edges_withTunnels_Bridges.shp\",\n",
    "        Path(E_OUT_DIR) / \"Evaluated_Edges.shp\",\n",
    "        Path(A_OUT_DIR) / \"osm_edges.shp\",\n",
    "    ]\n",
    "    for p in cand_edges:\n",
    "        if p.exists():\n",
    "            g = gpd.read_file(p)\n",
    "            if \"Damaged\" in g.columns:\n",
    "                edges_ok_src = g[g[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "            else:\n",
    "                edges_ok_src = g.copy()\n",
    "            if not edges_ok_src.empty:\n",
    "                break\n",
    "\n",
    "if (nodes_ok_src is None or getattr(nodes_ok_src, \"empty\", True)):\n",
    "    cand_nodes = [\n",
    "        Path(F_OUT_DIR) / \"Evaluated_Nodes_withTunnels_Bridges.shp\",\n",
    "        Path(A_OUT_DIR) / \"osm_nodes.shp\",\n",
    "    ]\n",
    "    for p in cand_nodes:\n",
    "        if p.exists():\n",
    "            n = gpd.read_file(p)\n",
    "            if \"Damaged\" in n.columns:\n",
    "                nodes_ok_src = n[n[\"Damaged\"].astype(str).str.lower().eq(\"no\")].copy()\n",
    "            else:\n",
    "                nodes_ok_src = n.copy()\n",
    "            if not nodes_ok_src.empty:\n",
    "                break\n",
    "\n",
    "if nodes_ok_src is None or edges_ok_src is None or nodes_ok_src.empty or edges_ok_src.empty:\n",
    "    raise RuntimeError(\"Could not assemble undamaged nodes/edges for BC.\")\n",
    "\n",
    "print(f\"UNDAMAGED for BC → nodes: {len(nodes_ok_src):,} | edges: {len(edges_ok_src):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cee11b-b075-465a-88ea-88369078a4a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ================= I3) Normalize schema helpers =================\n",
    "def ensure_nodes_index_xy(nodes_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Ensure:\n",
    "      - index is 'osmid' (if present),\n",
    "      - CRS is EPSG:4326,\n",
    "      - columns 'x' and 'y' are lon/lat in degrees from geometry.\n",
    "    \"\"\"\n",
    "    n = nodes_gdf.copy()\n",
    "\n",
    "    # --- Index: use OSMID if present ---\n",
    "    if \"osmid\" in n.columns:\n",
    "        if n.index.name != \"osmid\":\n",
    "            n = n.set_index(\"osmid\", drop=False)\n",
    "    else:\n",
    "        # fallback: create an osmid from the index\n",
    "        if n.index.name != \"osmid\":\n",
    "            n = n.reset_index().rename(columns={\"index\": \"osmid\"})\n",
    "            n = n.set_index(\"osmid\", drop=False)\n",
    "\n",
    "    # --- CRS: force WGS84 lon/lat ---\n",
    "    if n.crs is None:\n",
    "        n = n.set_crs(4326, allow_override=True)\n",
    "    if n.crs.to_epsg() != 4326:\n",
    "        n = n.to_crs(4326)\n",
    "\n",
    "    # --- x,y: always from geometry in EPSG:4326 ---\n",
    "    n[\"x\"] = n.geometry.x  # longitude\n",
    "    n[\"y\"] = n.geometry.y  # latitude\n",
    "\n",
    "    return n\n",
    "\n",
    "def _ensure_edges_uvk(edges_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Keep u/v/key as columns; do not set MultiIndex here.\"\"\"\n",
    "    e = edges_gdf.copy()\n",
    "    if isinstance(e.index, pd.MultiIndex):\n",
    "        e = e.reset_index()\n",
    "        idx_names = list(edges_gdf.index.names)\n",
    "        rename_map = {}\n",
    "        if len(idx_names) >= 1 and idx_names[0] and idx_names[0] != 'u':   rename_map[idx_names[0]] = 'u'\n",
    "        if len(idx_names) >= 2 and idx_names[1] and idx_names[1] != 'v':   rename_map[idx_names[1]] = 'v'\n",
    "        if len(idx_names) >= 3 and idx_names[2] and idx_names[2] != 'key': rename_map[idx_names[2]] = 'key'\n",
    "        if rename_map:\n",
    "            e = e.rename(columns=rename_map)\n",
    "    missing_uv = [c for c in ('u','v') if c not in e.columns]\n",
    "    if missing_uv:\n",
    "        raise ValueError(f\"Edges must have columns 'u' and 'v'; missing: {missing_uv}\")\n",
    "    if 'key' not in e.columns:\n",
    "        e['key'] = e.groupby(['u','v']).cumcount()\n",
    "    return e\n",
    "\n",
    "def _ensure_lengths(edges_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Ensure a 'length' column in meters (prefer projected UTM; fallback haversine).\"\"\"\n",
    "    e = edges_gdf.copy()\n",
    "    if \"length\" in e.columns and e[\"length\"].notna().all():\n",
    "        return e\n",
    "    try:\n",
    "        utm = e.estimate_utm_crs()\n",
    "        e[\"length\"] = e.to_crs(utm).geometry.length\n",
    "    except Exception:\n",
    "        def hav_m(geom):\n",
    "            try:\n",
    "                coords = list(geom.coords)\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "            R = 6371008.8\n",
    "            s = 0.0\n",
    "            for (x1,y1),(x2,y2) in zip(coords[:-1], coords[1:]):\n",
    "                dlat = radians(y2-y1); dlon = radians(x2-x1)\n",
    "                a = sin(dlat/2)**2 + cos(radians(y1))*cos(radians(y2))*sin(dlon/2)**2\n",
    "                s += 2*R*asin(sqrt(a))\n",
    "            return s\n",
    "        e[\"length\"] = e.geometry.apply(hav_m)\n",
    "    return e\n",
    "\n",
    "# Normalize + dtype align\n",
    "nodes_bc = ensure_nodes_index_xy(nodes_ok_src)\n",
    "edges_bc = _ensure_edges_uvk(edges_ok_src)\n",
    "\n",
    "# dtype align node index with edge u/v dtype (no MultiIndex yet)\n",
    "u_dtype = edges_bc['u'].dtype\n",
    "if nodes_bc.index.dtype != u_dtype:\n",
    "    nodes_bc.index = nodes_bc.index.astype(u_dtype)\n",
    "    if \"osmid\" in nodes_bc.columns:\n",
    "        nodes_bc[\"osmid\"] = nodes_bc[\"osmid\"].astype(u_dtype)\n",
    "\n",
    "if nodes_bc.crs is None:\n",
    "    nodes_bc = nodes_bc.set_crs(4326, allow_override=True)\n",
    "if edges_bc.crs is None:\n",
    "    edges_bc = edges_bc.set_crs(nodes_bc.crs, allow_override=True)\n",
    "\n",
    "print(\" Schema OK for OSMnx (pre-clip)\")\n",
    "print(\"  Nodes index:\", nodes_bc.index.name, \"| dtype:\", nodes_bc.index.dtype)\n",
    "print(\"  Edges u/v exist:\", set(['u','v']).issubset(edges_bc.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2994279b-0480-4be1-8250-210d4ff5d3b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I4) Optional lon/lat bbox clip =========================\n",
    "def _valid(x): return x is not None and isinstance(x, (int, float))\n",
    "use_bbox = USE_BBOX and all(_valid(v) for v in [lon_min, lon_max, lat_min, lat_max])\n",
    "\n",
    "if use_bbox:\n",
    "    nodes_ll = nodes_bc.to_crs(4326).copy()\n",
    "    edges_ll = edges_bc.to_crs(4326).copy()\n",
    "\n",
    "    xmin, xmax = min(lon_min, lon_max), max(lon_min, lon_max)\n",
    "    ymin, ymax = min(lat_min, lat_max), max(lat_min, lat_max)\n",
    "    rect = box(xmin, ymin, xmax, ymax)\n",
    "\n",
    "    # keep nodes strictly inside bbox\n",
    "    nodes_clip = nodes_ll[nodes_ll.geometry.within(rect)].copy()\n",
    "    keep_ids = set(nodes_clip[\"osmid\"].tolist())\n",
    "\n",
    "    # keep edges whose BOTH endpoints are inside\n",
    "    if not {\"u\", \"v\"}.issubset(edges_ll.columns):\n",
    "        raise ValueError(\"Edges must expose 'u' and 'v' columns at this step.\")\n",
    "    edges_clip = edges_ll[edges_ll[\"u\"].isin(keep_ids) & edges_ll[\"v\"].isin(keep_ids)].copy()\n",
    "\n",
    "    # back to original CRS\n",
    "    nodes_use = nodes_clip.to_crs(nodes_bc.crs)\n",
    "    edges_use = edges_clip.to_crs(edges_bc.crs)\n",
    "\n",
    "    print(f\" BBox filter applied → nodes: {len(nodes_use):,} | edges: {len(edges_use):,}\")\n",
    "else:\n",
    "    nodes_use = nodes_bc\n",
    "    edges_use = edges_bc\n",
    "    print(f\" Using full undamaged network → nodes: {len(nodes_use):,} | edges: {len(edges_use):,}\")\n",
    "\n",
    "if nodes_use.empty or edges_use.empty:\n",
    "    raise SystemExit(\"No nodes/edges in the selected extent for BC.\")\n",
    "\n",
    "# Compute edge lengths after final selection\n",
    "edges_use = _ensure_lengths(edges_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c3a00-481f-4755-8574-817caefb8e9e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I5) Finalize OSMnx-friendly indices =========================\n",
    "# --- Nodes: ensure index=osmid and x/y present ---\n",
    "nodes_g = nodes_use.copy()\n",
    "if 'osmid' not in nodes_g.columns:\n",
    "    nodes_g = nodes_g.reset_index().rename(columns={'index': 'osmid'})\n",
    "if nodes_g.index.name != 'osmid':\n",
    "    nodes_g = nodes_g.set_index('osmid', drop=False)\n",
    "\n",
    "if ('x' not in nodes_g.columns) or ('y' not in nodes_g.columns):\n",
    "    if nodes_g.crs and getattr(nodes_g.crs, \"is_projected\", False):\n",
    "        _n_ll = nodes_g.to_crs(4326)\n",
    "        nodes_g['x'] = _n_ll.geometry.x\n",
    "        nodes_g['y'] = _n_ll.geometry.y\n",
    "    else:\n",
    "        nodes_g['x'] = nodes_g.geometry.x\n",
    "        nodes_g['y'] = nodes_g.geometry.y\n",
    "\n",
    "# --- Edges: u/v/key are already columns; create canonical MultiIndex once for OSMnx ---\n",
    "edges_g = edges_use.copy()\n",
    "missing_uv = [c for c in ('u','v') if c not in edges_g.columns]\n",
    "if missing_uv:\n",
    "    raise KeyError(f\"Edges must have 'u' and 'v' columns; missing: {missing_uv}\")\n",
    "\n",
    "# ensure 'key' exists\n",
    "if 'key' not in edges_g.columns:\n",
    "    edges_g['key'] = edges_g.groupby(['u','v']).cumcount()\n",
    "\n",
    "# set MultiIndex and DROP u/v/key from columns to avoid duplication\n",
    "edges_g = edges_g.set_index(['u', 'v', 'key'], drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21f400-0bf7-4acc-b91d-29e2b0dff048",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I6) Build graph → undirected → largest CC =========================\n",
    "# Ensure compatible CRS tags\n",
    "if nodes_g.crs is None:\n",
    "    nodes_g = nodes_g.set_crs(4326, allow_override=True)\n",
    "if edges_g.crs is None:\n",
    "    edges_g = edges_g.set_crs(nodes_g.crs, allow_override=True)\n",
    "\n",
    "# Build MultiDiGraph from GDFs\n",
    "G_multi = ox.convert.graph_from_gdfs(nodes_g, edges_g)\n",
    "\n",
    "# Make undirected weighted by 'length'\n",
    "G_und = ox.convert.to_undirected(G_multi)\n",
    "\n",
    "# Largest connected component for stable BC\n",
    "if G_und.number_of_nodes() == 0:\n",
    "    raise SystemExit(\"Graph has no nodes after preprocessing.\")\n",
    "largest_cc = max(nx.connected_components(G_und), key=len)\n",
    "G = G_und.subgraph(largest_cc).copy()\n",
    "\n",
    "print(f\"Graph for BC → nodes: {G.number_of_nodes():,} | edges: {G.number_of_edges():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1a464-5499-4474-a85e-0ddd4b22b6e9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I7) Betweenness centrality =========================\n",
    "if USE_APPROX_BC:\n",
    "    k = min(K_SAMPLES, G.number_of_nodes())\n",
    "    bc_dict = nx.betweenness_centrality(G, k=k, seed=0, weight=BC_WEIGHT, normalized=BC_NORMALIZED)\n",
    "    print(f\"Computed APPROX betweenness centrality with k={k}.\")\n",
    "else:\n",
    "    bc_dict = nx.betweenness_centrality(G, weight=BC_WEIGHT, normalized=BC_NORMALIZED)\n",
    "    print(\"Computed EXACT betweenness centrality.\")\n",
    "\n",
    "# Quick peek\n",
    "if bc_dict:\n",
    "    top_node = max(bc_dict, key=bc_dict.get)\n",
    "    print(f\" Top BC node: {top_node} | BC={bc_dict[top_node]:.6f}\")\n",
    "else:\n",
    "    print(\" Empty BC result (degenerate component?).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b0288-d486-40d4-b672-e184347d77db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I8) Attach BC back to nodes dataset =========================\n",
    "nodes_bc = nodes_bc.copy()\n",
    "if 'osmid' not in nodes_bc.columns:\n",
    "    nodes_bc = nodes_bc.reset_index().rename(columns={'index': 'osmid'}).set_index('osmid', drop=False)\n",
    "\n",
    "bc_series = pd.Series(bc_dict, name='bc', dtype=float)\n",
    "nodes_bc['bc'] = nodes_bc['osmid'].map(bc_series).fillna(0.0).astype(float)\n",
    "\n",
    "print(f\"nodes_bc w/ BC assigned: {len(nodes_bc):,} rows | bc>0 count: {(nodes_bc['bc']>0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce6582-0ebd-4540-b1fe-b803382d80fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I9) Plot BC map =========================\n",
    "P = {\n",
    "    # ---- Output ----\n",
    "    \"OUT_NAME\": \"Betweenness_Centrality_Map.png\",   # filename for the exported PNG\n",
    "\n",
    "    # ---- Data / threshold ----\n",
    "    \"BC_THRESHOLD\": 0.1,                           # show nodes whose betweenness centrality >= this value\n",
    "\n",
    "    # ---- Manual zoom in EPSG:4326 (set all to None for auto extent) ----\n",
    "    \"lon_min\": 36.900,             # min longitude of custom zoom (None = auto)\n",
    "    \"lon_max\": 36.930,             # max longitude (None = auto)\n",
    "    \"lat_min\": 37.570,             # min latitude  (None = auto)\n",
    "    \"lat_max\": 37.600,             # max latitude  (None = auto)\n",
    "\n",
    "    # ---- Figure & theme ----\n",
    "    \"FIGSIZE\": (8, 7),                              # figure size (width, height) in inches\n",
    "    \"DPI\": 300,                                     # export resolution (dots per inch)\n",
    "    \"BG_COLOR\": \"black\",                            # background color for figure/axes\n",
    "    \"FG_COLOR\": \"white\",                            # foreground color for ticks/labels/spines\n",
    "\n",
    "    # ---- Base layers ----\n",
    "    \"EDGE_COLOR\": \"#808080\",                        # line color for the base network edges\n",
    "    \"EDGE_LW\": 0.7,                                 # linewidth for base network edges\n",
    "    \"EDGE_ALPHA\": 1.0,                              # transparency for base network edges (0..1)\n",
    "    \"AOI_COLOR\": \"white\",                           # color for AOI boundary\n",
    "    \"AOI_LW\": 1.2,                                  # linewidth for AOI boundary\n",
    "    \"AOI_ALPHA\": 1.0,                               # transparency for AOI boundary (0..1)\n",
    "    \"NODE_SIZE\": 12,                                # marker size for plotted nodes (above threshold)\n",
    "    \"NODE_EDGEWIDTH\": 0,                            # outline width for node markers (0 = none)\n",
    "    \"CMAP\": \"plasma\",                               # colormap used to color nodes by BC value\n",
    "\n",
    "    # ---- Colorbar ----\n",
    "    \"ADD_COLORBAR\": True,                           # toggle colorbar visibility\n",
    "    \"CB_LABEL\": \"Betweenness Centrality\",           # colorbar label text\n",
    "    \"CB_FRACTION\": 0.03,                            # colorbar size fraction relative to axes\n",
    "    \"CB_PAD\": 0.02,                                 # padding between axes and colorbar\n",
    "    \"CB_LABEL_COLOR\": \"white\",                      # color for colorbar label text\n",
    "    \"CB_TICK_COLOR\": \"white\",                       # color for colorbar tick labels\n",
    "\n",
    "    # ---- Axes labels & title ----\n",
    "    \"XLABEL\": \"Easting (m)\",                        # x-axis label\n",
    "    \"YLABEL\": \"Northing (m)\",                       # y-axis label\n",
    "    \"TITLE\": \"Betweenness Centrality\",              # plot title text\n",
    "    \"TITLE_COLOR\": \"white\",                         # plot title color\n",
    "\n",
    "    # ---- North arrow ----\n",
    "    \"ADD_NORTH_ARROW\": True,                        # toggle north arrow\n",
    "    \"NA_X\": 0.05, \"NA_Y\": 0.15,                     # arrow position in axes fraction (0..1)\n",
    "    \"NA_LEN\": 0.08,                                 # arrow length in axes fraction\n",
    "    \"NA_LABEL\": \"N\",                                # text label shown at arrow head\n",
    "    \"NA_COLOR\": \"white\", \"NA_LW\": 2, \"NA_FONTSIZE\": 14,  # arrow color, line width, font size\n",
    "\n",
    "    # ---- Scalebar ----\n",
    "    \"ADD_SCALEBAR\": True,                           # toggle scalebar\n",
    "    \"SB_UNITS\": \"m\",                                # scalebar units label\n",
    "    \"SB_LOC\": \"lower right\",                        # scalebar location on axes\n",
    "    \"SB_BOX_ALPHA\": 0.8,                            # scalebar box transparency (0..1)\n",
    "    \"SB_COLOR\": \"black\",                            # scalebar text/line color\n",
    "\n",
    "    # ---- Legend ----\n",
    "    \"ADD_LEGEND\": True,                             # toggle legend visibility\n",
    "    \"LEGEND_LOC\": \"upper right\",                    # legend placement\n",
    "    \"LEGEND_FACE\": \"white\",                         # legend box facecolor\n",
    "    \"LEGEND_EDGE\": \"black\",                         # legend box edgecolor\n",
    "    \"LEGEND_FRAME\": True,                           # draw legend frame box\n",
    "    \"LBL_EDGES\": \"Undamaged edges\",                 # legend label: base network line\n",
    "    \"LBL_NODES\": \"Nodes (BC ≥ {thr:.2f})\",          # legend label: BC nodes (format with BC_THRESHOLD)\n",
    "    \"LBL_AOI\": \"AOI boundary\",                      # legend label: AOI boundary\n",
    "    \"LEG_EDGES_LW\": 2.0,                            # legend line width for edges item\n",
    "    \"LEG_AOI_LW\": 1.2,                              # legend line width for AOI item\n",
    "    \"LEG_NODE_MARKERSIZE\": 7                        # legend marker size for node item\n",
    "}\n",
    "\n",
    "# ---------- Prepare projected layers (UTM) ----------\n",
    "seed = edges_use if not edges_use.empty else nodes_use\n",
    "utm_crs = seed.to_crs(4326).estimate_utm_crs()\n",
    "\n",
    "edges_m = edges_use.to_crs(utm_crs)\n",
    "nodes_m = nodes_bc.to_crs(utm_crs)   # full nodes (bc added), for plotting thresholded points\n",
    "aoi_m   = aoi_gdf_ll.to_crs(utm_crs) if 'aoi_gdf_ll' in globals() else None\n",
    "\n",
    "# Threshold + color scale\n",
    "max_bc_val = float(nodes_m[\"bc\"].max()) if len(nodes_m) else 0.0\n",
    "cmap = get_cmap(P[\"CMAP\"])\n",
    "norm = Normalize(vmin=0.0, vmax=max_bc_val if max_bc_val > 0 else 1.0)\n",
    "nodes_thr = nodes_m[nodes_m[\"bc\"] >= P[\"BC_THRESHOLD\"]].copy()\n",
    "if nodes_thr.empty:\n",
    "    print(f\"Warning: no nodes with BC ≥ {P['BC_THRESHOLD']}. Consider lowering the threshold.\")\n",
    "\n",
    "# Compute extent (auto-fit to drawn layers, with optional manual zoom in lon/lat)\n",
    "bounds = []\n",
    "if not edges_m.empty:\n",
    "    bounds.append(edges_m.total_bounds)\n",
    "if not nodes_m.empty:\n",
    "    bounds.append(nodes_m.total_bounds)\n",
    "if aoi_m is not None and not aoi_m.empty:\n",
    "    bounds.append(aoi_m.total_bounds)\n",
    "\n",
    "auto_xmin = min(b[0] for b in bounds)\n",
    "auto_ymin = min(b[1] for b in bounds)\n",
    "auto_xmax = max(b[2] for b in bounds)\n",
    "auto_ymax = max(b[3] for b in bounds)\n",
    "\n",
    "lon_min = P.get(\"lon_min\", None)\n",
    "lon_max = P.get(\"lon_max\", None)\n",
    "lat_min = P.get(\"lat_min\", None)\n",
    "lat_max = P.get(\"lat_max\", None)\n",
    "\n",
    "# If all four lon/lat limits are provided, use them as a manual zoom box\n",
    "if (lon_min is not None) and (lon_max is not None) and (lat_min is not None) and (lat_max is not None):\n",
    "    zoom_box_ll = box(lon_min, lat_min, lon_max, lat_max)\n",
    "    zoom_box_utm = gpd.GeoSeries([zoom_box_ll], crs=\"EPSG:4326\").to_crs(utm_crs).total_bounds\n",
    "    xmin, ymin, xmax, ymax = zoom_box_utm\n",
    "else:\n",
    "    xmin, ymin, xmax, ymax = auto_xmin, auto_ymin, auto_xmax, auto_ymax\n",
    "\n",
    "# --- Plot ---\n",
    "fig, ax = plt.subplots(figsize=P[\"FIGSIZE\"], facecolor=P[\"BG_COLOR\"])\n",
    "ax.set_facecolor(P[\"BG_COLOR\"])\n",
    "\n",
    "# Base network & AOI\n",
    "if not edges_m.empty:\n",
    "    edges_m.plot(ax=ax,\n",
    "                 color=P[\"EDGE_COLOR\"],\n",
    "                 linewidth=P[\"EDGE_LW\"],\n",
    "                 alpha=P[\"EDGE_ALPHA\"],\n",
    "                 zorder=1)\n",
    "\n",
    "if aoi_m is not None and not aoi_m.empty:\n",
    "    aoi_m.boundary.plot(ax=ax,\n",
    "                        color=P[\"AOI_COLOR\"],\n",
    "                        linewidth=P[\"AOI_LW\"],\n",
    "                        alpha=P[\"AOI_ALPHA\"],\n",
    "                        zorder=2)\n",
    "\n",
    "# Nodes (BC ≥ threshold)\n",
    "if not nodes_thr.empty:\n",
    "    ax.scatter(nodes_thr.geometry.x, nodes_thr.geometry.y,\n",
    "               c=nodes_thr[\"bc\"],\n",
    "               cmap=cmap,\n",
    "               norm=norm,\n",
    "               s=P[\"NODE_SIZE\"],\n",
    "               linewidths=P[\"NODE_EDGEWIDTH\"],\n",
    "               zorder=3)\n",
    "\n",
    "# Colorbar\n",
    "if P[\"ADD_COLORBAR\"]:\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax,\n",
    "                        fraction=P[\"CB_FRACTION\"],\n",
    "                        pad=P[\"CB_PAD\"])\n",
    "    cbar.set_label(P[\"CB_LABEL\"], color=P[\"CB_LABEL_COLOR\"])\n",
    "    cbar.ax.yaxis.set_tick_params(color=P[\"CB_TICK_COLOR\"])\n",
    "    plt.setp(cbar.ax.get_yticklabels(), color=P[\"CB_TICK_COLOR\"])\n",
    "\n",
    "# Frame + decor\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "if P[\"ADD_NORTH_ARROW\"]:\n",
    "    ax.annotate(P[\"NA_LABEL\"],\n",
    "                xy=(P[\"NA_X\"], P[\"NA_Y\"]),\n",
    "                xytext=(P[\"NA_X\"], P[\"NA_Y\"] - P[\"NA_LEN\"]),\n",
    "                xycoords=\"axes fraction\",\n",
    "                textcoords=\"axes fraction\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=P[\"NA_FONTSIZE\"],\n",
    "                fontweight=\"bold\",\n",
    "                arrowprops=dict(arrowstyle=\"-|>\", lw=P[\"NA_LW\"], color=P[\"NA_COLOR\"]),\n",
    "                color=P[\"NA_COLOR\"],\n",
    "                clip_on=False,\n",
    "                zorder=20)\n",
    "\n",
    "# Scalebar\n",
    "if P[\"ADD_SCALEBAR\"]:\n",
    "    if _have_scalebar:\n",
    "        ax.add_artist(\n",
    "            ScaleBar(1,\n",
    "                     P[\"SB_UNITS\"],\n",
    "                     location=P[\"SB_LOC\"],\n",
    "                     box_alpha=P[\"SB_BOX_ALPHA\"],\n",
    "                     color=P[\"SB_COLOR\"])\n",
    "        )\n",
    "    else:\n",
    "        print(\"Note: scalebar requested but matplotlib-scalebar is not installed. Skipping.\")\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.ticklabel_format(style=\"plain\")\n",
    "ax.tick_params(colors=P[\"FG_COLOR\"])\n",
    "for sp in ax.spines.values():\n",
    "    sp.set_edgecolor(P[\"FG_COLOR\"])\n",
    "ax.set_xlabel(P[\"XLABEL\"], color=P[\"FG_COLOR\"])\n",
    "ax.set_ylabel(P[\"YLABEL\"], color=P[\"FG_COLOR\"])\n",
    "ax.set_title(P[\"TITLE\"], color=P[\"TITLE_COLOR\"])\n",
    "\n",
    "# Legend\n",
    "if P[\"ADD_LEGEND\"]:\n",
    "    legend_items = [\n",
    "        Line2D([0], [0],\n",
    "               color=P[\"EDGE_COLOR\"],\n",
    "               lw=P[\"LEG_EDGES_LW\"],\n",
    "               label=P[\"LBL_EDGES\"]),\n",
    "        Line2D([0], [0],\n",
    "               marker=\"o\",\n",
    "               color=\"none\",\n",
    "               markerfacecolor=P[\"FG_COLOR\"],\n",
    "               markersize=P[\"LEG_NODE_MARKERSIZE\"],\n",
    "               label=P[\"LBL_NODES\"].format(thr=P[\"BC_THRESHOLD\"])),\n",
    "        Line2D([0], [0],\n",
    "               color=P[\"AOI_COLOR\"],\n",
    "               lw=P[\"LEG_AOI_LW\"],\n",
    "               label=P[\"LBL_AOI\"]),\n",
    "    ]\n",
    "    leg = ax.legend(handles=legend_items,\n",
    "                    loc=P[\"LEGEND_LOC\"],\n",
    "                    frameon=P[\"LEGEND_FRAME\"],\n",
    "                    facecolor=P[\"LEGEND_FACE\"],\n",
    "                    edgecolor=P[\"LEGEND_EDGE\"])\n",
    "    leg.set_zorder(1000)\n",
    "\n",
    "# Save + show\n",
    "out_path = Path(IMAGES_DIR) / P[\"OUT_NAME\"]\n",
    "fig.savefig(out_path,\n",
    "            dpi=P[\"DPI\"],\n",
    "            bbox_inches=\"tight\",\n",
    "            facecolor=fig.get_facecolor())\n",
    "plt.close(fig)\n",
    "print(f\" Saved: {out_path}\")\n",
    "display(Image(filename=out_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7d125-01fb-4b78-b71c-a4ac02ecf0da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ========================= I10) Export BC table (node id, lon, lat, BC) =========================\n",
    "# Ensure required columns and WGS84 coordinates\n",
    "_nodes = nodes_bc.copy()\n",
    "if 'osmid' not in _nodes.columns:\n",
    "    _nodes = _nodes.reset_index().rename(columns={'index':'osmid'})\n",
    "\n",
    "nodes_ll = _nodes.to_crs(4326) if getattr(_nodes.crs, \"to_epsg\", lambda: None)() != 4326 else _nodes\n",
    "\n",
    "bc_df = pd.DataFrame({\n",
    "    \"node_id\": nodes_ll[\"osmid\"].astype(object),\n",
    "    \"lon\": nodes_ll.geometry.x.astype(float),\n",
    "    \"lat\": nodes_ll.geometry.y.astype(float),\n",
    "    \"BC\": nodes_ll[\"bc\"].astype(float)\n",
    "}).sort_values(\"BC\", ascending=False)\n",
    "\n",
    "# Save CSV to Outputs/I\n",
    "bc_csv = Path(I_OUT_DIR) / \"Betweenness_Centrality_nodes.csv\"\n",
    "bc_df.to_csv(bc_csv, index=False)\n",
    "print(f\" Saved BC CSV → {bc_csv}\")\n",
    "try:\n",
    "    display(bc_df.head(10))\n",
    "except Exception:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
